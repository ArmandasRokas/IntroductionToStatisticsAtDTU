{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Preface This website contains solutions to the textbook Introduction to Statistics at DTU by Per B. Brockhoff, Jan K. M\u00f8ller, Elisabeth W. Andersen Peder Bacher, Lasse E. Christiansen","title":"Preface"},{"location":"#preface","text":"This website contains solutions to the textbook Introduction to Statistics at DTU by Per B. Brockhoff, Jan K. M\u00f8ller, Elisabeth W. Andersen Peder Bacher, Lasse E. Christiansen","title":"Preface"},{"location":"chapter_1/","text":"1 Descriptive Statistics 1.1 Infant birth weight In a study of different occupational groups the infant birth weight was recorded for randomly selected babies born by hairdressers, who had their first child. The following table shows the weight in grams (observations specified in sorted order) for 10 female births and 10 male births: Gender Weights Famles(x) 2474 2547 2830 3219 3429 3448 3677 3872 4001 4116 Males(y) 2844 2863 2963 3239 3379 3449 3582 3926 4151 4356 Solve at least the following questions a)-c) first \u201cmanually\u201d and then by the inbuilt functions in . It is OK to use as alternative to your pocket calculator for the \u201cmanual\u201d part, but avoid the inbuilt functions that will produce the results without forcing you to think about how to compute it during the manual part. a) Females What is the sample mean, variance and standard deviation of the female births? Express in your own words the story told by these numbers. The idea is to force you to interpret what can be learned from these numbers. sample mean - show average including outliers \\bar{x} = \\frac{2474+2547+2830+3219+3429+3448+3677+3872+4001+4116}{10} \\\\ = 3361.3 \\bar{x} = \\frac{2474+2547+2830+3219+3429+3448+3677+3872+4001+4116}{10} \\\\ = 3361.3 variance - it\u2019s the average of the distance of values from the mean squared s^2 = \\frac{((2474-3361.3)^2+(2547-3361.3)^2+ (2830-3361.3)^2+\\\\(3219-3361.3)^2+ (3429-3361.3)^2+(3448-3361.3)^2+\\\\ (3677-3361.3)^2+(3872-3361.3)^2+ (4001-3361.3)^2+\\\\(4116-3361.3)^2}{9} = 344920.5 s^2 = \\frac{((2474-3361.3)^2+(2547-3361.3)^2+ (2830-3361.3)^2+\\\\(3219-3361.3)^2+ (3429-3361.3)^2+(3448-3361.3)^2+\\\\ (3677-3361.3)^2+(3872-3361.3)^2+ (4001-3361.3)^2+\\\\(4116-3361.3)^2}{9} = 344920.5 standard deviation - it's the square root of the variance. s = \\sqrt{283158.2} = 587.2993 s = \\sqrt{283158.2} = 587.2993 b) Males Compute the same summary statistics of the male births. Compare and explain differences with the results for the female births. sample mean \\bar{x} = \\frac{2844+2863+ 2963+3239+ 3379+ 3449+ 3582+ 3926+ 4151+ 4356}{10} = 3475.2 \\bar{x} = \\frac{2844+2863+ 2963+3239+ 3379+ 3449+ 3582+ 3926+ 4151+ 4356}{10} = 3475.2 variance s^2 = \\frac{(2844-3475.2)^2+(2863-3475.2)^2+ (2963-3475.2)^2+ \\\\ (3239-3475.2)^2+ (3379-3475.2)^2+ (3449-3475.2)^2+\\\\ (3582-3475.2)^2+ (3926-3475.2)^2+ (4151-3475.2)^2+ (4356-3475.2)^2}{9} = 532.1261 s^2 = \\frac{(2844-3475.2)^2+(2863-3475.2)^2+ (2963-3475.2)^2+ \\\\ (3239-3475.2)^2+ (3379-3475.2)^2+ (3449-3475.2)^2+\\\\ (3582-3475.2)^2+ (3926-3475.2)^2+ (4151-3475.2)^2+ (4356-3475.2)^2}{9} = 532.1261 standard deviation s = \\sqrt{1625049} = 532.1261 s = \\sqrt{1625049} = 532.1261 Compared with females males infant is heavier with 113.9 in average. Moreover males weight varies 55.1732\u202c grams less than females. c) The five quartiles Find the five quartiles for each sample \u2014 and draw the two box plots with pen and paper (i.e. not using R) Females Q_{0} = q_{0} = x_{1} = 2474\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100} = x_{\\lceil{2.5}\\rceil}} = x_{3} = 2830 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3429+3448}{2} = 3438.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3872 \\\\ Q_{4} = q_{1} = x_{10} = 4116\\\\ Q_{0} = q_{0} = x_{1} = 2474\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100} = x_{\\lceil{2.5}\\rceil}} = x_{3} = 2830 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3429+3448}{2} = 3438.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3872 \\\\ Q_{4} = q_{1} = x_{10} = 4116\\\\ Males Q_{0} = q_{0} = x_{1} = 2844\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100}} = x_{\\lceil{2.5}\\rceil} = x_{3} = 2963 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3379+3449}{2} = 3414.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3926 \\\\ Q_{4} = q_{1} = x_{10} = 4356\\\\ Q_{0} = q_{0} = x_{1} = 2844\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100}} = x_{\\lceil{2.5}\\rceil} = x_{3} = 2963 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3379+3449}{2} = 3414.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3926 \\\\ Q_{4} = q_{1} = x_{10} = 4356\\\\ Boxplot: d) Inter Quartile Range(IQR) Are there any \u201cextreme\u201d observations in the two samples (use the modified box plot definition of extremness)? IQR = q_{0.75} - q_{0.25} = Q_{3}-Q_{1} IQR = q_{0.75} - q_{0.25} = Q_{3}-Q_{1} Females IQR = q_{0.75}- q_{0.25} = 3872 - 2830 = 1042 \\\\ \\text{extremes} < Q_{1} - 1042 * 1.5 = 2963 - 1563 = 1400 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + 1042 * 1.5 = 3872 + 1563 = 5435 IQR = q_{0.75}- q_{0.25} = 3872 - 2830 = 1042 \\\\ \\text{extremes} < Q_{1} - 1042 * 1.5 = 2963 - 1563 = 1400 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + 1042 * 1.5 = 3872 + 1563 = 5435 There are no observations lower than 1400 or higher than 5435, so there are no \"extreme\" observations Males IQR = q_{0.75}- q_{0.25} =3926 - 2963 = 963 \\\\ \\text{extremes} < Q_{1} - 963 * 1.5 = 2963 - 1444.5= 1518.5 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + * 1.5 = 3926 + 1444.5 = 5370.5 IQR = q_{0.75}- q_{0.25} =3926 - 2963 = 963 \\\\ \\text{extremes} < Q_{1} - 963 * 1.5 = 2963 - 1444.5= 1518.5 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + * 1.5 = 3926 + 1444.5 = 5370.5 There are no observations lower than 1518.5 or higher than 5370.5 , so there are no \"extreme\" observations. e) The coefficient of variations What are the coefficient of variations in the two groups? V = \\frac{s}{\\bar{x}} V = \\frac{s}{\\bar{x}} Females $$ V = \\frac{587.2993}{3361.1}= 0.1747 $$ Males V = \\frac{532.1261}{3475.2} = 0.153121 V = \\frac{532.1261}{3475.2} = 0.153121 1.2 Course grades To compare the difficulty of 2 different courses at a university the following grades distributions (given as number of pupils who achieved the grades) were registered: Grade Course 1 Course 2 Total Grade 12 20 14 34 Grade 10 14 14 28 Grade 7 16 27 43 Grade 4 20 22 42 Grade 2 12 27 39 Grade 0 16 17 33 Grade 12 10 22 32 a) Median What is the median of the 251 achieved grades? 4 b) Quartiles and IQR What are the quartiles and the IQR (Inter Quartile Range)? Q_{0} = q_{0} = x_{1} = -3\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{251}{100} = x_{\\lceil{62.75}\\rceil}} = x_{63} = 0 \\\\ Q_{2} = q_{0.50}= \\frac{x_{125}+ x_{126}}{2} = \\frac{4+4}{2} = 4 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{251}{100}} = x_{{\\lceil{188.25}\\rceil}} = x_{189} = 7 \\\\ Q_{4} = q_{1} = x_{10} = 12\\\\ IQR = q_{0.75}- q_{0.25} = 7 - 0 = 7 \\\\ Q_{0} = q_{0} = x_{1} = -3\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{251}{100} = x_{\\lceil{62.75}\\rceil}} = x_{63} = 0 \\\\ Q_{2} = q_{0.50}= \\frac{x_{125}+ x_{126}}{2} = \\frac{4+4}{2} = 4 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{251}{100}} = x_{{\\lceil{188.25}\\rceil}} = x_{189} = 7 \\\\ Q_{4} = q_{1} = x_{10} = 12\\\\ IQR = q_{0.75}- q_{0.25} = 7 - 0 = 7 \\\\ 1.3 Cholesterol In a clinical trial of a cholesterol-lowering agent, 15 patients\u2019 cholesterol (in mmol L^{-1} L^{-1} ) was measured before treatment and 3 weeks after starting treatment. Data is listed in the following table: Patient No. Before After 1 9.1 8.2 2 8.0 6.4 3 7.7 6.6 4 10.0 8.5 5 9.6 8.0 6 7.9 5.8 7 9.0 7.8 8 7.1 7.2 9 8.3 6.7 10 9.6 9.8 11 8.2 7.1 12 9.2 7.7 13 7.3 6.0 14 8.5 6.6 15 9.5 8.4 a) Medians What is the median of the cholesterol measurements for the patients before treatment, and similarly after treatment? \\bar{b} = 8.5 \\\\ \\bar{a} = 7.2 \\bar{b} = 8.5 \\\\ \\bar{a} = 7.2 b) Standard deviation Find the standard deviations of the cholesterol measurements of the patients before and after treatment. s_{b} = 0.9023778 \\\\ s_{a} = 1.090129 s_{b} = 0.9023778 \\\\ s_{a} = 1.090129 c) Sample covariance Find the sample covariance between cholesterol measurements of the patients before and after treatment. By Definition 1.18 s_{ab} = \\frac{1}{n-1}\\sum_{i=1}^{n}{(b_{i}-\\bar{b})(a_{i}-\\bar{a})} = 0.7964286 s_{ab} = \\frac{1}{n-1}\\sum_{i=1}^{n}{(b_{i}-\\bar{b})(a_{i}-\\bar{a})} = 0.7964286 d) Correlation Find the sample correlation between cholesterol measurements of the patients before and after treatment. r = \\frac{s_{ba}}{s_{b}*s_{a}} = 0.8096188 r = \\frac{s_{ba}}{s_{b}*s_{a}} = 0.8096188 e) Differences Compute the 15 differences (Dif = Before \u2212 After) and do various summary statistics and plotting of these: sample mean, sample variance, sample standard deviation, boxplot etc. before <- c ( 9.1 , 8.0 , 7.7 , 10.0 , 9.6 , 7.9 , 9.0 , 7.1 , 8.3 , 9.6 , 8.2 , 9.2 , 7.3 , 8.5 , 9.5 ) after <- c ( 8.2 , 6.4 , 6.6 , 8.5 , 8.0 , 5.8 , 7.8 , 7.2 , 6.7 , 9.8 , 7.1 , 7.7 , 6.0 , 6.6 , 8.4 ) diffBeforeAfter <- before - after mean ( diffBeforeAfter ) median ( diffBeforeAfter ) var ( diffBeforeAfter ) sd ( diffBeforeAfter ) quantile ( diffBeforeAfter ) # precentiles boxplot ( diffBeforeAfter , col = \"red\" ) text ( 1.3 , quantile ( diffBeforeAfter ), c ( \"Minimum\" , \"Q1\" , \"Median\" , \"Q3\" , \"Maximum\" ), col = \"blue\" ) f) Formal answer Observing such data the big question is whether an average decrease in cholesterol level can be \u201cshown statistically\u201d. How to formally answer this question is presented in Chapter 3, but consider now which summary statistics and/or plots would you look at to have some idea of what the answer will be? I would answer something like this: the most patients decreased cholesterol level between 1.1 and 1.6, which is Inner Quartile Range (IQR). However the worst result recorded is -0.2 and the best is 2.1. Lastly the mean is 1.21 and the median is 1.3.","title":"1 Descriptive Statistics"},{"location":"chapter_1/#1-descriptive-statistics","text":"","title":"1 Descriptive Statistics"},{"location":"chapter_1/#11-infant-birth-weight","text":"In a study of different occupational groups the infant birth weight was recorded for randomly selected babies born by hairdressers, who had their first child. The following table shows the weight in grams (observations specified in sorted order) for 10 female births and 10 male births: Gender Weights Famles(x) 2474 2547 2830 3219 3429 3448 3677 3872 4001 4116 Males(y) 2844 2863 2963 3239 3379 3449 3582 3926 4151 4356 Solve at least the following questions a)-c) first \u201cmanually\u201d and then by the inbuilt functions in . It is OK to use as alternative to your pocket calculator for the \u201cmanual\u201d part, but avoid the inbuilt functions that will produce the results without forcing you to think about how to compute it during the manual part.","title":"1.1 Infant birth weight"},{"location":"chapter_1/#a-females","text":"What is the sample mean, variance and standard deviation of the female births? Express in your own words the story told by these numbers. The idea is to force you to interpret what can be learned from these numbers. sample mean - show average including outliers \\bar{x} = \\frac{2474+2547+2830+3219+3429+3448+3677+3872+4001+4116}{10} \\\\ = 3361.3 \\bar{x} = \\frac{2474+2547+2830+3219+3429+3448+3677+3872+4001+4116}{10} \\\\ = 3361.3 variance - it\u2019s the average of the distance of values from the mean squared s^2 = \\frac{((2474-3361.3)^2+(2547-3361.3)^2+ (2830-3361.3)^2+\\\\(3219-3361.3)^2+ (3429-3361.3)^2+(3448-3361.3)^2+\\\\ (3677-3361.3)^2+(3872-3361.3)^2+ (4001-3361.3)^2+\\\\(4116-3361.3)^2}{9} = 344920.5 s^2 = \\frac{((2474-3361.3)^2+(2547-3361.3)^2+ (2830-3361.3)^2+\\\\(3219-3361.3)^2+ (3429-3361.3)^2+(3448-3361.3)^2+\\\\ (3677-3361.3)^2+(3872-3361.3)^2+ (4001-3361.3)^2+\\\\(4116-3361.3)^2}{9} = 344920.5 standard deviation - it's the square root of the variance. s = \\sqrt{283158.2} = 587.2993 s = \\sqrt{283158.2} = 587.2993","title":"a) Females"},{"location":"chapter_1/#b-males","text":"Compute the same summary statistics of the male births. Compare and explain differences with the results for the female births. sample mean \\bar{x} = \\frac{2844+2863+ 2963+3239+ 3379+ 3449+ 3582+ 3926+ 4151+ 4356}{10} = 3475.2 \\bar{x} = \\frac{2844+2863+ 2963+3239+ 3379+ 3449+ 3582+ 3926+ 4151+ 4356}{10} = 3475.2 variance s^2 = \\frac{(2844-3475.2)^2+(2863-3475.2)^2+ (2963-3475.2)^2+ \\\\ (3239-3475.2)^2+ (3379-3475.2)^2+ (3449-3475.2)^2+\\\\ (3582-3475.2)^2+ (3926-3475.2)^2+ (4151-3475.2)^2+ (4356-3475.2)^2}{9} = 532.1261 s^2 = \\frac{(2844-3475.2)^2+(2863-3475.2)^2+ (2963-3475.2)^2+ \\\\ (3239-3475.2)^2+ (3379-3475.2)^2+ (3449-3475.2)^2+\\\\ (3582-3475.2)^2+ (3926-3475.2)^2+ (4151-3475.2)^2+ (4356-3475.2)^2}{9} = 532.1261 standard deviation s = \\sqrt{1625049} = 532.1261 s = \\sqrt{1625049} = 532.1261 Compared with females males infant is heavier with 113.9 in average. Moreover males weight varies 55.1732\u202c grams less than females.","title":"b) Males"},{"location":"chapter_1/#c-the-five-quartiles","text":"Find the five quartiles for each sample \u2014 and draw the two box plots with pen and paper (i.e. not using R) Females Q_{0} = q_{0} = x_{1} = 2474\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100} = x_{\\lceil{2.5}\\rceil}} = x_{3} = 2830 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3429+3448}{2} = 3438.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3872 \\\\ Q_{4} = q_{1} = x_{10} = 4116\\\\ Q_{0} = q_{0} = x_{1} = 2474\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100} = x_{\\lceil{2.5}\\rceil}} = x_{3} = 2830 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3429+3448}{2} = 3438.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3872 \\\\ Q_{4} = q_{1} = x_{10} = 4116\\\\ Males Q_{0} = q_{0} = x_{1} = 2844\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100}} = x_{\\lceil{2.5}\\rceil} = x_{3} = 2963 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3379+3449}{2} = 3414.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3926 \\\\ Q_{4} = q_{1} = x_{10} = 4356\\\\ Q_{0} = q_{0} = x_{1} = 2844\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{10}{100}} = x_{\\lceil{2.5}\\rceil} = x_{3} = 2963 \\\\ Q_{2} = q_{0.50}= \\frac{x_{5}+ x_{6}}{2} = \\frac{3379+3449}{2} = 3414.5 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{10}{100}} = x_{{\\lceil{7.5}\\rceil}} = x_{8} = 3926 \\\\ Q_{4} = q_{1} = x_{10} = 4356\\\\ Boxplot:","title":"c) The five quartiles"},{"location":"chapter_1/#d-inter-quartile-rangeiqr","text":"Are there any \u201cextreme\u201d observations in the two samples (use the modified box plot definition of extremness)? IQR = q_{0.75} - q_{0.25} = Q_{3}-Q_{1} IQR = q_{0.75} - q_{0.25} = Q_{3}-Q_{1} Females IQR = q_{0.75}- q_{0.25} = 3872 - 2830 = 1042 \\\\ \\text{extremes} < Q_{1} - 1042 * 1.5 = 2963 - 1563 = 1400 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + 1042 * 1.5 = 3872 + 1563 = 5435 IQR = q_{0.75}- q_{0.25} = 3872 - 2830 = 1042 \\\\ \\text{extremes} < Q_{1} - 1042 * 1.5 = 2963 - 1563 = 1400 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + 1042 * 1.5 = 3872 + 1563 = 5435 There are no observations lower than 1400 or higher than 5435, so there are no \"extreme\" observations Males IQR = q_{0.75}- q_{0.25} =3926 - 2963 = 963 \\\\ \\text{extremes} < Q_{1} - 963 * 1.5 = 2963 - 1444.5= 1518.5 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + * 1.5 = 3926 + 1444.5 = 5370.5 IQR = q_{0.75}- q_{0.25} =3926 - 2963 = 963 \\\\ \\text{extremes} < Q_{1} - 963 * 1.5 = 2963 - 1444.5= 1518.5 \\\\ \\text{OR} \\\\ \\text{extremes} > Q_{3} + * 1.5 = 3926 + 1444.5 = 5370.5 There are no observations lower than 1518.5 or higher than 5370.5 , so there are no \"extreme\" observations.","title":"d) Inter Quartile Range(IQR)"},{"location":"chapter_1/#e-the-coefficient-of-variations","text":"What are the coefficient of variations in the two groups? V = \\frac{s}{\\bar{x}} V = \\frac{s}{\\bar{x}} Females $$ V = \\frac{587.2993}{3361.1}= 0.1747 $$ Males V = \\frac{532.1261}{3475.2} = 0.153121 V = \\frac{532.1261}{3475.2} = 0.153121","title":"e) The coefficient of variations"},{"location":"chapter_1/#12-course-grades","text":"To compare the difficulty of 2 different courses at a university the following grades distributions (given as number of pupils who achieved the grades) were registered: Grade Course 1 Course 2 Total Grade 12 20 14 34 Grade 10 14 14 28 Grade 7 16 27 43 Grade 4 20 22 42 Grade 2 12 27 39 Grade 0 16 17 33 Grade 12 10 22 32","title":"1.2 Course grades"},{"location":"chapter_1/#a-median","text":"What is the median of the 251 achieved grades? 4","title":"a) Median"},{"location":"chapter_1/#b-quartiles-and-iqr","text":"What are the quartiles and the IQR (Inter Quartile Range)? Q_{0} = q_{0} = x_{1} = -3\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{251}{100} = x_{\\lceil{62.75}\\rceil}} = x_{63} = 0 \\\\ Q_{2} = q_{0.50}= \\frac{x_{125}+ x_{126}}{2} = \\frac{4+4}{2} = 4 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{251}{100}} = x_{{\\lceil{188.25}\\rceil}} = x_{189} = 7 \\\\ Q_{4} = q_{1} = x_{10} = 12\\\\ IQR = q_{0.75}- q_{0.25} = 7 - 0 = 7 \\\\ Q_{0} = q_{0} = x_{1} = -3\\\\ Q_{1} = q_{0.25}= x_{25*\\frac{251}{100} = x_{\\lceil{62.75}\\rceil}} = x_{63} = 0 \\\\ Q_{2} = q_{0.50}= \\frac{x_{125}+ x_{126}}{2} = \\frac{4+4}{2} = 4 \\\\ Q_{3} = q_{0.75} = x_{75*\\frac{251}{100}} = x_{{\\lceil{188.25}\\rceil}} = x_{189} = 7 \\\\ Q_{4} = q_{1} = x_{10} = 12\\\\ IQR = q_{0.75}- q_{0.25} = 7 - 0 = 7 \\\\","title":"b) Quartiles and IQR"},{"location":"chapter_1/#13-cholesterol","text":"In a clinical trial of a cholesterol-lowering agent, 15 patients\u2019 cholesterol (in mmol L^{-1} L^{-1} ) was measured before treatment and 3 weeks after starting treatment. Data is listed in the following table: Patient No. Before After 1 9.1 8.2 2 8.0 6.4 3 7.7 6.6 4 10.0 8.5 5 9.6 8.0 6 7.9 5.8 7 9.0 7.8 8 7.1 7.2 9 8.3 6.7 10 9.6 9.8 11 8.2 7.1 12 9.2 7.7 13 7.3 6.0 14 8.5 6.6 15 9.5 8.4","title":"1.3 Cholesterol"},{"location":"chapter_1/#a-medians","text":"What is the median of the cholesterol measurements for the patients before treatment, and similarly after treatment? \\bar{b} = 8.5 \\\\ \\bar{a} = 7.2 \\bar{b} = 8.5 \\\\ \\bar{a} = 7.2","title":"a) Medians"},{"location":"chapter_1/#b-standard-deviation","text":"Find the standard deviations of the cholesterol measurements of the patients before and after treatment. s_{b} = 0.9023778 \\\\ s_{a} = 1.090129 s_{b} = 0.9023778 \\\\ s_{a} = 1.090129","title":"b) Standard deviation"},{"location":"chapter_1/#c-sample-covariance","text":"Find the sample covariance between cholesterol measurements of the patients before and after treatment. By Definition 1.18 s_{ab} = \\frac{1}{n-1}\\sum_{i=1}^{n}{(b_{i}-\\bar{b})(a_{i}-\\bar{a})} = 0.7964286 s_{ab} = \\frac{1}{n-1}\\sum_{i=1}^{n}{(b_{i}-\\bar{b})(a_{i}-\\bar{a})} = 0.7964286","title":"c) Sample covariance"},{"location":"chapter_1/#d-correlation","text":"Find the sample correlation between cholesterol measurements of the patients before and after treatment. r = \\frac{s_{ba}}{s_{b}*s_{a}} = 0.8096188 r = \\frac{s_{ba}}{s_{b}*s_{a}} = 0.8096188","title":"d) Correlation"},{"location":"chapter_1/#e-differences","text":"Compute the 15 differences (Dif = Before \u2212 After) and do various summary statistics and plotting of these: sample mean, sample variance, sample standard deviation, boxplot etc. before <- c ( 9.1 , 8.0 , 7.7 , 10.0 , 9.6 , 7.9 , 9.0 , 7.1 , 8.3 , 9.6 , 8.2 , 9.2 , 7.3 , 8.5 , 9.5 ) after <- c ( 8.2 , 6.4 , 6.6 , 8.5 , 8.0 , 5.8 , 7.8 , 7.2 , 6.7 , 9.8 , 7.1 , 7.7 , 6.0 , 6.6 , 8.4 ) diffBeforeAfter <- before - after mean ( diffBeforeAfter ) median ( diffBeforeAfter ) var ( diffBeforeAfter ) sd ( diffBeforeAfter ) quantile ( diffBeforeAfter ) # precentiles boxplot ( diffBeforeAfter , col = \"red\" ) text ( 1.3 , quantile ( diffBeforeAfter ), c ( \"Minimum\" , \"Q1\" , \"Median\" , \"Q3\" , \"Maximum\" ), col = \"blue\" )","title":"e) Differences"},{"location":"chapter_1/#f-formal-answer","text":"Observing such data the big question is whether an average decrease in cholesterol level can be \u201cshown statistically\u201d. How to formally answer this question is presented in Chapter 3, but consider now which summary statistics and/or plots would you look at to have some idea of what the answer will be? I would answer something like this: the most patients decreased cholesterol level between 1.1 and 1.6, which is Inner Quartile Range (IQR). However the worst result recorded is -0.2 and the best is 2.1. Lastly the mean is 1.21 and the median is 1.3.","title":"f) Formal answer"},{"location":"chapter_2/","text":"2 Probability: Discrete 2.1 Discrete random variable a) Let X be a stochastic variable. When running the R-command dbinom(4,10,0.6) R returns 0.1115, written as: dbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1115 What distribution is applied and what does 0.1115 represent? Binomial distribution is applied Shows the density or probability of 4 successes in 10 trails with each probability 0.6 b) Let X be the same stochastic variable as above. The following are results from : pbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1662 pbinom ( 5 , 10 , 0.6 ) [ 1 ] 0.3669 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007 P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007 c ) Let X be a stochastic variable. From R we get: dpois ( 4 , 3 ) [ 1 ] 0.168 What distribution is applied and what does 0.168 represent? Poisson distribution The probability of 4 events to happen with rate 3 in given interval. d) Let X be the same stochastic variable as above. The following are results from R: ppois ( 4 , 3 ) [ 1 ] 0.8153 ppois ( 5 , 3 ) [ 1 ] 0.9161 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008 P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008 2.4 Consumer survey In a consumer survey performed by a newspaper, 20 different groceries (products) were purchased in a grocery store. Discrepancies between the price appearing on the sales slip and the shelf price were found in 6 of these purchased products. a) At the same time a customer buys 3 random (different) products within the group consisting of the 20 goods in the store. The probability that no discrepancies occurs for this customer is? Hyper-geometric distribution 0 - the desired number of successes (discrepancies) 6 - total number of successes (discrepancies) in the population 14 - total number of not discrepancies 3 - tries without replacement > dhyper ( 0 , 6 , 14 , 3 ) [ 1 ] 0.3192982 2.5 Hay delivery quality A horse owner receives 20 bales of hay in a sealed plastic packaging. To control the hay, 3 bales of hay are randomly selected, and each checked whether it contains harmful fungal spores. It is believed that among the 20 bales of hay 2 bales are infected with fungal spores. A random variable X describes the number of infected bales of hay among the three selected. a) The mean of X, ( \\mu_{X} \\mu_{X} ), the variance of X, ( \\sigma^2_{X} \\sigma^2_{X} ) and P ( X \u2265 1 ) are? We know that: Hyper-geometric distribution n = 3 - draws without replacement a = 2 - the number of successes in the large population N = 20 - elements in the large population So: \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843 \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843 b) Another supplier advertises that no more than 1% of his bales of hay are infected. The horse owner buys 10 bales of hay from this supplier, and decides to buy hay for the rest of the season from this supplier if the 10 bales are error-free. What is the probability that the 10 purchased bales of hay are error-free, if 1% of the bales from a supplier are infected ( p_{1} p_{1} ) and the probability that the 10 purchased bales of hay are error-free, if 10% of the bales from a supplier are infected ( p_{10} p_{10} ) ? The difference from a) is that in a) we picked only 3 from 20 and needed to find probability only in this amount, but here we have probability of event and number of events. > dbinom ( 0 , 10 , 0.01 ) [ 1 ] 0.9043821 > dbinom ( 0 , 10 , 0.1 ) [ 1 ] 0.3486784 2.7 A fully automated production On a large fully automated production plant items are pushed to a side band at random time points, from which they are automatically fed to a control unit. The production plant is set up in such a way that the number of items sent to the control unit on average is 1.6 item pr. minute. Let the random variable X denote the number of items pushed to the side band in 1 minute. It is assumed that X follows a Poisson distribution. a) What is the probability that there will arrive more than 5 items at the control unit in a given minute is? X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 > 1 - ppois ( 5 , 1.6 ) [ 1 ] 0.006040291 b) What is the probability that no more than 8 items arrive to the control unit within a 5-minute period? \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 > ppois ( 8 , 8 ) [ 1 ] 0.5925473 2.8 Call center staff The staffing for answering calls in a company is based on that there will be 180 phone calls per hour randomly distributed. If there are 20 calls or more in a period of 5 minutes the capacity is exceeded, and there will be an unwanted waiting time, hence there is a capacity of 19 calls per 5 minutes. a) What is the probability that the capacity is exceeded in a random period of 5 minutes? \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 > 1 - ppois ( 19 , 15 ) [ 1 ] 0.1247812 b) If the probability should be at least 99% that all calls will be handled without waiting time for a randomly selected period of 5 minutes, how large should the capacity per 5 minutes then at least be? The 0.99 quantile of the number of calls is at 25, so 99% of all randomly selected periods of 5 minutes will have at maximum 25 calls, so therefore the capacity should be 25 calls per 5 minutes. q_{0.99} = 25 q_{0.99} = 25 > qpois ( 0.99 , 15 ) [ 1 ] 25 2.9 Continuous random variable a) The following R commands and results are given: pnorm ( 2 ) [ 1 ] 0.9772 pnorm ( 2 , 1 , 1 ) [ 1 ] 0.8413 pnorm ( 2 , 1 , 2 ) [ 1 ] 0.6915 Specify which distributionsare used and explain the resulting probabili- ties (preferably by a sketch). Normal distribution pnorm(2) shows cdf for standard normal distribution: $$ Z \\sim N(0,1) \\ \\text{,where } \\mu = 0 , \\sigma^2 = 1\\ F(2) = 0.9772 $$ pnorm(2,1,1) shows cdf for X: X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 - pnorm(2,1,2) shows cdf for Y: $$ Y \\sim N(1,4)\\ \\text{,where } \\mu = 1 , \\sigma^2 = 4\\ F(2) = 0.6915 $$ Note that the graph has been scaled. b) What is the result of the following command: qnorm(pnorm(2)) ? pnorm gives \"a distance\" up to F(2) , which is 0.9772499. We can use \"that distance\" in qnorm function to find a value again, which is 2. (See Figure 2.2 in the book for more) > pnorm ( 2 ) [ 1 ] 0.9772499 > qnorm ( pnorm ( 2 )) [ 1 ] 2 c) State what the numbers represent in the three cases. First case qnorm ( 0.975 ) [ 1 ] 1.96 N(0,1) has the 97,5% quantile at x=1.96 Second case qnorm ( 0.975 , 1 , 1 ) [ 1 ] 2.96 N(1,1) has the 97,5% quantile at x=2.96 Third case qnorm ( 0.975 , 1 , 2 ) [ 1 ] 4.92 N(1,4) has the 97,5% quantile at x=4.92 2.10 The normal pdf a) Which of the following statements regarding the probability density function of the normal distribution N(1, 2^2) is false? The total area under the curve is equal to 1.0 The mean is equal to 1^2 The variance is equal to 2 . Variance is equal to 4, because standard deviation is equal to 2: N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} The curve is symmetric about the mean. The two tails of the curve extend indefinitely. b) Let X be normally distributed with mean 24 and variance 16. Calculate the following probabilities: P(X\\leqslant20) = 0.1586553 P(X\\leqslant20) = 0.1586553 > pnorm ( 20 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.1586553 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 > 1 - pnorm ( 29.5 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.08456572 P(X=23.8) = 0.09961098 P(X=23.8) = 0.09961098 > dnorm ( 23.8 , mean = 24 , sd = sqrt ( 16 )) [ 1 ] 0.09961098 2.11 Computer chip control A machine for checking computer chips uses on average 65 milliseconds per check with a standard deviation of 4 milliseconds. A newer machine, potentially to be bought, uses on average 54 milliseconds per check with a standard deviation of 3 milliseconds. It can be used that check times can be assumed normally distributed and independent. a) What is the probability that the time savings per check using the new machine is less than 10 milliseconds is? By theorem 2.40 and example 2.41: X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 > pnorm ( 10 , 11 , sqrt ( 25 )) [ 1 ] 0.4207403 Note that it does not matter in continuous distributions if we use < < or \\leqslant \\leqslant in order to define the probability. b) What is the mean and standard deviation for the total time use for checking 100 chips on the new machine is? By theorem 2.56: Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30 Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30 2.12 Concrete items A manufacturer of concrete items knows that the length (L) of his items are reasonably normally distributed with muL = 3000 mm and sigmaL = 3 mm. The requirement for these elements is that the length should be not more than 3007 mm and the length must be at least 2993 mm. a) The expected error rate in the manufacturing will be? The expected error rate is the probability of manufacturing an item shorter than 2993 and longer than 3007, so: L \\sim (3000, 9)\\\\ L \\sim (3000, 9)\\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 > pnorm ( 3007 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.9901847 > pnorm ( 2993 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.009815329 b) The concrete items are supported by beams, where the distance between the beams is called Lbeam and can be assumed normal distributed. The concrete items length is still called L. For the items to be supported correctly, the following requirements for these lengths must be fulfilled: 90mm < L - Lbeam < 110 mm. It is assumed that the mean of the distance between the beams is mbeam = 2900 mm. How large may the standard deviation sigmabeam of the distance between the beams be if you want the requirement fulfilled in 99% of the cases? Find: \\sigma_{beam} \\sigma_{beam} Needs be fulfilled: P(90<L-L_{beam}<110) = 0.99 P(90<L-L_{beam}<110) = 0.99 We know: L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ We can draw a graph like this, because 99% of all distances should between 90 and 110. So there is only 0.5% left in each side, that the 0.005 quantile is at 90 and the 0.995 quantile is at 110: We can also write this like following: P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ We can use theorem 2.43 in order to find a standard deviation of the distance, because the value of the standardized normal random variable at 0.005 quantile should be equal to the transformed distance variable: z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} And the same at 0.995 quantile: z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} We choose the second equation: z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} > qnorm ( 0.995 ) [ 1 ] 2.575829 So the result is: \\sigma_{beam} = 2.464107 \\sigma_{beam} = 2.464107 2.13 Online statistic video views In 2013, there were 110,000 views of the DTU statistics videos that are available online. Assume first that the occurrence of views through 2014 follows a Poisson process with a 2013 average: \\lambda_{365days} = 110000 \\lambda_{365days} = 110000 . a) What is the probability that in a randomly chosen half an hour there is no occurrence of views? Here we can use either Exponential distribution or Poisson to find the probability. - Poisson distribution \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 > dpois ( x = 0 , lambda = 6.278539 ) [ 1 ] 0.00187614 Exponential distribution X \\sim Exp(\\lambda_{365days}=110000) \\\\ X \\sim Exp(\\lambda_{365days}=110000) \\\\ 0 event between now and 30 min is given by: $$ P(X>\\frac{30}{365*24*60}) = $$ or can be written as 1 minus the probability of occurring next event between now and 30min $$ = 1 - P(X\\leqslant\\frac{30}{365*24*60}) = 0.00187614 $$ > 1 - pexp ( q = 30 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.00187614 b) There has just been a view, what is the probability that you have to wait more than fifteen minutes for the next view? 0 events between now and 15min is given by: P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 > 1 - pexp ( q = 15 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.04331443","title":"2 Probability: Discrete"},{"location":"chapter_2/#2-probability-discrete","text":"","title":"2 Probability: Discrete"},{"location":"chapter_2/#21-discrete-random-variable","text":"","title":"2.1 Discrete random variable"},{"location":"chapter_2/#a","text":"Let X be a stochastic variable. When running the R-command dbinom(4,10,0.6) R returns 0.1115, written as: dbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1115 What distribution is applied and what does 0.1115 represent? Binomial distribution is applied Shows the density or probability of 4 successes in 10 trails with each probability 0.6","title":"a)"},{"location":"chapter_2/#b","text":"Let X be the same stochastic variable as above. The following are results from : pbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1662 pbinom ( 5 , 10 , 0.6 ) [ 1 ] 0.3669 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007 P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007","title":"b)"},{"location":"chapter_2/#c","text":"Let X be a stochastic variable. From R we get: dpois ( 4 , 3 ) [ 1 ] 0.168 What distribution is applied and what does 0.168 represent? Poisson distribution The probability of 4 events to happen with rate 3 in given interval.","title":"c )"},{"location":"chapter_2/#d","text":"Let X be the same stochastic variable as above. The following are results from R: ppois ( 4 , 3 ) [ 1 ] 0.8153 ppois ( 5 , 3 ) [ 1 ] 0.9161 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008 P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008","title":"d)"},{"location":"chapter_2/#24-consumer-survey","text":"In a consumer survey performed by a newspaper, 20 different groceries (products) were purchased in a grocery store. Discrepancies between the price appearing on the sales slip and the shelf price were found in 6 of these purchased products.","title":"2.4 Consumer survey"},{"location":"chapter_2/#a_1","text":"At the same time a customer buys 3 random (different) products within the group consisting of the 20 goods in the store. The probability that no discrepancies occurs for this customer is? Hyper-geometric distribution 0 - the desired number of successes (discrepancies) 6 - total number of successes (discrepancies) in the population 14 - total number of not discrepancies 3 - tries without replacement > dhyper ( 0 , 6 , 14 , 3 ) [ 1 ] 0.3192982","title":"a)"},{"location":"chapter_2/#25-hay-delivery-quality","text":"A horse owner receives 20 bales of hay in a sealed plastic packaging. To control the hay, 3 bales of hay are randomly selected, and each checked whether it contains harmful fungal spores. It is believed that among the 20 bales of hay 2 bales are infected with fungal spores. A random variable X describes the number of infected bales of hay among the three selected.","title":"2.5 Hay delivery quality"},{"location":"chapter_2/#a_2","text":"The mean of X, ( \\mu_{X} \\mu_{X} ), the variance of X, ( \\sigma^2_{X} \\sigma^2_{X} ) and P ( X \u2265 1 ) are? We know that: Hyper-geometric distribution n = 3 - draws without replacement a = 2 - the number of successes in the large population N = 20 - elements in the large population So: \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843 \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843","title":"a)"},{"location":"chapter_2/#b_1","text":"Another supplier advertises that no more than 1% of his bales of hay are infected. The horse owner buys 10 bales of hay from this supplier, and decides to buy hay for the rest of the season from this supplier if the 10 bales are error-free. What is the probability that the 10 purchased bales of hay are error-free, if 1% of the bales from a supplier are infected ( p_{1} p_{1} ) and the probability that the 10 purchased bales of hay are error-free, if 10% of the bales from a supplier are infected ( p_{10} p_{10} ) ? The difference from a) is that in a) we picked only 3 from 20 and needed to find probability only in this amount, but here we have probability of event and number of events. > dbinom ( 0 , 10 , 0.01 ) [ 1 ] 0.9043821 > dbinom ( 0 , 10 , 0.1 ) [ 1 ] 0.3486784","title":"b)"},{"location":"chapter_2/#27-a-fully-automated-production","text":"On a large fully automated production plant items are pushed to a side band at random time points, from which they are automatically fed to a control unit. The production plant is set up in such a way that the number of items sent to the control unit on average is 1.6 item pr. minute. Let the random variable X denote the number of items pushed to the side band in 1 minute. It is assumed that X follows a Poisson distribution.","title":"2.7 A fully automated production"},{"location":"chapter_2/#a_3","text":"What is the probability that there will arrive more than 5 items at the control unit in a given minute is? X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 > 1 - ppois ( 5 , 1.6 ) [ 1 ] 0.006040291","title":"a)"},{"location":"chapter_2/#b_2","text":"What is the probability that no more than 8 items arrive to the control unit within a 5-minute period? \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 > ppois ( 8 , 8 ) [ 1 ] 0.5925473","title":"b)"},{"location":"chapter_2/#28-call-center-staff","text":"The staffing for answering calls in a company is based on that there will be 180 phone calls per hour randomly distributed. If there are 20 calls or more in a period of 5 minutes the capacity is exceeded, and there will be an unwanted waiting time, hence there is a capacity of 19 calls per 5 minutes.","title":"2.8 Call center staff"},{"location":"chapter_2/#a_4","text":"What is the probability that the capacity is exceeded in a random period of 5 minutes? \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 > 1 - ppois ( 19 , 15 ) [ 1 ] 0.1247812","title":"a)"},{"location":"chapter_2/#b_3","text":"If the probability should be at least 99% that all calls will be handled without waiting time for a randomly selected period of 5 minutes, how large should the capacity per 5 minutes then at least be? The 0.99 quantile of the number of calls is at 25, so 99% of all randomly selected periods of 5 minutes will have at maximum 25 calls, so therefore the capacity should be 25 calls per 5 minutes. q_{0.99} = 25 q_{0.99} = 25 > qpois ( 0.99 , 15 ) [ 1 ] 25","title":"b)"},{"location":"chapter_2/#29-continuous-random-variable","text":"","title":"2.9 Continuous random variable"},{"location":"chapter_2/#a_5","text":"The following R commands and results are given: pnorm ( 2 ) [ 1 ] 0.9772 pnorm ( 2 , 1 , 1 ) [ 1 ] 0.8413 pnorm ( 2 , 1 , 2 ) [ 1 ] 0.6915 Specify which distributionsare used and explain the resulting probabili- ties (preferably by a sketch). Normal distribution pnorm(2) shows cdf for standard normal distribution: $$ Z \\sim N(0,1) \\ \\text{,where } \\mu = 0 , \\sigma^2 = 1\\ F(2) = 0.9772 $$ pnorm(2,1,1) shows cdf for X: X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 - pnorm(2,1,2) shows cdf for Y: $$ Y \\sim N(1,4)\\ \\text{,where } \\mu = 1 , \\sigma^2 = 4\\ F(2) = 0.6915 $$ Note that the graph has been scaled.","title":"a)"},{"location":"chapter_2/#b_4","text":"What is the result of the following command: qnorm(pnorm(2)) ? pnorm gives \"a distance\" up to F(2) , which is 0.9772499. We can use \"that distance\" in qnorm function to find a value again, which is 2. (See Figure 2.2 in the book for more) > pnorm ( 2 ) [ 1 ] 0.9772499 > qnorm ( pnorm ( 2 )) [ 1 ] 2","title":"b)"},{"location":"chapter_2/#c_1","text":"State what the numbers represent in the three cases. First case qnorm ( 0.975 ) [ 1 ] 1.96 N(0,1) has the 97,5% quantile at x=1.96 Second case qnorm ( 0.975 , 1 , 1 ) [ 1 ] 2.96 N(1,1) has the 97,5% quantile at x=2.96 Third case qnorm ( 0.975 , 1 , 2 ) [ 1 ] 4.92 N(1,4) has the 97,5% quantile at x=4.92","title":"c)"},{"location":"chapter_2/#210-the-normal-pdf","text":"","title":"2.10 The normal pdf"},{"location":"chapter_2/#a_6","text":"Which of the following statements regarding the probability density function of the normal distribution N(1, 2^2) is false? The total area under the curve is equal to 1.0 The mean is equal to 1^2 The variance is equal to 2 . Variance is equal to 4, because standard deviation is equal to 2: N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} The curve is symmetric about the mean. The two tails of the curve extend indefinitely.","title":"a)"},{"location":"chapter_2/#b_5","text":"Let X be normally distributed with mean 24 and variance 16. Calculate the following probabilities: P(X\\leqslant20) = 0.1586553 P(X\\leqslant20) = 0.1586553 > pnorm ( 20 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.1586553 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 > 1 - pnorm ( 29.5 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.08456572 P(X=23.8) = 0.09961098 P(X=23.8) = 0.09961098 > dnorm ( 23.8 , mean = 24 , sd = sqrt ( 16 )) [ 1 ] 0.09961098","title":"b)"},{"location":"chapter_2/#211-computer-chip-control","text":"A machine for checking computer chips uses on average 65 milliseconds per check with a standard deviation of 4 milliseconds. A newer machine, potentially to be bought, uses on average 54 milliseconds per check with a standard deviation of 3 milliseconds. It can be used that check times can be assumed normally distributed and independent.","title":"2.11 Computer chip control"},{"location":"chapter_2/#a_7","text":"What is the probability that the time savings per check using the new machine is less than 10 milliseconds is? By theorem 2.40 and example 2.41: X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 > pnorm ( 10 , 11 , sqrt ( 25 )) [ 1 ] 0.4207403 Note that it does not matter in continuous distributions if we use < < or \\leqslant \\leqslant in order to define the probability.","title":"a)"},{"location":"chapter_2/#b_6","text":"What is the mean and standard deviation for the total time use for checking 100 chips on the new machine is? By theorem 2.56: Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30 Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30","title":"b)"},{"location":"chapter_2/#212-concrete-items","text":"A manufacturer of concrete items knows that the length (L) of his items are reasonably normally distributed with muL = 3000 mm and sigmaL = 3 mm. The requirement for these elements is that the length should be not more than 3007 mm and the length must be at least 2993 mm.","title":"2.12 Concrete items"},{"location":"chapter_2/#a_8","text":"The expected error rate in the manufacturing will be? The expected error rate is the probability of manufacturing an item shorter than 2993 and longer than 3007, so: L \\sim (3000, 9)\\\\ L \\sim (3000, 9)\\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 > pnorm ( 3007 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.9901847 > pnorm ( 2993 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.009815329","title":"a)"},{"location":"chapter_2/#b_7","text":"The concrete items are supported by beams, where the distance between the beams is called Lbeam and can be assumed normal distributed. The concrete items length is still called L. For the items to be supported correctly, the following requirements for these lengths must be fulfilled: 90mm < L - Lbeam < 110 mm. It is assumed that the mean of the distance between the beams is mbeam = 2900 mm. How large may the standard deviation sigmabeam of the distance between the beams be if you want the requirement fulfilled in 99% of the cases? Find: \\sigma_{beam} \\sigma_{beam} Needs be fulfilled: P(90<L-L_{beam}<110) = 0.99 P(90<L-L_{beam}<110) = 0.99 We know: L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ We can draw a graph like this, because 99% of all distances should between 90 and 110. So there is only 0.5% left in each side, that the 0.005 quantile is at 90 and the 0.995 quantile is at 110: We can also write this like following: P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ We can use theorem 2.43 in order to find a standard deviation of the distance, because the value of the standardized normal random variable at 0.005 quantile should be equal to the transformed distance variable: z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} And the same at 0.995 quantile: z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} We choose the second equation: z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} > qnorm ( 0.995 ) [ 1 ] 2.575829 So the result is: \\sigma_{beam} = 2.464107 \\sigma_{beam} = 2.464107","title":"b)"},{"location":"chapter_2/#213-online-statistic-video-views","text":"In 2013, there were 110,000 views of the DTU statistics videos that are available online. Assume first that the occurrence of views through 2014 follows a Poisson process with a 2013 average: \\lambda_{365days} = 110000 \\lambda_{365days} = 110000 .","title":"2.13 Online statistic video views"},{"location":"chapter_2/#a_9","text":"What is the probability that in a randomly chosen half an hour there is no occurrence of views? Here we can use either Exponential distribution or Poisson to find the probability. - Poisson distribution \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 > dpois ( x = 0 , lambda = 6.278539 ) [ 1 ] 0.00187614 Exponential distribution X \\sim Exp(\\lambda_{365days}=110000) \\\\ X \\sim Exp(\\lambda_{365days}=110000) \\\\ 0 event between now and 30 min is given by: $$ P(X>\\frac{30}{365*24*60}) = $$ or can be written as 1 minus the probability of occurring next event between now and 30min $$ = 1 - P(X\\leqslant\\frac{30}{365*24*60}) = 0.00187614 $$ > 1 - pexp ( q = 30 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.00187614","title":"a)"},{"location":"chapter_2/#b_8","text":"There has just been a view, what is the probability that you have to wait more than fifteen minutes for the next view? 0 events between now and 15min is given by: P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 > 1 - pexp ( q = 15 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.04331443","title":"b)"},{"location":"chapter_2_1/","text":"2 Probability: Discrete 2.1 Discrete random variable a) Let X be a stochastic variable. When running the R-command dbinom(4,10,0.6) R returns 0.1115, written as: dbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1115 What distribution is applied and what does 0.1115 represent? Binomial distribution is applied Shows the density or probability of 4 successes in 10 trails with each probability 0.6 b) Let X be the same stochastic variable as above. The following are results from : pbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1662 pbinom ( 5 , 10 , 0.6 ) [ 1 ] 0.3669 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007 P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007 c ) Let X be a stochastic variable. From R we get: dpois ( 4 , 3 ) [ 1 ] 0.168 What distribution is applied and what does 0.168 represent? Poisson distribution The probability of 4 events to happen with rate 3 in given interval. d) Let X be the same stochastic variable as above. The following are results from R: ppois ( 4 , 3 ) [ 1 ] 0.8153 ppois ( 5 , 3 ) [ 1 ] 0.9161 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008 P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008 2.4 Consumer survey In a consumer survey performed by a newspaper, 20 different groceries (products) were purchased in a grocery store. Discrepancies between the price appearing on the sales slip and the shelf price were found in 6 of these purchased products. a) At the same time a customer buys 3 random (different) products within the group consisting of the 20 goods in the store. The probability that no discrepancies occurs for this customer is? Hyper-geometric distribution 0 - the desired number of successes (discrepancies) 6 - total number of successes (discrepancies) in the population 14 - total number of not discrepancies 3 - tries without replacement > dhyper ( 0 , 6 , 14 , 3 ) [ 1 ] 0.3192982 2.5 Hay delivery quality A horse owner receives 20 bales of hay in a sealed plastic packaging. To control the hay, 3 bales of hay are randomly selected, and each checked whether it contains harmful fungal spores. It is believed that among the 20 bales of hay 2 bales are infected with fungal spores. A random variable X describes the number of infected bales of hay among the three selected. a) The mean of X, ( \\mu_{X} \\mu_{X} ), the variance of X, ( \\sigma^2_{X} \\sigma^2_{X} ) and P ( X \u2265 1 ) are? We know that: Hyper-geometric distribution n = 3 - draws without replacement a = 2 - the number of successes in the large population N = 20 - elements in the large population So: \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843 \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843 b) Another supplier advertises that no more than 1% of his bales of hay are infected. The horse owner buys 10 bales of hay from this supplier, and decides to buy hay for the rest of the season from this supplier if the 10 bales are error-free. What is the probability that the 10 purchased bales of hay are error-free, if 1% of the bales from a supplier are infected ( p_{1} p_{1} ) and the probability that the 10 purchased bales of hay are error-free, if 10% of the bales from a supplier are infected ( p_{10} p_{10} ) ? The difference from a) is that in a) we picked only 3 from 20 and needed to find probability only in this amount, but here we have probability of event and number of events. > dbinom ( 0 , 10 , 0.01 ) [ 1 ] 0.9043821 > dbinom ( 0 , 10 , 0.1 ) [ 1 ] 0.3486784 2.7 A fully automated production On a large fully automated production plant items are pushed to a side band at random time points, from which they are automatically fed to a control unit. The production plant is set up in such a way that the number of items sent to the control unit on average is 1.6 item pr. minute. Let the random variable X denote the number of items pushed to the side band in 1 minute. It is assumed that X follows a Poisson distribution. a) What is the probability that there will arrive more than 5 items at the control unit in a given minute is? X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 > 1 - ppois ( 5 , 1.6 ) [ 1 ] 0.006040291 b) What is the probability that no more than 8 items arrive to the control unit within a 5-minute period? \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 > ppois ( 8 , 8 ) [ 1 ] 0.5925473 2.8 Call center staff The staffing for answering calls in a company is based on that there will be 180 phone calls per hour randomly distributed. If there are 20 calls or more in a period of 5 minutes the capacity is exceeded, and there will be an unwanted waiting time, hence there is a capacity of 19 calls per 5 minutes. a) What is the probability that the capacity is exceeded in a random period of 5 minutes? \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 > 1 - ppois ( 19 , 15 ) [ 1 ] 0.1247812 b) If the probability should be at least 99% that all calls will be handled without waiting time for a randomly selected period of 5 minutes, how large should the capacity per 5 minutes then at least be? The 0.99 quantile of the number of calls is at 25, so 99% of all randomly selected periods of 5 minutes will have at maximum 25 calls, so therefore the capacity should be 25 calls per 5 minutes. q_{0.99} = 25 q_{0.99} = 25 > qpois ( 0.99 , 15 ) [ 1 ] 25","title":"2 Probability Discrete"},{"location":"chapter_2_1/#2-probability-discrete","text":"","title":"2 Probability: Discrete"},{"location":"chapter_2_1/#21-discrete-random-variable","text":"","title":"2.1 Discrete random variable"},{"location":"chapter_2_1/#a","text":"Let X be a stochastic variable. When running the R-command dbinom(4,10,0.6) R returns 0.1115, written as: dbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1115 What distribution is applied and what does 0.1115 represent? Binomial distribution is applied Shows the density or probability of 4 successes in 10 trails with each probability 0.6","title":"a)"},{"location":"chapter_2_1/#b","text":"Let X be the same stochastic variable as above. The following are results from : pbinom ( 4 , 10 , 0.6 ) [ 1 ] 0.1662 pbinom ( 5 , 10 , 0.6 ) [ 1 ] 0.3669 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007 P(X\\leqslant5) = 0.3669\\\\ P(X < 5 ) = 0.1662 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.1662 = 0.8338\\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.3669 - 0.1662 = 0.2007","title":"b)"},{"location":"chapter_2_1/#c","text":"Let X be a stochastic variable. From R we get: dpois ( 4 , 3 ) [ 1 ] 0.168 What distribution is applied and what does 0.168 represent? Poisson distribution The probability of 4 events to happen with rate 3 in given interval.","title":"c )"},{"location":"chapter_2_1/#d","text":"Let X be the same stochastic variable as above. The following are results from R: ppois ( 4 , 3 ) [ 1 ] 0.8153 ppois ( 5 , 3 ) [ 1 ] 0.9161 Calculate the following probabilities: P ( X \u2264 5 ) , P ( X < 5 ) , P ( X > 4 ) and P ( X = 5 ) . P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008 P(X\\leqslant5) = 0.9161 \\\\ P(X < 5 ) = 0.8153 \\\\ P(X>4) = 1 - P(X < 5 ) = 1 - 0.8153 = 0.1847 \\\\ P(X = 5) = P(X\\leqslant5) - P(X < 5 ) = 0.9161 - 0.8153 = 0.1008","title":"d)"},{"location":"chapter_2_1/#24-consumer-survey","text":"In a consumer survey performed by a newspaper, 20 different groceries (products) were purchased in a grocery store. Discrepancies between the price appearing on the sales slip and the shelf price were found in 6 of these purchased products.","title":"2.4 Consumer survey"},{"location":"chapter_2_1/#a_1","text":"At the same time a customer buys 3 random (different) products within the group consisting of the 20 goods in the store. The probability that no discrepancies occurs for this customer is? Hyper-geometric distribution 0 - the desired number of successes (discrepancies) 6 - total number of successes (discrepancies) in the population 14 - total number of not discrepancies 3 - tries without replacement > dhyper ( 0 , 6 , 14 , 3 ) [ 1 ] 0.3192982","title":"a)"},{"location":"chapter_2_1/#25-hay-delivery-quality","text":"A horse owner receives 20 bales of hay in a sealed plastic packaging. To control the hay, 3 bales of hay are randomly selected, and each checked whether it contains harmful fungal spores. It is believed that among the 20 bales of hay 2 bales are infected with fungal spores. A random variable X describes the number of infected bales of hay among the three selected.","title":"2.5 Hay delivery quality"},{"location":"chapter_2_1/#a_2","text":"The mean of X, ( \\mu_{X} \\mu_{X} ), the variance of X, ( \\sigma^2_{X} \\sigma^2_{X} ) and P ( X \u2265 1 ) are? We know that: Hyper-geometric distribution n = 3 - draws without replacement a = 2 - the number of successes in the large population N = 20 - elements in the large population So: \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843 \\mu = n \\frac{a}{N}= 3 * \\frac{2}{20} = 0.3 \\\\ \\sigma = n \\frac{a(N-a)}{N^2}*\\frac{N-n}{N-1} = 1.216 \\\\ P(X \\geqslant 1 ) = 1 - P(X = 0) = 1 - 0.7157 = 0.2843","title":"a)"},{"location":"chapter_2_1/#b_1","text":"Another supplier advertises that no more than 1% of his bales of hay are infected. The horse owner buys 10 bales of hay from this supplier, and decides to buy hay for the rest of the season from this supplier if the 10 bales are error-free. What is the probability that the 10 purchased bales of hay are error-free, if 1% of the bales from a supplier are infected ( p_{1} p_{1} ) and the probability that the 10 purchased bales of hay are error-free, if 10% of the bales from a supplier are infected ( p_{10} p_{10} ) ? The difference from a) is that in a) we picked only 3 from 20 and needed to find probability only in this amount, but here we have probability of event and number of events. > dbinom ( 0 , 10 , 0.01 ) [ 1 ] 0.9043821 > dbinom ( 0 , 10 , 0.1 ) [ 1 ] 0.3486784","title":"b)"},{"location":"chapter_2_1/#27-a-fully-automated-production","text":"On a large fully automated production plant items are pushed to a side band at random time points, from which they are automatically fed to a control unit. The production plant is set up in such a way that the number of items sent to the control unit on average is 1.6 item pr. minute. Let the random variable X denote the number of items pushed to the side band in 1 minute. It is assumed that X follows a Poisson distribution.","title":"2.7 A fully automated production"},{"location":"chapter_2_1/#a_3","text":"What is the probability that there will arrive more than 5 items at the control unit in a given minute is? X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 X \\sim Po(\\lambda^{min} = 1.6) \\\\ P(X>5) = 1 - P(X\\leqslant 5) = 0.006040291 > 1 - ppois ( 5 , 1.6 ) [ 1 ] 0.006040291","title":"a)"},{"location":"chapter_2_1/#b_2","text":"What is the probability that no more than 8 items arrive to the control unit within a 5-minute period? \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 \\lambda^{5min} = \\lambda{min} * 5 = 1.6 * 5 = 8 \\\\ P(X \\leqslant 8) = 0.5925473 > ppois ( 8 , 8 ) [ 1 ] 0.5925473","title":"b)"},{"location":"chapter_2_1/#28-call-center-staff","text":"The staffing for answering calls in a company is based on that there will be 180 phone calls per hour randomly distributed. If there are 20 calls or more in a period of 5 minutes the capacity is exceeded, and there will be an unwanted waiting time, hence there is a capacity of 19 calls per 5 minutes.","title":"2.8 Call center staff"},{"location":"chapter_2_1/#a_4","text":"What is the probability that the capacity is exceeded in a random period of 5 minutes? \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 \\lambda^{5min}=\\frac{\\lambda^{60min}}{12}=\\frac{180}{12}= 15 \\\\ P(X\\geqslant20) = 1 - P(X<19) = 1 - 0.8752188 = 0.1247812 > 1 - ppois ( 19 , 15 ) [ 1 ] 0.1247812","title":"a)"},{"location":"chapter_2_1/#b_3","text":"If the probability should be at least 99% that all calls will be handled without waiting time for a randomly selected period of 5 minutes, how large should the capacity per 5 minutes then at least be? The 0.99 quantile of the number of calls is at 25, so 99% of all randomly selected periods of 5 minutes will have at maximum 25 calls, so therefore the capacity should be 25 calls per 5 minutes. q_{0.99} = 25 q_{0.99} = 25 > qpois ( 0.99 , 15 ) [ 1 ] 25","title":"b)"},{"location":"chapter_2_2/","text":"2 Probability: Continuous 2.9 Continuous random variable a) The following R commands and results are given: pnorm ( 2 ) [ 1 ] 0.9772 pnorm ( 2 , 1 , 1 ) [ 1 ] 0.8413 pnorm ( 2 , 1 , 2 ) [ 1 ] 0.6915 Specify which distributionsare used and explain the resulting probabili- ties (preferably by a sketch). Normal distribution pnorm(2) shows cdf for standard normal distribution: $$ Z \\sim N(0,1) \\ \\text{,where } \\mu = 0 , \\sigma^2 = 1\\ F(2) = 0.9772 $$ pnorm(2,1,1) shows cdf for X: X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 pnorm(2,1,2) shows cdf for Y: $$ Y \\sim N(1,4)\\ \\text{,where } \\mu = 1 , \\sigma^2 = 4\\ F(2) = 0.6915 $$ Note that the graph has been scaled. b) What is the result of the following command: qnorm(pnorm(2)) ? pnorm gives \"a distance\" up to F(2) , which is 0.9772499. We can use \"that distance\" in qnorm function to find a value again, which is 2. (See Figure 2.2 in the book for more) > pnorm ( 2 ) [ 1 ] 0.9772499 > qnorm ( pnorm ( 2 )) [ 1 ] 2 c) State what the numbers represent in the three cases. First case qnorm ( 0.975 ) [ 1 ] 1.96 N(0,1) has the 97,5% quantile at x=1.96 Second case qnorm ( 0.975 , 1 , 1 ) [ 1 ] 2.96 N(1,1) has the 97,5% quantile at x=2.96 Third case qnorm ( 0.975 , 1 , 2 ) [ 1 ] 4.92 N(1,4) has the 97,5% quantile at x=4.92 2.10 The normal pdf a) Which of the following statements regarding the probability density function of the normal distribution N(1, 2^2) N(1, 2^2) is false? The total area under the curve is equal to 1.0 The mean is equal to 1^2 The variance is equal to 2. The curve is symmetric about the mean. The two tails of the curve extend indefinitely. Answer : 3 is false. Variance is equal to 4, because the standard deviation is equal to 2: N(1,2^2) \\text{,where }N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} N(1,2^2) \\text{,where }N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} b) Let X be normally distributed with mean 24 and variance 16. Calculate the following probabilities: P(X\\leqslant20) = 0.1586553 P(X\\leqslant20) = 0.1586553 > pnorm ( 20 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.1586553 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 > 1 - pnorm ( 29.5 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.08456572 P(X=23.8) = 0.09961098 P(X=23.8) = 0.09961098 > dnorm ( 23.8 , mean = 24 , sd = sqrt ( 16 )) [ 1 ] 0.09961098 2.11 Computer chip control A machine for checking computer chips uses on average 65 milliseconds per check with a standard deviation of 4 milliseconds. A newer machine, potentially to be bought, uses on average 54 milliseconds per check with a standard deviation of 3 milliseconds. It can be used that check times can be assumed normally distributed and independent. a) What is the probability that the time savings per check using the new machine is less than 10 milliseconds is? By theorem 2.40 and example 2.41: X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 > pnorm ( 10 , 11 , sqrt ( 25 )) [ 1 ] 0.4207403 Note that it does not matter in continuous distributions if we use < < or \\leqslant \\leqslant in order to define the probability. b) What is the mean and standard deviation for the total time use for checking 100 chips on the new machine is? By theorem 2.56: Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30 Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30 2.12 Concrete items A manufacturer of concrete items knows that the length (L) of his items are reasonably normally distributed with \\mu_{L} \\mu_{L} = 3000 mm and \\sigma_{L} \\sigma_{L} = 3 mm. The requirement for these elements is that the length should be not more than 3007 mm and the length must be at least 2993 mm. a) The expected error rate in the manufacturing will be? The expected error rate is the probability of manufacturing an item shorter than 2993 and longer than 3007, so: L \\sim (3000, 9)\\\\ L \\sim (3000, 9)\\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 > pnorm ( 3007 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.9901847 > pnorm ( 2993 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.009815329 b) The concrete items are supported by beams, where the distance between the beams is called L_{beam} L_{beam} and can be assumed normal distributed. The concrete items length is still called L L . For the items to be supported correctly, the following requirements for these lengths must be fulfilled: 90mm < L - L_{beam} L - L_{beam} < 110 mm. It is assumed that the mean of the distance between the beams is \\mu_{beam} \\mu_{beam} = 2900 mm. How large may the standard deviation \\sigma_{beam} \\sigma_{beam} of the distance between the beams be if you want the requirement fulfilled in 99% of the cases? Find: \\sigma_{beam} \\sigma_{beam} Needs be fulfilled: P(90<L-L_{beam}<110) = 0.99 P(90<L-L_{beam}<110) = 0.99 We know: L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ We can draw a graph like this, because 99% of all distances should between 90 and 110. So there is only 0.5% left in each side, that the 0.005 quantile is at 90 and the 0.995 quantile is at 110: We can also write this like following: P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ We can use theorem 2.43 in order to find a standard deviation of the distance, because the value of the standardized normal random variable at 0.005 quantile should be equal to the transformed distance variable: z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} And the same at 0.995 quantile: z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} We choose the second equation: z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} > qnorm ( 0.995 ) [ 1 ] 2.575829 So the result is: \\sigma_{beam} = 2.464107 \\sigma_{beam} = 2.464107 2.13 Online statistic video views In 2013, there were 110,000 views of the DTU statistics videos that are available online. Assume first that the occurrence of views through 2014 follows a Poisson process with a 2013 average: \\lambda_{365days} = 110000 \\lambda_{365days} = 110000 . a) What is the probability that in a randomly chosen half an hour there is no occurrence of views? Here we can use either Exponential distribution or Poisson to find the probability. - Poisson distribution \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 > dpois ( x = 0 , lambda = 6.278539 ) [ 1 ] 0.00187614 Exponential distribution X \\sim Exp(\\lambda_{365days}=110000) \\\\ X \\sim Exp(\\lambda_{365days}=110000) \\\\ 0 event between now and 30 min is given by: $$ P(X>\\frac{30}{365*24*60}) = $$ or can be written as 1 minus the probability of occurring next event between now and 30min $$ = 1 - P(X\\leqslant\\frac{30}{365*24*60}) = 0.00187614 $$ > 1 - pexp ( q = 30 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.00187614 b) There has just been a view, what is the probability that you have to wait more than fifteen minutes for the next view? 0 events between now and 15min is given by: P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 > 1 - pexp ( q = 15 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.04331443","title":"2 Probability Continuous"},{"location":"chapter_2_2/#2-probability-continuous","text":"","title":"2 Probability: Continuous"},{"location":"chapter_2_2/#29-continuous-random-variable","text":"","title":"2.9 Continuous random variable"},{"location":"chapter_2_2/#a","text":"The following R commands and results are given: pnorm ( 2 ) [ 1 ] 0.9772 pnorm ( 2 , 1 , 1 ) [ 1 ] 0.8413 pnorm ( 2 , 1 , 2 ) [ 1 ] 0.6915 Specify which distributionsare used and explain the resulting probabili- ties (preferably by a sketch). Normal distribution pnorm(2) shows cdf for standard normal distribution: $$ Z \\sim N(0,1) \\ \\text{,where } \\mu = 0 , \\sigma^2 = 1\\ F(2) = 0.9772 $$ pnorm(2,1,1) shows cdf for X: X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 X \\sim N(1,1)\\\\ \\text{,where } \\mu = 1 , \\sigma^2 = 1\\\\ F(2) = 0.8413 pnorm(2,1,2) shows cdf for Y: $$ Y \\sim N(1,4)\\ \\text{,where } \\mu = 1 , \\sigma^2 = 4\\ F(2) = 0.6915 $$ Note that the graph has been scaled.","title":"a)"},{"location":"chapter_2_2/#b","text":"What is the result of the following command: qnorm(pnorm(2)) ? pnorm gives \"a distance\" up to F(2) , which is 0.9772499. We can use \"that distance\" in qnorm function to find a value again, which is 2. (See Figure 2.2 in the book for more) > pnorm ( 2 ) [ 1 ] 0.9772499 > qnorm ( pnorm ( 2 )) [ 1 ] 2","title":"b)"},{"location":"chapter_2_2/#c","text":"State what the numbers represent in the three cases. First case qnorm ( 0.975 ) [ 1 ] 1.96 N(0,1) has the 97,5% quantile at x=1.96 Second case qnorm ( 0.975 , 1 , 1 ) [ 1 ] 2.96 N(1,1) has the 97,5% quantile at x=2.96 Third case qnorm ( 0.975 , 1 , 2 ) [ 1 ] 4.92 N(1,4) has the 97,5% quantile at x=4.92","title":"c)"},{"location":"chapter_2_2/#210-the-normal-pdf","text":"","title":"2.10 The normal pdf"},{"location":"chapter_2_2/#a_1","text":"Which of the following statements regarding the probability density function of the normal distribution N(1, 2^2) N(1, 2^2) is false? The total area under the curve is equal to 1.0 The mean is equal to 1^2 The variance is equal to 2. The curve is symmetric about the mean. The two tails of the curve extend indefinitely. Answer : 3 is false. Variance is equal to 4, because the standard deviation is equal to 2: N(1,2^2) \\text{,where }N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance} N(1,2^2) \\text{,where }N(\\mu, \\sigma^2) \\\\ \\sigma \\text{- standart deviation} \\\\ \\sigma^2 \\text{- variance}","title":"a)"},{"location":"chapter_2_2/#b_1","text":"Let X be normally distributed with mean 24 and variance 16. Calculate the following probabilities: P(X\\leqslant20) = 0.1586553 P(X\\leqslant20) = 0.1586553 > pnorm ( 20 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.1586553 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 P(X>29.5) = 1 - P(X\\leqslant29.5) = 0.08456572 > 1 - pnorm ( 29.5 , mean = 24 , sd = sqrt ( 16 ) ) [ 1 ] 0.08456572 P(X=23.8) = 0.09961098 P(X=23.8) = 0.09961098 > dnorm ( 23.8 , mean = 24 , sd = sqrt ( 16 )) [ 1 ] 0.09961098","title":"b)"},{"location":"chapter_2_2/#211-computer-chip-control","text":"A machine for checking computer chips uses on average 65 milliseconds per check with a standard deviation of 4 milliseconds. A newer machine, potentially to be bought, uses on average 54 milliseconds per check with a standard deviation of 3 milliseconds. It can be used that check times can be assumed normally distributed and independent.","title":"2.11 Computer chip control"},{"location":"chapter_2_2/#a_2","text":"What is the probability that the time savings per check using the new machine is less than 10 milliseconds is? By theorem 2.40 and example 2.41: X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 X \\sim N(65,16) \\\\ Y \\sim N(54,9) \\\\ Z = X - Y \\\\ \\mu_{Z} =\\mu_{X} - \\mu_{Y} = 65-54=11 \\\\ \\sigma^2_{Z} = \\sigma^2_{X}+\\sigma^2_{Y}= 16+9=25\\\\ Z\\sim N(11,25)\\\\ P(Z\\leqslant10)=0.4207403 > pnorm ( 10 , 11 , sqrt ( 25 )) [ 1 ] 0.4207403 Note that it does not matter in continuous distributions if we use < < or \\leqslant \\leqslant in order to define the probability.","title":"a)"},{"location":"chapter_2_2/#b_2","text":"What is the mean and standard deviation for the total time use for checking 100 chips on the new machine is? By theorem 2.56: Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30 Y \\sim N(54,9) \\\\ \\mu_{Z}= 100*E(X)= 100*54= 5400 \\\\ \\sigma_{Z} = \\sqrt{V(100X)} = \\sqrt{100*9} = 30","title":"b)"},{"location":"chapter_2_2/#212-concrete-items","text":"A manufacturer of concrete items knows that the length (L) of his items are reasonably normally distributed with \\mu_{L} \\mu_{L} = 3000 mm and \\sigma_{L} \\sigma_{L} = 3 mm. The requirement for these elements is that the length should be not more than 3007 mm and the length must be at least 2993 mm.","title":"2.12 Concrete items"},{"location":"chapter_2_2/#a_3","text":"The expected error rate in the manufacturing will be? The expected error rate is the probability of manufacturing an item shorter than 2993 and longer than 3007, so: L \\sim (3000, 9)\\\\ L \\sim (3000, 9)\\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(L>3007) = 1 - P(L<3007) \\\\ P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 P(2993>L>3007) = P(L>3007) + P(L<2993) = \\\\ (1 - P(L<3007)) + P(L<2993) = \\\\ (1-0.9901847) + 0.009815329 = 0.01963066 > pnorm ( 3007 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.9901847 > pnorm ( 2993 , mean = 3000 , sd = sqrt ( 9 )) [ 1 ] 0.009815329","title":"a)"},{"location":"chapter_2_2/#b_3","text":"The concrete items are supported by beams, where the distance between the beams is called L_{beam} L_{beam} and can be assumed normal distributed. The concrete items length is still called L L . For the items to be supported correctly, the following requirements for these lengths must be fulfilled: 90mm < L - L_{beam} L - L_{beam} < 110 mm. It is assumed that the mean of the distance between the beams is \\mu_{beam} \\mu_{beam} = 2900 mm. How large may the standard deviation \\sigma_{beam} \\sigma_{beam} of the distance between the beams be if you want the requirement fulfilled in 99% of the cases? Find: \\sigma_{beam} \\sigma_{beam} Needs be fulfilled: P(90<L-L_{beam}<110) = 0.99 P(90<L-L_{beam}<110) = 0.99 We know: L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ L\\sim(3000,9)\\\\ L_{beam} \\sim (2900, \\sigma^2_{beam}) \\\\ \\mu_{L-L_{beam}}=\\mu_{L}-\\mu_{beam}=3000-2900=100\\\\ \\sigma_{L-L_{beam}}=\\sqrt{9+\\sigma^2_{beam}}\\\\ We can draw a graph like this, because 99% of all distances should between 90 and 110. So there is only 0.5% left in each side, that the 0.005 quantile is at 90 and the 0.995 quantile is at 110: We can also write this like following: P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ P(90<L-L_{beam}<110) = P(L-L_{beam}<110) - P(L-L_{beam}<90) \\\\ P(L-L_{beam}<110) = 0.995 \\\\ P(L-L_{beam}<90) = 0.005 \\\\ We can use theorem 2.43 in order to find a standard deviation of the distance, because the value of the standardized normal random variable at 0.005 quantile should be equal to the transformed distance variable: z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.005} = \\frac{90-100}{\\sqrt{9+\\sigma^2_{beam}}} And the same at 0.995 quantile: z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995} = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} We choose the second equation: z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} z_{0.995}= 2.575829 \\\\ 2.575829 = \\frac{110-100}{\\sqrt{9+\\sigma^2_{beam}}} > qnorm ( 0.995 ) [ 1 ] 2.575829 So the result is: \\sigma_{beam} = 2.464107 \\sigma_{beam} = 2.464107","title":"b)"},{"location":"chapter_2_2/#213-online-statistic-video-views","text":"In 2013, there were 110,000 views of the DTU statistics videos that are available online. Assume first that the occurrence of views through 2014 follows a Poisson process with a 2013 average: \\lambda_{365days} = 110000 \\lambda_{365days} = 110000 .","title":"2.13 Online statistic video views"},{"location":"chapter_2_2/#a_4","text":"What is the probability that in a randomly chosen half an hour there is no occurrence of views? Here we can use either Exponential distribution or Poisson to find the probability. - Poisson distribution \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 \\lambda_{30min}= \\frac{110000*30}{365*24*60} = 6.278539 \\\\ X \\sim Po(\\lambda_{30min}= 6.278539 ) \\\\ P(X=0) = 0.00187614 > dpois ( x = 0 , lambda = 6.278539 ) [ 1 ] 0.00187614 Exponential distribution X \\sim Exp(\\lambda_{365days}=110000) \\\\ X \\sim Exp(\\lambda_{365days}=110000) \\\\ 0 event between now and 30 min is given by: $$ P(X>\\frac{30}{365*24*60}) = $$ or can be written as 1 minus the probability of occurring next event between now and 30min $$ = 1 - P(X\\leqslant\\frac{30}{365*24*60}) = 0.00187614 $$ > 1 - pexp ( q = 30 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.00187614","title":"a)"},{"location":"chapter_2_2/#b_4","text":"There has just been a view, what is the probability that you have to wait more than fifteen minutes for the next view? 0 events between now and 15min is given by: P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 P(X>\\frac{15}{365*24*60}) = \\\\ 1 - P(X\\leqslant\\frac{15}{365*24*60}) = 0.04331443 > 1 - pexp ( q = 15 / ( 365 * 24 * 60 ), rate = 110000 ) [ 1 ] 0.04331443","title":"b)"},{"location":"chapter_3_1/","text":"3 Confidence Intervals 3.1 Concrete items A construction company receives concrete items for a construction. The length of the items are assumed reasonably normally distributed. The following requirements for the length of the elements are made \\mu=3000mm \\mu=3000mm . The company samples 9 items from a delivery which are then measured for control. The following measurements (in mm) are found: 3003, 3005, 2997, 3006, 2999, 2998, 3007, 3005, 3001. a) Compute the following three statistics: the sample mean, the sample standard deviation and the standard error of the mean, and what are the interpretations of these statistics? \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ SE_{\\bar{x}}= \\frac{s}{\\sqrt{n}} = 1.236033 \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ SE_{\\bar{x}}= \\frac{s}{\\sqrt{n}} = 1.236033 > sample <- c ( 3003 , 3005 , 2997 , 3006 , 2999 , 2998 , 3007 , 3005 , 3001 ) > mean <- mean ( sample ) [ 1 ] 3002.333 > sd <- sd ( sample ) [ 1 ] 3.708099 > error <- sd / sqrt ( 9 ) [ 1 ] 1.236033 b) In a construction process, 5 concrete items are joined together to a single construction with a length which is then the complete length of the 5 concrete items. It is very important that the length of this new construction is within 15 m plus/minus 1 cm. How often will it happen that such a construction will be more than 1 cm away from the 15 m target (assume that the population mean concrete item length is \\mu \\mu = 3000 mm and that the population standard deviation is \\sigma \\sigma = 3)? Find: P(14990>L>15010) P(14990>L>15010) We know: L \\sim N(3000,3^2 ) \\\\ L^{scale} = 5L \\\\ L^{scale} \\sim N(15000, 45) L \\sim N(3000,3^2 ) \\\\ L^{scale} = 5L \\\\ L^{scale} \\sim N(15000, 45) Solution: $$ P(14990>L^{scale}>15010) = 2*P(L^{scale}<14990) = 0.1360371 \\ $$ > 2 * pnorm ( 14990 , mean = 15000 , sd = sqrt ( 45 )) [ 1 ] 0.1360371 c) Find the 95% confidence interval for the mean \\mu \\mu . \\bar{x}\\pm t_{0.975}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 2.306*1.236 = \\\\ = 3002.333 \\pm 2.850216 = [ 2999.483, 3005.184] \\bar{x}\\pm t_{0.975}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 2.306*1.236 = \\\\ = 3002.333 \\pm 2.850216 = [ 2999.483, 3005.184] > qt ( 0.975 , 9-1 ) [ 1 ] 2.306004 d) Find the 99% confidence interval for \\mu \\mu . Compare with the 95% one from above and explain why it is smaller/larger! \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 3.355387*1.236 = \\\\ = 3002.333 \\pm 4.147258 = [2998.186, 3006.48] \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 3.355387*1.236 = \\\\ = 3002.333 \\pm 4.147258 = [2998.186, 3006.48] > qt ( 0.995 , 9-1 ) [ 1 ] 3.355387 It is larger, because in this case 99% of all CI's should contain the true mean. So that means, if we want a higher likelihood, that the CI contains the population mean, so we should make the CI larger. e) Find the 95% confidence intervals for the variance \\sigma^2 \\sigma^2 and the standard deviation \\sigma \\sigma . The 95% CI for the variance: \\left[\\frac{(n-1)s^2}{\\chi^2_{0.975}}, \\frac{(n-1)s^2}{\\chi^2_{0.025}}\\right] = [6.27333, 50.46495] \\\\ \\left[\\frac{(n-1)s^2}{\\chi^2_{0.975}}, \\frac{(n-1)s^2}{\\chi^2_{0.025}}\\right] = [6.27333, 50.46495] \\\\ > ( 9-1 ) * var ( sample ) / qchisq ( 0.975 , df = 8 ) [ 1 ] 6.27333 > ( 9-1 ) * var ( sample ) / qchisq ( 0.025 , df = 8 ) [ 1 ] 50.46495 The 95% CI for the standard deviation: \\left[\\sqrt{6.27333}, \\sqrt{50.46495}\\right] = [2.504662, 7.103869] \\\\ \\left[\\sqrt{6.27333}, \\sqrt{50.46495}\\right] = [2.504662, 7.103869] \\\\ f) Find the 99% confidence intervals for the variance \\sigma^2 \\sigma^2 and the standard deviation \\sigma \\sigma . The 99% CI for the variance: \\left[\\frac{(n-1)s^2}{\\chi^2_{0.995}}, \\frac{(n-1)s^2}{\\chi^2_{0.005}}\\right] = [5.010259, 81.82009] \\\\ \\left[\\frac{(n-1)s^2}{\\chi^2_{0.995}}, \\frac{(n-1)s^2}{\\chi^2_{0.005}}\\right] = [5.010259, 81.82009] \\\\ > ( 9-1 ) * var ( sample ) / qchisq ( 0.995 , df = 8 ) [ 1 ] 5.010259 > ( 9-1 ) * var ( sample ) / qchisq ( 0.005 , df = 8 ) [ 1 ] 81.82009 The 99% CI for the standard deviation: \\left[\\sqrt{5.010259}, \\sqrt{81.82009}\\right] = [2.238361, 9.045446] \\\\ \\left[\\sqrt{5.010259}, \\sqrt{81.82009}\\right] = [2.238361, 9.045446] \\\\ 3.2 Aluminum profile The length of an aluminum profile is checked by taking a sample of 16 items whose length is measured. The measurement results from this sample are listed below, all measurements are in mm: 180.02, 180.00, 180.01, 179.97, 179.92, 180.05, 179.94, 180.10,180.24, 180.12, 180.13, 180.22, 179.96, 180.10, 179.96, 180.06 . From data is obtained: $\\bar{x}=180.05 $ and s = 0.0959 s = 0.0959 . It can be assumed that the sample comes from a population which is normal distributed. a) A 90%-confidence interval for \\mu \\mu becomes? \\bar{x}\\pm t_{0.95}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 1.75305*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.04202937 = [ 180.008, 180.092] \\bar{x}\\pm t_{0.95}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 1.75305*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.04202937 = [ 180.008, 180.092] > qt ( 0.95 , 15 ) [ 1 ] 1.75305 b) A 99%-confidence interval for \\sigma \\sigma becomes? \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.995}}}, \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.005}}}\\right] = [0.06485128, 0.1731578] \\\\ \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.995}}}, \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.005}}}\\right] = [0.06485128, 0.1731578] \\\\ > sqrt (( 16-1 ) * 0.0959 ^ 2 / qchisq ( 0.995 , df = 15 )) [ 1 ] 0.06485128 > sqrt (( 16-1 ) * 0.0959 ^ 2 / qchisq ( 0.005 , df = 15 )) [ 1 ] 0.1731578","title":"3 Confidence Intervals"},{"location":"chapter_3_1/#3-confidence-intervals","text":"","title":"3 Confidence Intervals"},{"location":"chapter_3_1/#31-concrete-items","text":"A construction company receives concrete items for a construction. The length of the items are assumed reasonably normally distributed. The following requirements for the length of the elements are made \\mu=3000mm \\mu=3000mm . The company samples 9 items from a delivery which are then measured for control. The following measurements (in mm) are found: 3003, 3005, 2997, 3006, 2999, 2998, 3007, 3005, 3001.","title":"3.1 Concrete items"},{"location":"chapter_3_1/#a","text":"Compute the following three statistics: the sample mean, the sample standard deviation and the standard error of the mean, and what are the interpretations of these statistics? \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ SE_{\\bar{x}}= \\frac{s}{\\sqrt{n}} = 1.236033 \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ SE_{\\bar{x}}= \\frac{s}{\\sqrt{n}} = 1.236033 > sample <- c ( 3003 , 3005 , 2997 , 3006 , 2999 , 2998 , 3007 , 3005 , 3001 ) > mean <- mean ( sample ) [ 1 ] 3002.333 > sd <- sd ( sample ) [ 1 ] 3.708099 > error <- sd / sqrt ( 9 ) [ 1 ] 1.236033","title":"a)"},{"location":"chapter_3_1/#b","text":"In a construction process, 5 concrete items are joined together to a single construction with a length which is then the complete length of the 5 concrete items. It is very important that the length of this new construction is within 15 m plus/minus 1 cm. How often will it happen that such a construction will be more than 1 cm away from the 15 m target (assume that the population mean concrete item length is \\mu \\mu = 3000 mm and that the population standard deviation is \\sigma \\sigma = 3)? Find: P(14990>L>15010) P(14990>L>15010) We know: L \\sim N(3000,3^2 ) \\\\ L^{scale} = 5L \\\\ L^{scale} \\sim N(15000, 45) L \\sim N(3000,3^2 ) \\\\ L^{scale} = 5L \\\\ L^{scale} \\sim N(15000, 45) Solution: $$ P(14990>L^{scale}>15010) = 2*P(L^{scale}<14990) = 0.1360371 \\ $$ > 2 * pnorm ( 14990 , mean = 15000 , sd = sqrt ( 45 )) [ 1 ] 0.1360371","title":"b)"},{"location":"chapter_3_1/#c","text":"Find the 95% confidence interval for the mean \\mu \\mu . \\bar{x}\\pm t_{0.975}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 2.306*1.236 = \\\\ = 3002.333 \\pm 2.850216 = [ 2999.483, 3005.184] \\bar{x}\\pm t_{0.975}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 2.306*1.236 = \\\\ = 3002.333 \\pm 2.850216 = [ 2999.483, 3005.184] > qt ( 0.975 , 9-1 ) [ 1 ] 2.306004","title":"c)"},{"location":"chapter_3_1/#d","text":"Find the 99% confidence interval for \\mu \\mu . Compare with the 95% one from above and explain why it is smaller/larger! \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 3.355387*1.236 = \\\\ = 3002.333 \\pm 4.147258 = [2998.186, 3006.48] \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 3002.333 \\pm 3.355387*1.236 = \\\\ = 3002.333 \\pm 4.147258 = [2998.186, 3006.48] > qt ( 0.995 , 9-1 ) [ 1 ] 3.355387 It is larger, because in this case 99% of all CI's should contain the true mean. So that means, if we want a higher likelihood, that the CI contains the population mean, so we should make the CI larger.","title":"d)"},{"location":"chapter_3_1/#e","text":"Find the 95% confidence intervals for the variance \\sigma^2 \\sigma^2 and the standard deviation \\sigma \\sigma . The 95% CI for the variance: \\left[\\frac{(n-1)s^2}{\\chi^2_{0.975}}, \\frac{(n-1)s^2}{\\chi^2_{0.025}}\\right] = [6.27333, 50.46495] \\\\ \\left[\\frac{(n-1)s^2}{\\chi^2_{0.975}}, \\frac{(n-1)s^2}{\\chi^2_{0.025}}\\right] = [6.27333, 50.46495] \\\\ > ( 9-1 ) * var ( sample ) / qchisq ( 0.975 , df = 8 ) [ 1 ] 6.27333 > ( 9-1 ) * var ( sample ) / qchisq ( 0.025 , df = 8 ) [ 1 ] 50.46495 The 95% CI for the standard deviation: \\left[\\sqrt{6.27333}, \\sqrt{50.46495}\\right] = [2.504662, 7.103869] \\\\ \\left[\\sqrt{6.27333}, \\sqrt{50.46495}\\right] = [2.504662, 7.103869] \\\\","title":"e)"},{"location":"chapter_3_1/#f","text":"Find the 99% confidence intervals for the variance \\sigma^2 \\sigma^2 and the standard deviation \\sigma \\sigma . The 99% CI for the variance: \\left[\\frac{(n-1)s^2}{\\chi^2_{0.995}}, \\frac{(n-1)s^2}{\\chi^2_{0.005}}\\right] = [5.010259, 81.82009] \\\\ \\left[\\frac{(n-1)s^2}{\\chi^2_{0.995}}, \\frac{(n-1)s^2}{\\chi^2_{0.005}}\\right] = [5.010259, 81.82009] \\\\ > ( 9-1 ) * var ( sample ) / qchisq ( 0.995 , df = 8 ) [ 1 ] 5.010259 > ( 9-1 ) * var ( sample ) / qchisq ( 0.005 , df = 8 ) [ 1 ] 81.82009 The 99% CI for the standard deviation: \\left[\\sqrt{5.010259}, \\sqrt{81.82009}\\right] = [2.238361, 9.045446] \\\\ \\left[\\sqrt{5.010259}, \\sqrt{81.82009}\\right] = [2.238361, 9.045446] \\\\","title":"f)"},{"location":"chapter_3_1/#32-aluminum-profile","text":"The length of an aluminum profile is checked by taking a sample of 16 items whose length is measured. The measurement results from this sample are listed below, all measurements are in mm: 180.02, 180.00, 180.01, 179.97, 179.92, 180.05, 179.94, 180.10,180.24, 180.12, 180.13, 180.22, 179.96, 180.10, 179.96, 180.06 . From data is obtained: $\\bar{x}=180.05 $ and s = 0.0959 s = 0.0959 . It can be assumed that the sample comes from a population which is normal distributed.","title":"3.2 Aluminum profile"},{"location":"chapter_3_1/#a_1","text":"A 90%-confidence interval for \\mu \\mu becomes? \\bar{x}\\pm t_{0.95}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 1.75305*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.04202937 = [ 180.008, 180.092] \\bar{x}\\pm t_{0.95}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 1.75305*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.04202937 = [ 180.008, 180.092] > qt ( 0.95 , 15 ) [ 1 ] 1.75305","title":"a)"},{"location":"chapter_3_1/#b_1","text":"A 99%-confidence interval for \\sigma \\sigma becomes? \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.995}}}, \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.005}}}\\right] = [0.06485128, 0.1731578] \\\\ \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.995}}}, \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{0.005}}}\\right] = [0.06485128, 0.1731578] \\\\ > sqrt (( 16-1 ) * 0.0959 ^ 2 / qchisq ( 0.995 , df = 15 )) [ 1 ] 0.06485128 > sqrt (( 16-1 ) * 0.0959 ^ 2 / qchisq ( 0.005 , df = 15 )) [ 1 ] 0.1731578","title":"b)"},{"location":"chapter_3_2/","text":"3 Hypothesis Testing 3.3 Concrete items A construction company receives concrete items for a construction. The length of the items are assumed reasonably normally distributed. The following requirements for the length of the elements are made \\mu=3000mm \\mu=3000mm . The company samples 9 items from a delivery which are then measured for control. The following measurements (in mm) are found: 3003, 3005, 2997, 3006, 2999, 2998, 3007, 3005, 3001. a) To investigate whether the requirement to the mean is fulfilled (with \\alpha= 5% \\alpha= 5% ), the following hypothesis should be tested H_{0}:\\ =\\ 3000 \\\\ H_{1}:\\ \\neq\\ 3000 H_{0}:\\ =\\ 3000 \\\\ H_{1}:\\ \\neq\\ 3000 Or similarly asked: what is the evidence against the null hypothesis? We know that: \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ By using Method 3.36 1. $$ t_{obs}= \\frac{\\bar{x}-\\mu_{0}}{s/\\sqrt{n}}=1.88749 $$ > ( 3002.333-3000 ) / ( 3.708099 / sqrt ( 9 )) [ 1 ] 1.88749 2. $$ \\text{p-value}= 2*P(T>|t_{obs}|) = 0.09579526 $$ > 2 * ( 1 - pt ( 1.88749 , df = 8 )) [ 1 ] 0.09579526 3. Conclusion: \\text{p-value} \\text{p-value} (0.096) is more than \\alpha \\alpha (0.05), so we can accept H_{0} H_{0} Note that we can produce same result by using t.test in R > t.test ( sample , mu = 3000 ) One Sample t - test data : sample t = 1.8878 , df = 8 , p - value = 0.09576 alternative hypothesis : true mean is not equal to 3000 95 percent confidence interval : 2999.483 3005.184 sample estimates : mean of x 3002.333 b) What would the level $\\alpha = 0.01 $ critical values be for this test, and what are the interpretation of these? t_{\\alpha/2} = t_{0.005}= -3.355387 \\\\ t_{1-\\alpha/2}= t_{0.995} = 3.355387 t_{\\alpha/2} = t_{0.005}= -3.355387 \\\\ t_{1-\\alpha/2}= t_{0.995} = 3.355387 > qt ( 0.005 , df = 8 ) [ 1 ] -3.355387 > qt ( 0.995 , df = 8 ) [ 1 ] 3.355387 We can reject H_0 H_0 if the observed test-statistics ( t_{obs} t_{obs} ) is more extreme than the calculated critical value with the significance level of \\alpha=0.01 \\alpha=0.01 c) What would the level \\alpha=0.05 \\alpha=0.05 critical values be for this test (compare also with the values found in the previous question)? t_{\\alpha/2} = t_{0.025}= -2.306004 \\\\ t_{1-\\alpha/2}= t_{0.975} = 2.306004 t_{\\alpha/2} = t_{0.025}= -2.306004 \\\\ t_{1-\\alpha/2}= t_{0.975} = 2.306004 > qt ( 0.05 / 2 , df = 8 ) [ 1 ] -2.306004 > qt ( 1-0.05 / 2 , df = 8 ) [ 1 ] 2.306004 Critical values get closer to each other as the \\alpha \\alpha increases. d) Investigate, by some plots, whether the data here appears to be coming from a normal distribution (as assumed until now)? hist ( sample , main = \"Histogram of Concrete items\" , xlab = \"Measurements\" ) qqnorm ( sample , ylab = \"Measurements Quantiles\" ) qqline ( sample ) qqwrap <- function ( x , y , ... ){ stdy <- ( y - mean ( y )) / sd ( y ) qqnorm ( stdy , main = \"\" , ... ) qqline ( stdy )} wallyplot ( x - mean ( sample ), FUN = qqwrap , ylim = c ( -3 , 3 )) e) Assuming that you, maybe among different plots, also did the normal q-q plot above, the question is now: What exactly is plotted in that plot? Or more specifically: what are the x- and y-coordinates of e.g. the two points to the lower left in this plot? X coordinates represent the expected normal quantiles. Y coordinates represent the sample quantiles. For example, the point ( 0, 3002.333 ) ( 0, 3002.333 ) represents respectively the 0.5 quantiles of the expected normal distribution and the sample. 3.4 Aluminum profile The length of an aluminum profile is checked by taking a sample of 16 items whose length is measured. The measurement results from this sample are listed below, all measurements are in mm: 180.02, 180.00, 180.01, 179.97, 179.92, 180.05, 179.94, 180.10,180.24, 180.12, 180.13, 180.22, 179.96, 180.10, 179.96, 180.06 . From data is obtained: $\\bar{x}=180.05 $ and s = 0.0959 s = 0.0959 . It can be assumed that the sample comes from a population which is normal distributed. a) Find the evidence against the following hypothesis: H_{0}\\ : =\\ \\mu=180 H_{0}\\ : =\\ \\mu=180 > t.test ( aluminum , mu = 180 ) One Sample t - test data : aluminum t = 2.0851 , df = 15 , p - value = 0.05456 alternative hypothesis : true mean is not equal to 180 95 percent confidence interval : 179.9989 180.1011 sample estimates : mean of x 180.05 \\text{p-value} \\text{p-value} (0.05452038) is more than 0.05, but less than 1, so there is a weak evidences against H_{0} H_{0} . b) If the following hypothesis test is carried out H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 What are the level \\alpha= 1% \\alpha= 1% critical values for this test? t_{\\alpha/2} = t_{0.005}= -2.946713 \\\\ t_{1-\\alpha/2}= t_{0.995} = 2.946713 t_{\\alpha/2} = t_{0.005}= -2.946713 \\\\ t_{1-\\alpha/2}= t_{0.995} = 2.946713 > qt ( 0.005 , df = 16-1 ) [ 1 ] -2.946713 > qt ( 0.995 , df = 16-1 ) [ 1 ] 2.946713 c) What is the 99%-confidence interval for \\mu \\mu ? \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 2.946713*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.07064744 = [ 179.9794, 180.1206] \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 2.946713*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.07064744 = [ 179.9794, 180.1206] > qt ( 0.995 , 15 ) [ 1 ] 2.946713 d) Carry out the following hypothesis test using \\alpha=5\\% \\alpha=5\\% H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 We know that: \\bar{x} = 180.05 \\\\ s = 0.0959 \\\\ \\bar{x} = 180.05 \\\\ s = 0.0959 \\\\ By using Method 3.36 1. $$ t_{obs}= \\frac{\\bar{x}-\\mu_{0}}{s/\\sqrt{n}}= 2.085506 $$ > ( 180.05-180 ) / ( 0.0959 / sqrt ( 16 )) [ 1 ] 2.085506 2. $$ \\text{p-value}= 2*P(T>|t_{obs}|) = 0.05452038 $$ > 2 * ( 1 - pt ( 2.085506 , df = 15 )) [ 1 ] 0.05452038 3. Conclusion: \\text{p-value} \\text{p-value} (0.05452038) is more than \\alpha \\alpha (0.05), so we can accept H_{0} H_{0} . > t.test ( aluminum , mu = 180 ) One Sample t - test data : aluminum t = 2.0851 , df = 15 , p - value = 0.05456 alternative hypothesis : true mean is not equal to 180 95 percent confidence interval : 179.9989 180.1011 sample estimates : mean of x 180.05 \\text{p-value} \\text{p-value} (0.05452038) is more than 0.05, but less than 1, so there is weak evidences against H_{0} H_{0} .","title":"3 Hypothesis Testing"},{"location":"chapter_3_2/#3-hypothesis-testing","text":"","title":"3 Hypothesis Testing"},{"location":"chapter_3_2/#33-concrete-items","text":"A construction company receives concrete items for a construction. The length of the items are assumed reasonably normally distributed. The following requirements for the length of the elements are made \\mu=3000mm \\mu=3000mm . The company samples 9 items from a delivery which are then measured for control. The following measurements (in mm) are found: 3003, 3005, 2997, 3006, 2999, 2998, 3007, 3005, 3001.","title":"3.3 Concrete items"},{"location":"chapter_3_2/#a","text":"To investigate whether the requirement to the mean is fulfilled (with \\alpha= 5% \\alpha= 5% ), the following hypothesis should be tested H_{0}:\\ =\\ 3000 \\\\ H_{1}:\\ \\neq\\ 3000 H_{0}:\\ =\\ 3000 \\\\ H_{1}:\\ \\neq\\ 3000 Or similarly asked: what is the evidence against the null hypothesis? We know that: \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ \\bar{x} = 3002.333 \\\\ s = 3.708099 \\\\ By using Method 3.36 1. $$ t_{obs}= \\frac{\\bar{x}-\\mu_{0}}{s/\\sqrt{n}}=1.88749 $$ > ( 3002.333-3000 ) / ( 3.708099 / sqrt ( 9 )) [ 1 ] 1.88749 2. $$ \\text{p-value}= 2*P(T>|t_{obs}|) = 0.09579526 $$ > 2 * ( 1 - pt ( 1.88749 , df = 8 )) [ 1 ] 0.09579526 3. Conclusion: \\text{p-value} \\text{p-value} (0.096) is more than \\alpha \\alpha (0.05), so we can accept H_{0} H_{0} Note that we can produce same result by using t.test in R > t.test ( sample , mu = 3000 ) One Sample t - test data : sample t = 1.8878 , df = 8 , p - value = 0.09576 alternative hypothesis : true mean is not equal to 3000 95 percent confidence interval : 2999.483 3005.184 sample estimates : mean of x 3002.333","title":"a)"},{"location":"chapter_3_2/#b","text":"What would the level $\\alpha = 0.01 $ critical values be for this test, and what are the interpretation of these? t_{\\alpha/2} = t_{0.005}= -3.355387 \\\\ t_{1-\\alpha/2}= t_{0.995} = 3.355387 t_{\\alpha/2} = t_{0.005}= -3.355387 \\\\ t_{1-\\alpha/2}= t_{0.995} = 3.355387 > qt ( 0.005 , df = 8 ) [ 1 ] -3.355387 > qt ( 0.995 , df = 8 ) [ 1 ] 3.355387 We can reject H_0 H_0 if the observed test-statistics ( t_{obs} t_{obs} ) is more extreme than the calculated critical value with the significance level of \\alpha=0.01 \\alpha=0.01","title":"b)"},{"location":"chapter_3_2/#c","text":"What would the level \\alpha=0.05 \\alpha=0.05 critical values be for this test (compare also with the values found in the previous question)? t_{\\alpha/2} = t_{0.025}= -2.306004 \\\\ t_{1-\\alpha/2}= t_{0.975} = 2.306004 t_{\\alpha/2} = t_{0.025}= -2.306004 \\\\ t_{1-\\alpha/2}= t_{0.975} = 2.306004 > qt ( 0.05 / 2 , df = 8 ) [ 1 ] -2.306004 > qt ( 1-0.05 / 2 , df = 8 ) [ 1 ] 2.306004 Critical values get closer to each other as the \\alpha \\alpha increases.","title":"c)"},{"location":"chapter_3_2/#d","text":"Investigate, by some plots, whether the data here appears to be coming from a normal distribution (as assumed until now)? hist ( sample , main = \"Histogram of Concrete items\" , xlab = \"Measurements\" ) qqnorm ( sample , ylab = \"Measurements Quantiles\" ) qqline ( sample ) qqwrap <- function ( x , y , ... ){ stdy <- ( y - mean ( y )) / sd ( y ) qqnorm ( stdy , main = \"\" , ... ) qqline ( stdy )} wallyplot ( x - mean ( sample ), FUN = qqwrap , ylim = c ( -3 , 3 ))","title":"d)"},{"location":"chapter_3_2/#e","text":"Assuming that you, maybe among different plots, also did the normal q-q plot above, the question is now: What exactly is plotted in that plot? Or more specifically: what are the x- and y-coordinates of e.g. the two points to the lower left in this plot? X coordinates represent the expected normal quantiles. Y coordinates represent the sample quantiles. For example, the point ( 0, 3002.333 ) ( 0, 3002.333 ) represents respectively the 0.5 quantiles of the expected normal distribution and the sample.","title":"e)"},{"location":"chapter_3_2/#34-aluminum-profile","text":"The length of an aluminum profile is checked by taking a sample of 16 items whose length is measured. The measurement results from this sample are listed below, all measurements are in mm: 180.02, 180.00, 180.01, 179.97, 179.92, 180.05, 179.94, 180.10,180.24, 180.12, 180.13, 180.22, 179.96, 180.10, 179.96, 180.06 . From data is obtained: $\\bar{x}=180.05 $ and s = 0.0959 s = 0.0959 . It can be assumed that the sample comes from a population which is normal distributed.","title":"3.4 Aluminum profile"},{"location":"chapter_3_2/#a_1","text":"Find the evidence against the following hypothesis: H_{0}\\ : =\\ \\mu=180 H_{0}\\ : =\\ \\mu=180 > t.test ( aluminum , mu = 180 ) One Sample t - test data : aluminum t = 2.0851 , df = 15 , p - value = 0.05456 alternative hypothesis : true mean is not equal to 180 95 percent confidence interval : 179.9989 180.1011 sample estimates : mean of x 180.05 \\text{p-value} \\text{p-value} (0.05452038) is more than 0.05, but less than 1, so there is a weak evidences against H_{0} H_{0} .","title":"a)"},{"location":"chapter_3_2/#b_1","text":"If the following hypothesis test is carried out H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 What are the level \\alpha= 1% \\alpha= 1% critical values for this test? t_{\\alpha/2} = t_{0.005}= -2.946713 \\\\ t_{1-\\alpha/2}= t_{0.995} = 2.946713 t_{\\alpha/2} = t_{0.005}= -2.946713 \\\\ t_{1-\\alpha/2}= t_{0.995} = 2.946713 > qt ( 0.005 , df = 16-1 ) [ 1 ] -2.946713 > qt ( 0.995 , df = 16-1 ) [ 1 ] 2.946713","title":"b)"},{"location":"chapter_3_2/#c_1","text":"What is the 99%-confidence interval for \\mu \\mu ? \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 2.946713*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.07064744 = [ 179.9794, 180.1206] \\bar{x}\\pm t_{0.995}* \\frac{s}{\\sqrt{n}} = 180.05 \\pm 2.946713*\\frac{0.0959}{\\sqrt{16}} = \\\\ = 180.05 \\pm 0.07064744 = [ 179.9794, 180.1206] > qt ( 0.995 , 15 ) [ 1 ] 2.946713","title":"c)"},{"location":"chapter_3_2/#d_1","text":"Carry out the following hypothesis test using \\alpha=5\\% \\alpha=5\\% H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 H_{0}:\\ \\mu=180 \\\\ H_{1}:\\ \\mu\\neq180 We know that: \\bar{x} = 180.05 \\\\ s = 0.0959 \\\\ \\bar{x} = 180.05 \\\\ s = 0.0959 \\\\ By using Method 3.36 1. $$ t_{obs}= \\frac{\\bar{x}-\\mu_{0}}{s/\\sqrt{n}}= 2.085506 $$ > ( 180.05-180 ) / ( 0.0959 / sqrt ( 16 )) [ 1 ] 2.085506 2. $$ \\text{p-value}= 2*P(T>|t_{obs}|) = 0.05452038 $$ > 2 * ( 1 - pt ( 2.085506 , df = 15 )) [ 1 ] 0.05452038 3. Conclusion: \\text{p-value} \\text{p-value} (0.05452038) is more than \\alpha \\alpha (0.05), so we can accept H_{0} H_{0} . > t.test ( aluminum , mu = 180 ) One Sample t - test data : aluminum t = 2.0851 , df = 15 , p - value = 0.05456 alternative hypothesis : true mean is not equal to 180 95 percent confidence interval : 179.9989 180.1011 sample estimates : mean of x 180.05 \\text{p-value} \\text{p-value} (0.05452038) is more than 0.05, but less than 1, so there is weak evidences against H_{0} H_{0} .","title":"d)"},{"location":"chapter_3_3/","text":"3 Analysis of Two Samples 3.6 Cholesterol In a clinical trial of a cholesterol-lowering agent, 15 patients\u2019 cholesterol (in mmol/L) has been measured before treatment and 3 weeks after starting treatment. Data are listed in the following table: Patient Before After 1 9.1 8.2 2 8.0 6.4 3 7.7 6.6 4 10.0 8.5 5 9.6 8.0 6 7.9 5.8 7 9.0 7.8 8 7.1 7.2 9 8.3 6.7 10 9.6 9.8 11 8.2 7.1 12 9.2 7.7 13 7.3 6.0 14 8.5 6.6 15 9.5 8.4 The following is run in R: x1 <- c ( 9.1 , 8.0 , 7.7 , 10.0 , 9.6 , 7.9 , 9.0 , 7.1 , 8.3 , 9.6 , 8.2 , 9.2 , 7.3 , 8.5 , 9.5 ) x2 <- c ( 8.2 , 6.4 , 6.6 , 8.5 , 8.0 , 5.8 , 7.8 , 7.2 , 6.7 , 9.8 , 7.1 , 7.7 , 6.0 , 6.6 , 8.4 ) t.test ( x1 , x2 ) Welch Two Sample t - test data : x1 and x2 t = 3.3 , df = 27 , p - value = 0.003 alternative hypothesis : true difference in means is not equal to 0 95 percent confidence interval : 0.4637 1.9630 sample estimates : mean of x mean of y 8.600 7.387 t.test ( x1 , x2 , pair = TRUE ) Paired t - test data : x1 and x2 t = 7.3 , df = 14 , p - value = 0.000004 alternative hypothesis : true difference in means is not equal to 0 95 percent confidence interval : 0.8588 1.5678 sample estimates : mean of the differences 1.213 a) Can there, based on these data be demonstrated a significant decrease in cholesterol levels with \\alpha \\alpha = 0.001? This is clearly a paired setting, because the same persons were measured before treatment and 3 weeks after starting treatment. So only the results from the last of the R-calls are relevant, where we can read off the results: The (non-directional) \\text{p-value}= 0.00000367 \\text{p-value}= 0.00000367 , so there is very strong evidence against the null hypothesis, and we can beyond any reasonable doubts conclude that the mean cholesterol level has decreased after the 3 weeks. 3.7 Pulse Runner Pulse end Pulse 1min 1 173 120 2 175 115 3 174 122 4 183 123 5 181 125 6 180 140 7 170 108 8 182 133 9 188 134 10 178 121 11 181 130 12 183 126 13 185 128 The following was run in R: Pulse_end <- c ( 173 , 175 , 174 , 183 , 181 , 180 , 170 , 182 , 188 , 178 , 181 , 183 , 185 ) Pulse_1min <- c ( 120 , 115 , 122 , 123 , 125 , 140 , 108 , 133 , 134 , 121 , 130 , 126 , 128 ) mean ( Pulse_end ) [ 1 ] 179.5 mean ( Pulse_1min ) [ 1 ] 125 sd ( Pulse_end ) [ 1 ] 5.19 sd ( Pulse_1min ) [ 1 ] 8.406 sd ( Pulse_end - Pulse_1min ) [ 1 ] 5.768 a) What is the 99% confidence interval for the mean pulse drop (meaning the drop during 1 minute from end of workout)? We know that these samples are dependent(paired situation), so so we apply the one-sample theory (Method 3.9) on the differences in order to find CI mean_diff <- mean ( Pulse_end ) - mean ( Pulse_1min ) c ( mean_diff - qt ( 1-0.01 / 2 , df = 12 ) * sd_diff / sqrt ( 13 ), mean_diff + qt ( 1-0.01 / 2 , df = 12 ) * sd_diff / sqrt ( 13 )) 49.57507 59.34801 b) Consider now the 13 pulse end measurements (first row in the table). What is the 95% confidence interval for the standard deviation of these? By method 3.19 \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [3.721662, 8.567283] \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [3.721662, 8.567283] c ( sqrt ( 12 * var ( Pulse_end ) / qchisq ( 1-0.05 / 2 , df = 12 )), sqrt ( 12 * var ( Pulse_end ) / qchisq ( 0.05 / 2 , df = 12 ))) [ 1 ] 3.721662 8.567283 So the answer is that we accept that \\sigma\\in[3.721662, 8.567283] \\sigma\\in[3.721662, 8.567283] 3.8 Foil production In the production of a certain foil (film), the foil is controlled by measuring the thickness of the foil in a number of points distributed over the width of the foil. The production is considered stable if the mean of the difference between the maximum and minimum measurements does not exceed 0.35 mm. At a given day, the following random samples are observed for 10 foils: Foil Max. in mm y_{max} y_{max} Min. in mm y_{min} y_{min} Max-Min(D) 1 2.62 2.14 0.48 2 2.71 2.39 0.32 3 2.18 1.86 0.32 4 2.25 1.92 0.33 5 2.72 2.33 0.39 6 2.34 2.00 0.34 7 2.63 2.25 0.38 8 1.86 1.50 0.36 9 2.84 2.27 0.57 10 2.93 2.37 0.56 The following statistics may potentially be used $$ \\bar{y} {max} = 2.508, \\bar{y} = 2.103, s_{y_{max}}=0.3373,\\ s_{y_{min}}=0.2834, s_D=0.09664 $$ a) What is a 95% confidence interval for the mean difference? Answer: $$ [0.3358679, 0.4741321] $$ > c ( 2.508-2.103 - qt ( 1-0.05 / 2 , df = 9 ) * 0.09664 / sqrt ( 10 ), 2.508-2.103 + qt ( 1-0.05 / 2 , df = 9 ) * 0.09664 / sqrt ( 10 )) [ 1 ] 0.3358679 0.4741321 Note: The confidence interval contains those values of the mean difference that we believe in based on the data. b) How much evidence is there that the mean difference is different from 0.35? State the null hypothesis, t-statistic and p-value for this question. H_0:\\ \\mu=0.35 \\\\ H_1:\\ \\mu\\ne0.35 H_0:\\ \\mu=0.35 \\\\ H_1:\\ \\mu\\ne0.35 By using Method 3.36 1. $$ t_{obs}= \\frac{\\bar{x}-\\mu_{0}}{s/\\sqrt{n}}=1.799723 $$ > (( 2.508-2.103 ) -0.35 ) / ( 0.09664 / sqrt ( 10 )) [ 1 ] 1.799723 2. $$ \\text{p-value}= 2*P(T>|t_{obs}|) = 0.1054369 $$ > 2 * ( 1 - pt ( 1.799723 , df = 9 )) [ 1 ] 0.1054369 3. Conclusion: \\text{p-value} \\text{p-value} is 0.1054369, so there is little or evidence against H_{0} H_{0} , which is \\mu=0.35 \\mu=0.35 3.9 Course project At a specific education it was decided to introduce a project, running through the course period, as a part of the grade point evaluation. In order to assess whether it has changed the percentage of students passing the course, the following data was collected: Before introduction of project After introduction of project Number of students evaluated 50 24 Number of students failed 13 3 Average grade point \\bar{x} \\bar{x} 6.420 7.375 Sample standard deviation s s 2.205 1.813 a) As it is assumed that the grades are approximately normally distributed in each group, the following hypothesis is tested: H_{0} \\ : \\ \\mu_{Before}= \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}= 0 \\\\ H_{1}\\ : \\ \\mu_{Before} \\ne \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}\\ne 0 H_{0} \\ : \\ \\mu_{Before}= \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}= 0 \\\\ H_{1}\\ : \\ \\mu_{Before} \\ne \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}\\ne 0 The test statistic, the p-value and the conclusion for this test become? By method 3.51(Welch): t_{obs}= \\frac{(\\bar{x}_1-\\bar{x}_2)-\\delta_0}{\\sqrt{s_1^2/n_1+s^2_2/n_2}}= -1.973387\\\\ v = \\frac{(\\frac{s^2_1}{n_1}+\\frac{s^2_2}{n_2})^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}= 54.38591 t_{obs}= \\frac{(\\bar{x}_1-\\bar{x}_2)-\\delta_0}{\\sqrt{s_1^2/n_1+s^2_2/n_2}}= -1.973387\\\\ v = \\frac{(\\frac{s^2_1}{n_1}+\\frac{s^2_2}{n_2})^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}= 54.38591 > tobs <- ( 6.420-7.375 ) / ( sqrt (( 2.205 ^ 2 / 50 ) + ( 1.813 ^ 2 / 24 ))) [ 1 ] -1.973387 > v <- (( s1 ^ 2 / n1 ) + ( s2 ^ 2 / n2 )) ^ 2 / ((( s1 ^ 2 / n1 ) ^ 2 / ( n1 -1 )) + (( s2 ^ 2 / n2 ) ^ 2 / ( n2 -1 ))) [ 1 ] 54.38591 \\text{p-value}= 0.05354164 \\text{p-value}= 0.05354164 2 * ( 1 - pt ( 1.973387 , df = 54.38591 )) Conclusion On a 5% level we cannot conclude a significant difference in the grade point means before and after. This means that we cannot reject H_0 H_0 b) A 99% confidence interval for the mean grade point difference is? By method 3.47: \\bar{x}-\\bar{y}\\pm t_{1-\\alpha/2}*\\sqrt{\\frac{s_{1}^2}{n_1}+\\frac{s^2_{2}}{n_2}} = [-2.2467772,0.3367772] \\bar{x}-\\bar{y}\\pm t_{1-\\alpha/2}*\\sqrt{\\frac{s_{1}^2}{n_1}+\\frac{s^2_{2}}{n_2}} = [-2.2467772,0.3367772] c ( 6.420-7.375 - qt ( 1-0.01 / 2 , df = v ) * sqrt ( 2.205 ^ 2 / 50+1.813 ^ 2 / 24 ), 6.420-7.375 + qt ( 1-0.01 / 2 , df = v ) * sqrt ( 2.205 ^ 2 / 50+1.813 ^ 2 / 24 )) [ 1 ] -2.2467772 0.3367772 The answer: we accept that the mean difference in the interval [-2.247; 0.337] [-2.247; 0.337] c) A 95% confidence interval for the grade point standard deviation after the introduction of the project becomes? By method 3.19 \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [1.409088, 2.543205] \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [1.409088, 2.543205] n <- 24 sd <- 1.813 alpha <- 0.05 c ( sqrt (( n -1 ) * sd ^ 2 / qchisq ( 1 - alpha / 2 , df = ( n -1 ))), sqrt (( n -1 ) * sd ^ 2 / qchisq ( alpha / 2 , df = ( n -1 )))) [ 1 ] 1.409088 2.543205 So the answer is that we accept that \\sigma\\in[1.409088, 2.543205] \\sigma\\in[1.409088, 2.543205]","title":"3 Analysis of Two samples"},{"location":"chapter_3_3/#3-analysis-of-two-samples","text":"","title":"3 Analysis of Two Samples"},{"location":"chapter_3_3/#36-cholesterol","text":"In a clinical trial of a cholesterol-lowering agent, 15 patients\u2019 cholesterol (in mmol/L) has been measured before treatment and 3 weeks after starting treatment. Data are listed in the following table: Patient Before After 1 9.1 8.2 2 8.0 6.4 3 7.7 6.6 4 10.0 8.5 5 9.6 8.0 6 7.9 5.8 7 9.0 7.8 8 7.1 7.2 9 8.3 6.7 10 9.6 9.8 11 8.2 7.1 12 9.2 7.7 13 7.3 6.0 14 8.5 6.6 15 9.5 8.4 The following is run in R: x1 <- c ( 9.1 , 8.0 , 7.7 , 10.0 , 9.6 , 7.9 , 9.0 , 7.1 , 8.3 , 9.6 , 8.2 , 9.2 , 7.3 , 8.5 , 9.5 ) x2 <- c ( 8.2 , 6.4 , 6.6 , 8.5 , 8.0 , 5.8 , 7.8 , 7.2 , 6.7 , 9.8 , 7.1 , 7.7 , 6.0 , 6.6 , 8.4 ) t.test ( x1 , x2 ) Welch Two Sample t - test data : x1 and x2 t = 3.3 , df = 27 , p - value = 0.003 alternative hypothesis : true difference in means is not equal to 0 95 percent confidence interval : 0.4637 1.9630 sample estimates : mean of x mean of y 8.600 7.387 t.test ( x1 , x2 , pair = TRUE ) Paired t - test data : x1 and x2 t = 7.3 , df = 14 , p - value = 0.000004 alternative hypothesis : true difference in means is not equal to 0 95 percent confidence interval : 0.8588 1.5678 sample estimates : mean of the differences 1.213","title":"3.6 Cholesterol"},{"location":"chapter_3_3/#a","text":"Can there, based on these data be demonstrated a significant decrease in cholesterol levels with \\alpha \\alpha = 0.001? This is clearly a paired setting, because the same persons were measured before treatment and 3 weeks after starting treatment. So only the results from the last of the R-calls are relevant, where we can read off the results: The (non-directional) \\text{p-value}= 0.00000367 \\text{p-value}= 0.00000367 , so there is very strong evidence against the null hypothesis, and we can beyond any reasonable doubts conclude that the mean cholesterol level has decreased after the 3 weeks.","title":"a)"},{"location":"chapter_3_3/#37-pulse","text":"Runner Pulse end Pulse 1min 1 173 120 2 175 115 3 174 122 4 183 123 5 181 125 6 180 140 7 170 108 8 182 133 9 188 134 10 178 121 11 181 130 12 183 126 13 185 128 The following was run in R: Pulse_end <- c ( 173 , 175 , 174 , 183 , 181 , 180 , 170 , 182 , 188 , 178 , 181 , 183 , 185 ) Pulse_1min <- c ( 120 , 115 , 122 , 123 , 125 , 140 , 108 , 133 , 134 , 121 , 130 , 126 , 128 ) mean ( Pulse_end ) [ 1 ] 179.5 mean ( Pulse_1min ) [ 1 ] 125 sd ( Pulse_end ) [ 1 ] 5.19 sd ( Pulse_1min ) [ 1 ] 8.406 sd ( Pulse_end - Pulse_1min ) [ 1 ] 5.768","title":"3.7 Pulse"},{"location":"chapter_3_3/#a_1","text":"What is the 99% confidence interval for the mean pulse drop (meaning the drop during 1 minute from end of workout)? We know that these samples are dependent(paired situation), so so we apply the one-sample theory (Method 3.9) on the differences in order to find CI mean_diff <- mean ( Pulse_end ) - mean ( Pulse_1min ) c ( mean_diff - qt ( 1-0.01 / 2 , df = 12 ) * sd_diff / sqrt ( 13 ), mean_diff + qt ( 1-0.01 / 2 , df = 12 ) * sd_diff / sqrt ( 13 )) 49.57507 59.34801","title":"a)"},{"location":"chapter_3_3/#b","text":"Consider now the 13 pulse end measurements (first row in the table). What is the 95% confidence interval for the standard deviation of these? By method 3.19 \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [3.721662, 8.567283] \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [3.721662, 8.567283] c ( sqrt ( 12 * var ( Pulse_end ) / qchisq ( 1-0.05 / 2 , df = 12 )), sqrt ( 12 * var ( Pulse_end ) / qchisq ( 0.05 / 2 , df = 12 ))) [ 1 ] 3.721662 8.567283 So the answer is that we accept that \\sigma\\in[3.721662, 8.567283] \\sigma\\in[3.721662, 8.567283]","title":"b)"},{"location":"chapter_3_3/#38-foil-production","text":"In the production of a certain foil (film), the foil is controlled by measuring the thickness of the foil in a number of points distributed over the width of the foil. The production is considered stable if the mean of the difference between the maximum and minimum measurements does not exceed 0.35 mm. At a given day, the following random samples are observed for 10 foils: Foil Max. in mm y_{max} y_{max} Min. in mm y_{min} y_{min} Max-Min(D) 1 2.62 2.14 0.48 2 2.71 2.39 0.32 3 2.18 1.86 0.32 4 2.25 1.92 0.33 5 2.72 2.33 0.39 6 2.34 2.00 0.34 7 2.63 2.25 0.38 8 1.86 1.50 0.36 9 2.84 2.27 0.57 10 2.93 2.37 0.56 The following statistics may potentially be used $$ \\bar{y} {max} = 2.508, \\bar{y} = 2.103, s_{y_{max}}=0.3373,\\ s_{y_{min}}=0.2834, s_D=0.09664 $$","title":"3.8 Foil production"},{"location":"chapter_3_3/#a_2","text":"What is a 95% confidence interval for the mean difference? Answer: $$ [0.3358679, 0.4741321] $$ > c ( 2.508-2.103 - qt ( 1-0.05 / 2 , df = 9 ) * 0.09664 / sqrt ( 10 ), 2.508-2.103 + qt ( 1-0.05 / 2 , df = 9 ) * 0.09664 / sqrt ( 10 )) [ 1 ] 0.3358679 0.4741321 Note: The confidence interval contains those values of the mean difference that we believe in based on the data.","title":"a)"},{"location":"chapter_3_3/#b_1","text":"How much evidence is there that the mean difference is different from 0.35? State the null hypothesis, t-statistic and p-value for this question. H_0:\\ \\mu=0.35 \\\\ H_1:\\ \\mu\\ne0.35 H_0:\\ \\mu=0.35 \\\\ H_1:\\ \\mu\\ne0.35 By using Method 3.36 1. $$ t_{obs}= \\frac{\\bar{x}-\\mu_{0}}{s/\\sqrt{n}}=1.799723 $$ > (( 2.508-2.103 ) -0.35 ) / ( 0.09664 / sqrt ( 10 )) [ 1 ] 1.799723 2. $$ \\text{p-value}= 2*P(T>|t_{obs}|) = 0.1054369 $$ > 2 * ( 1 - pt ( 1.799723 , df = 9 )) [ 1 ] 0.1054369 3. Conclusion: \\text{p-value} \\text{p-value} is 0.1054369, so there is little or evidence against H_{0} H_{0} , which is \\mu=0.35 \\mu=0.35","title":"b)"},{"location":"chapter_3_3/#39-course-project","text":"At a specific education it was decided to introduce a project, running through the course period, as a part of the grade point evaluation. In order to assess whether it has changed the percentage of students passing the course, the following data was collected: Before introduction of project After introduction of project Number of students evaluated 50 24 Number of students failed 13 3 Average grade point \\bar{x} \\bar{x} 6.420 7.375 Sample standard deviation s s 2.205 1.813","title":"3.9 Course project"},{"location":"chapter_3_3/#a_3","text":"As it is assumed that the grades are approximately normally distributed in each group, the following hypothesis is tested: H_{0} \\ : \\ \\mu_{Before}= \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}= 0 \\\\ H_{1}\\ : \\ \\mu_{Before} \\ne \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}\\ne 0 H_{0} \\ : \\ \\mu_{Before}= \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}= 0 \\\\ H_{1}\\ : \\ \\mu_{Before} \\ne \\mu_{After} \\equiv \\mu_{Before}-\\mu_{After}\\ne 0 The test statistic, the p-value and the conclusion for this test become? By method 3.51(Welch): t_{obs}= \\frac{(\\bar{x}_1-\\bar{x}_2)-\\delta_0}{\\sqrt{s_1^2/n_1+s^2_2/n_2}}= -1.973387\\\\ v = \\frac{(\\frac{s^2_1}{n_1}+\\frac{s^2_2}{n_2})^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}= 54.38591 t_{obs}= \\frac{(\\bar{x}_1-\\bar{x}_2)-\\delta_0}{\\sqrt{s_1^2/n_1+s^2_2/n_2}}= -1.973387\\\\ v = \\frac{(\\frac{s^2_1}{n_1}+\\frac{s^2_2}{n_2})^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}= 54.38591 > tobs <- ( 6.420-7.375 ) / ( sqrt (( 2.205 ^ 2 / 50 ) + ( 1.813 ^ 2 / 24 ))) [ 1 ] -1.973387 > v <- (( s1 ^ 2 / n1 ) + ( s2 ^ 2 / n2 )) ^ 2 / ((( s1 ^ 2 / n1 ) ^ 2 / ( n1 -1 )) + (( s2 ^ 2 / n2 ) ^ 2 / ( n2 -1 ))) [ 1 ] 54.38591 \\text{p-value}= 0.05354164 \\text{p-value}= 0.05354164 2 * ( 1 - pt ( 1.973387 , df = 54.38591 )) Conclusion On a 5% level we cannot conclude a significant difference in the grade point means before and after. This means that we cannot reject H_0 H_0","title":"a)"},{"location":"chapter_3_3/#b_2","text":"A 99% confidence interval for the mean grade point difference is? By method 3.47: \\bar{x}-\\bar{y}\\pm t_{1-\\alpha/2}*\\sqrt{\\frac{s_{1}^2}{n_1}+\\frac{s^2_{2}}{n_2}} = [-2.2467772,0.3367772] \\bar{x}-\\bar{y}\\pm t_{1-\\alpha/2}*\\sqrt{\\frac{s_{1}^2}{n_1}+\\frac{s^2_{2}}{n_2}} = [-2.2467772,0.3367772] c ( 6.420-7.375 - qt ( 1-0.01 / 2 , df = v ) * sqrt ( 2.205 ^ 2 / 50+1.813 ^ 2 / 24 ), 6.420-7.375 + qt ( 1-0.01 / 2 , df = v ) * sqrt ( 2.205 ^ 2 / 50+1.813 ^ 2 / 24 )) [ 1 ] -2.2467772 0.3367772 The answer: we accept that the mean difference in the interval [-2.247; 0.337] [-2.247; 0.337]","title":"b)"},{"location":"chapter_3_3/#c","text":"A 95% confidence interval for the grade point standard deviation after the introduction of the project becomes? By method 3.19 \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [1.409088, 2.543205] \\left[\\sqrt{\\frac{(n-1)s^2}{\\chi_{1-0.05/2}^2}}, \\sqrt{\\frac{(n-1)s^2}{\\chi_{0.05/2}^2}} \\right] = [1.409088, 2.543205] n <- 24 sd <- 1.813 alpha <- 0.05 c ( sqrt (( n -1 ) * sd ^ 2 / qchisq ( 1 - alpha / 2 , df = ( n -1 ))), sqrt (( n -1 ) * sd ^ 2 / qchisq ( alpha / 2 , df = ( n -1 )))) [ 1 ] 1.409088 2.543205 So the answer is that we accept that \\sigma\\in[1.409088, 2.543205] \\sigma\\in[1.409088, 2.543205]","title":"c)"},{"location":"chapter_4_1/","text":"4 Simulation methods 4.1 Reliability: System lifetime A system consists of three components A, B and C serially connected, such that A is positioned before B, which is again positioned before C. The system will be functioning only so long as A, B and C are all functioning. The lifetime in months of the three components are assumed to follow exponential distributions with means: 2 months, 3 months and 5 months, respectively (hence there are three random variables, X_{A} X_{A} , X_B X_B and X_C X_C with exponential distributions with \\lambda_{A} \\lambda_{A} = \u00bd, \\lambda_{B} \\lambda_{B} = \u2153 and \\lambda_{C} \\lambda_{C} = \u2155 resp.) a) Generate, by simulation, a large number (at least 1000 \u2013 go for 10000 or 100000 if your computer is up for it) of system lifetimes (hint: consider how the random variable Y = System lifetime is a function of the three X-variables: is it the sum, the mean, the median, the minimum, the maximum, the range or something even different?). The lifetime can be seen as the minimal value of the three random component lifetimes \\text{\"Lifetime\"} = min(X_A,X_B,X_C) \\text{\"Lifetime\"} = min(X_A,X_B,X_C) k <- 10000 xA <- rexp ( k , 1 / 2 ) xB <- rexp ( k , 1 / 3 ) xC <- rexp ( k , 1 / 5 ) x <- cbind ( xA , xB , xC ) lifetimes <- apply ( x , 1 , min ) # The second argument in apply() function, 1, means that there should be used rows (NOT columns) for finding the minimal value b) Estimate the mean system lifetime. \\bar{x} = 0.9770395 \\bar{x} = 0.9770395 > mean ( lifetimes ) [ 1 ] 0.9770395 c) Estimate the standard deviation of system lifetimes. \\bar{s} = 0.9791683 \\bar{s} = 0.9791683 > sd ( lifetimes ) [ 1 ] 0.9791683 d) Estimate the probability that the system fails within 1 month. P(X<1)= 0.6395 P(X<1)= 0.6395 > mean(lifetimes<1) [1] 0.6395 e) Estimate the median system lifetime > median(lifetimes) [1] 0.6714813 f) Estimate the 10 th percentile of system lifetimes > quantile ( lifetimes , 0.1 ) 10 % 0.09988259 g) What seems to be the distribution of system lifetimes? (histogram etc) It seems to be the exponential distribution hist ( lifetimes , col = \"blue\" , nclass = 30 ) 4.2 Basic bootstrap CI The following measurements were given for the cylindrical compressive strength (in MPa) for 11 prestressed concrete beams: 38.43, 38.43, 38.39, 38.83, 38.45, 38.35, 38.43, 38.31, 38.32, 38.48, 38.50 38.43, 38.43, 38.39, 38.83, 38.45, 38.35, 38.43, 38.31, 38.32, 38.48, 38.50 1000 bootstrap samples (each sample hence consisting of 11 measurements) were generated from these data, and the 1000 bootstrap means were arranged on order. Refer to the smallest as \\bar{x}^*_{(1)} \\bar{x}^*_{(1)} , the second smallest as \\bar{x}^*_{(2)} \\bar{x}^*_{(2)} and so on, with the largest being \\bar{x}^*_{(1000)} \\bar{x}^*_{(1000)} . Assume that \\bar{x}^*_{(25)} = 38.3818\\\\ \\bar{x}^*_{(26)} = 38.3818\\\\ \\bar{x}^*_{(50)} = 38.3909\\\\ \\bar{x}^*_{(51)} = 38.3918\\\\ \\bar{x}^*_{(950)} = 38.5218\\\\ \\bar{x}^*_{(951)} = 38.5236\\\\ \\bar{x}^*_{(975)} = 38.5382\\\\ \\bar{x}^*_{(976)} = 38.5391\\\\ \\bar{x}^*_{(25)} = 38.3818\\\\ \\bar{x}^*_{(26)} = 38.3818\\\\ \\bar{x}^*_{(50)} = 38.3909\\\\ \\bar{x}^*_{(51)} = 38.3918\\\\ \\bar{x}^*_{(950)} = 38.5218\\\\ \\bar{x}^*_{(951)} = 38.5236\\\\ \\bar{x}^*_{(975)} = 38.5382\\\\ \\bar{x}^*_{(976)} = 38.5391\\\\ a) Compute a 95% bootstrap confidence interval for the mean compressive strength. We need to find: [q_{0.025}, q_{0.975}] [q_{0.025}, q_{0.975}] By definition 1.7 q_p = (x_{(np)}+x_{(np+1}))/2 q_p = (x_{(np)}+x_{(np+1}))/2 So q_{0.025} = (x_{1000*0.025}+x_{1000*0.025+1})/2 = \\\\ (x_{25}+ x_{26})/2 = (38.3818 + 38.3818)/2 = 38.3818 q_{0.025} = (x_{1000*0.025}+x_{1000*0.025+1})/2 = \\\\ (x_{25}+ x_{26})/2 = (38.3818 + 38.3818)/2 = 38.3818 And q_{0.975}= (x_{1000*0.975}+x_{1000*0.975+1})/2= \\\\ (x_{975}+x_{976})/2= (38.5382 + 38.5391)/2 = 38.53865 q_{0.975}= (x_{1000*0.975}+x_{1000*0.975+1})/2= \\\\ (x_{975}+x_{976})/2= (38.5382 + 38.5391)/2 = 38.53865 The answer is that we accept that \\bar{x} \\in [38.3818, 38.53865] \\bar{x} \\in [38.3818, 38.53865] b) Compute a 90% bootstrap confidence interval for the mean compressive strength. We know \\alpha = 1 - \\frac{90\\%}{100\\%} = 0.1 \\\\ \\alpha = 1 - \\frac{90\\%}{100\\%} = 0.1 \\\\ We need to find [q_{\\alpha/2}, q_{1-\\alpha/2}] = [q_{0.05}, q_{0.95}] [q_{\\alpha/2}, q_{1-\\alpha/2}] = [q_{0.05}, q_{0.95}] So q_{0.05} = (x_{50}+x_{51})/2 = (38.3909+38.3918)/2 = 38.39135 \\\\ q_{0.95} = (x_{950}+x_{951})/2 = (38.5218+38.5236)/2 = 38.5227 q_{0.05} = (x_{50}+x_{51})/2 = (38.3909+38.3918)/2 = 38.39135 \\\\ q_{0.95} = (x_{950}+x_{951})/2 = (38.5218+38.5236)/2 = 38.5227 The answer is that we accept that \\bar{x} \\in [38.39135, 38.5227] \\bar{x} \\in [38.39135, 38.5227] 4.3 Various bootstrap CIs Consider the data from the exercise above. These data are entered into R as: x <- c ( 38.43 , 38.43 , 38.39 , 38.83 , 38.45 , 38.35 , 38.43 , 38.31 , 38.32 , 38.48 , 38.50 ) Now generate k = 1000 k = 1000 bootstrap samples and compute the 1000 means (go higher if your computer is fine with it) a) What are the 2.5%, and 97.5% quantiles (so what is the 95% confidence interval for \\mu \\mu without assuming any distribution)? > k <- 10000 > x <- c ( 38.43 , 38.43 , 38.39 , 38.83 , 38.45 , 38.35 , + 38.43 , 38.31 , 38.32 , 38.48 , 38.50 ) > simSamples <- replicate ( k , sample ( x , replace = TRUE )) > simMeans <- apply ( simSamples , 2 , mean ) > hist ( simMeans ) > quantile ( simMeans , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.38091 38.53727 b) Find the 95% confidence interval for \\mu \\mu by the parametric bootstrap assuming the normal distribution for the observations. Compare with the classical analytic approach based on the t-distribution from Chapter 2. Parametric distribution: > simSamples <- replicate ( k , rnorm ( length ( x ), xBar , sBar )) > simMean <- apply ( simSamples , 2 , mean ) > quantile ( simMean , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.36430 38.53135 Based on the t-distribution: > c ( xBar - qt ( 0.975 , df = length ( x ) -1 ) * sBar / sqrt ( length ( x )), + xBar + qt ( 0.975 , df = length ( x ) -1 ) * sBar / sqrt ( length ( x ))) [ 1 ] 38.35250 38.54205 > t.test ( x ) One Sample t - test data : x t = 903.89 , df = 10 , p - value < 2.2e-16 alternative hypothesis : true mean is not equal to 0 95 percent confidence interval : 38.35250 38.54205 sample estimates : mean of x 38.44727 c) Find the 95% confidence interval for \\mu \\mu by the parametric bootstrap assuming the log-normal distribution for the observations. > logx <- log ( x ) > logxMean <- mean ( logx ) > logxSd <- sd ( logx ) > sim_logx <- replicate ( k , rlnorm ( length ( logx ), logxMean , logxSd )) > sim_mean <- apply ( sim_logx , 2 , mean ) > quantile ( sim_mean , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.36428 38.53088 d) Find the 95% confidence interval for the lower quartile Q_1 Q_1 by the parametric bootstrap assuming the normal distribution for the observations. > Q1 <- function ( x ) { quantile ( x , 0.25 )} > xBar <- mean ( x ) > sBar <- sd ( x ) > simSamples <- replicate ( k , rnorm ( length ( x ), xBar , sBar )) > simQ1 <- apply ( simSamples , 2 , Q1 ) > quantile ( simQ1 , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.25936 38.46556 e) Find the 95% confidence interval for the lower quartile Q_1 Q_1 by the non-parametric bootstrap (so without any distributional assumptions) > simSamples <- replicate ( k , sample ( x , replace = TRUE )) > simQ1_nonparametric <- apply ( simSamples , 2 , Q1 ) > quantile ( simQ1_nonparametric , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.315 38.430 4.4 Two-sample TV data A TV producer had 20 consumers evaluate the quality of two different TV flat screens - 10 consumers for each screen. A scale from 1 (worst) up to 5 (best) were used and the following results were obtained: TV screen 1 TV screen 2 1 3 2 4 1 2 3 4 2 2 1 3 2 2 3 4 1 3 1 2 a) Compare the two means without assuming any distribution for the two samples (non-parametric bootstrap confidence interval and relevant hypothesis test interpretation). tv1 <- c ( 1 , 2 , 1 , 3 , 2 , 1 , 2 , 3 , 1 , 1 ) tv2 <- c ( 3 , 4 , 2 , 4 , 2 , 3 , 2 , 4 , 3 , 2 ) k <- 100000 sim_tv1 <- replicate ( k , sample ( tv1 , replace = TRUE )) sim_tv2 <- replicate ( k , sample ( tv2 , replace = TRUE )) means_sim_tv1 <- apply ( sim_tv1 , 2 , mean ) means_sim_tv2 <- apply ( sim_tv2 , 2 , mean ) sim_dif <- means_sim_tv1 - means_sim_tv2 quantile ( sim_dif , c ( 0.025 , 0.975 )) 2.5 % 97.5% -1.9 -0.5 If: H_0 :\\ \\mu_1= \\mu_2 H_0 :\\ \\mu_1= \\mu_2 so we reject the null hypothesis, since 0 is not included in the CI of the differences. b) Compare the two means assuming normal distributions for the two samples without using simulations (or rather: assuming/hoping that the sample sizes are large enough to make the results approximately valid). t.test ( tv1 , tv2 ) Welch Two Sample t - test data : tv1 and tv2 t = -3.1574 , df = 17.932 , p - value = 0.005468 alternative hypothesis : true difference in means is not equal to 0 95 percent confidence interval : -1.99869 -0.40131 sample estimates : mean of x mean of y 1.7 2.9 c) Compare the two means assuming normal distributions for the two samples simulation based (parametric bootstrap confidence interval and relevant hypothesis test interpretation \u2013 in spite of the obviously wrong assumption). tv1 <- c ( 1 , 2 , 1 , 3 , 2 , 1 , 2 , 3 , 1 , 1 ) tv2 <- c ( 3 , 4 , 2 , 4 , 2 , 3 , 2 , 4 , 3 , 2 ) k <- 100000 n <- length ( tv1 ) sim_norm_tv1 <- replicate ( k , rnorm ( n , mean = mean ( tv1 ), sd = sd ( tv1 ) )) sim_norm_tv2 <- replicate ( k , rnorm ( n , mean = mean ( tv2 ), sd = sd ( tv2 ) )) means_sim_tv1 <- apply ( sim_norm_tv1 , 2 , mean ) means_sim_tv2 <- apply ( sim_norm_tv2 , 2 , mean ) sim_norm_dif <- means_sim_tv1 - means_sim_tv2 quantile ( sim_norm_dif , c ( 0.025 , 0.975 )) 2.5 % 97.5% -1.9371878 -0.4560157 We reject the null hypothesis of \\mu_1=\\mu_2 \\mu_1=\\mu_2 4.5 Non-linear error propagation The pressure P P , and the volume V V of one mole of an ideal gas are related by the equation PV = 8.31T PV = 8.31T , when P P is measured in kilopascals, T T is measured in kelvins, and V V is measured in liters. a) Assume that P P is measured to be 240.48 kPa 240.48 kPa and V V to be 9.987 L 9.987 L with known measurement errors (given as standard deviations): 0.03 kPa 0.03 kPa and$ 0.002 L$. Estimate T T and find the uncertainty in the estimate. We know: $$ PV = 8.31T\\ T = \\frac{PV}{8.31} $$ Estimate T T : $$ \\hat{T} = 240.48*9.987 / 8.31 = 289.0101 $$ Differentiate the function with respect to both p and v: f(p,v) = \\frac{pv}{8.31} \\\\ \\frac{\\partial f}{\\partial p} = \\frac{1*p^0v}{8.31}=\\frac{v}{8.31} \\\\ \\frac{\\partial f}{\\partial v} = \\frac{p*1*v^0}{8.31} = \\frac{p}{8.31} \\\\ f(p,v) = \\frac{pv}{8.31} \\\\ \\frac{\\partial f}{\\partial p} = \\frac{1*p^0v}{8.31}=\\frac{v}{8.31} \\\\ \\frac{\\partial f}{\\partial v} = \\frac{p*1*v^0}{8.31} = \\frac{p}{8.31} \\\\ Calculate the uncertainty: \\sigma^2_{\\hat{T}} = \\left(\\frac{\\partial f}{\\partial p}\\right)^2*\\sigma^2_p+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{v^2}{8.31^2} * \\sigma^2_p + \\frac{p^2}{8.31^2}*\\sigma^2_v =\\\\ 9.987^2/8.31^2*0.03^2+240.48^2/8.31^2*0.002^2 = 0.3210887 \\\\ \\sigma^2_{\\hat{T}} = \\left(\\frac{\\partial f}{\\partial p}\\right)^2*\\sigma^2_p+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{v^2}{8.31^2} * \\sigma^2_p + \\frac{p^2}{8.31^2}*\\sigma^2_v =\\\\ 9.987^2/8.31^2*0.03^2+240.48^2/8.31^2*0.002^2 = 0.3210887 \\\\ So the uncertainty is: \\sigma_{\\hat{T}} = \\sqrt{0.3210887} = 0.06818855 \\sigma_{\\hat{T}} = \\sqrt{0.3210887} = 0.06818855 b) Assume that P P is measured to be 240.48kPa 240.48kPa and T T to be 289.12K 289.12K with known measurement errors (given as standard deviations): 0.03kPa 0.03kPa and 0.02K 0.02K . Estimate V V and find the uncertainty in the estimate. We know: $$ V = \\frac{8.31T}{P}\\ $$ Estimate $$ \\hat{V} = 8.31*289.12/240.48= 9.990798 $$ Differentiate the function with respect to both p and v: $$ f(p,v) = \\frac{8.31t}{p} \\ \\frac{\\partial f}{\\partial t} = \\frac{1*t^0*8.31}{p}=\\frac{8.31}{p} \\ \\frac{\\partial f}{\\partial p} = 8.31t*-1*p^{-1-1} =- \\frac{8.31t}{p^2} \\ $$ Calculate the uncertainty: $$ \\sigma^2_{\\hat{V}} = \\left(\\frac{\\partial f}{\\partial t}\\right) 2*\\sigma 2_t+\\left(\\frac{\\partial f}{\\partial p}\\right) 2*\\sigma 2_p = \\ \\frac{8.31 2}{p 2} * \\sigma^2_t + \\left( -\\frac{8.31*t}{p^2}\\sigma_p \\right)^2 =\\ 8.31 2/240.48 2*0.02^2 + (- 8.31*289.12/240.48 2*0.03) 2= 0.001425149 ^2\\ $$ So the uncertainty is: $$ \\sigma_{\\hat{T}} = \\sqrt{0.001425149 ^2} = 0.001425149 $$ c) Assume that V V is measured to be 9.987 L 9.987 L and T T to be 289.12 K 289.12 K with known measurement errors (given as standard deviations): 0.002 L 0.002 L and 0.02 K 0.02 K . Estimate P and find the uncertainty in the estimate. We know: P = \\frac{8.31T}{V}\\\\ P = \\frac{8.31T}{V}\\\\ Estimate P P : \\hat{P} = 8.31*289.12/9.987 = 240.5715 \\hat{P} = 8.31*289.12/9.987 = 240.5715 Differentiate the function with respect to both t and v: f(t,v) = \\frac{8.31t}{v} \\\\ \\frac{\\partial f}{\\partial t} = \\frac{1*t^0*8.31}{v}=\\frac{8.31}{v} \\\\ \\frac{\\partial f}{\\partial v} = 8.31t*-1*v^{-1-1} =- \\frac{8.31t}{v^2} \\\\ f(t,v) = \\frac{8.31t}{v} \\\\ \\frac{\\partial f}{\\partial t} = \\frac{1*t^0*8.31}{v}=\\frac{8.31}{v} \\\\ \\frac{\\partial f}{\\partial v} = 8.31t*-1*v^{-1-1} =- \\frac{8.31t}{v^2} \\\\ Calculate the uncertainty: \\sigma^2_{\\hat{P}} = \\left(\\frac{\\partial f}{\\partial t}\\right)^2*\\sigma^2_t+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{8.31^2}{v^2} * \\sigma^2_t + \\left( -\\frac{8.31*t}{v^2}\\sigma_v \\right)^2 =\\\\ 8.31^2/9.987^2*0.02^2 + (- 8.31*289.12/9.987^2*0.002)^2= 0.00259796\\\\ \\sigma^2_{\\hat{P}} = \\left(\\frac{\\partial f}{\\partial t}\\right)^2*\\sigma^2_t+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{8.31^2}{v^2} * \\sigma^2_t + \\left( -\\frac{8.31*t}{v^2}\\sigma_v \\right)^2 =\\\\ 8.31^2/9.987^2*0.02^2 + (- 8.31*289.12/9.987^2*0.002)^2= 0.00259796\\\\ So the uncertainty is: \\sigma_{\\hat{T}} = \\sqrt{0.00259796} = 0.05097019 \\sigma_{\\hat{T}} = \\sqrt{0.00259796} = 0.05097019 d) Try to answer one or more of these questions by simulation (assume that the errors are normally distributed). Let's do simulations in order to estimate P P and find the the uncertainty in the estimate, where: $$ P = \\frac{8.31T}{V}\\ $$ > n <- 10000 > Ts <- rnorm ( n , mean = 289.12 , sd = 0.02 ) > Vs <- rnorm ( n , mean = 9.987 , sd = 0.002 ) > p <- 8.31 * Ts / Vs > mean ( p ) [ 1 ] 240.5706 > sd ( p ) [ 1 ] 0.05104125","title":"4 Simulation Methods"},{"location":"chapter_4_1/#4-simulation-methods","text":"","title":"4 Simulation methods"},{"location":"chapter_4_1/#41-reliability-system-lifetime","text":"A system consists of three components A, B and C serially connected, such that A is positioned before B, which is again positioned before C. The system will be functioning only so long as A, B and C are all functioning. The lifetime in months of the three components are assumed to follow exponential distributions with means: 2 months, 3 months and 5 months, respectively (hence there are three random variables, X_{A} X_{A} , X_B X_B and X_C X_C with exponential distributions with \\lambda_{A} \\lambda_{A} = \u00bd, \\lambda_{B} \\lambda_{B} = \u2153 and \\lambda_{C} \\lambda_{C} = \u2155 resp.)","title":"4.1 Reliability: System lifetime"},{"location":"chapter_4_1/#a","text":"Generate, by simulation, a large number (at least 1000 \u2013 go for 10000 or 100000 if your computer is up for it) of system lifetimes (hint: consider how the random variable Y = System lifetime is a function of the three X-variables: is it the sum, the mean, the median, the minimum, the maximum, the range or something even different?). The lifetime can be seen as the minimal value of the three random component lifetimes \\text{\"Lifetime\"} = min(X_A,X_B,X_C) \\text{\"Lifetime\"} = min(X_A,X_B,X_C) k <- 10000 xA <- rexp ( k , 1 / 2 ) xB <- rexp ( k , 1 / 3 ) xC <- rexp ( k , 1 / 5 ) x <- cbind ( xA , xB , xC ) lifetimes <- apply ( x , 1 , min ) # The second argument in apply() function, 1, means that there should be used rows (NOT columns) for finding the minimal value","title":"a)"},{"location":"chapter_4_1/#b","text":"Estimate the mean system lifetime. \\bar{x} = 0.9770395 \\bar{x} = 0.9770395 > mean ( lifetimes ) [ 1 ] 0.9770395","title":"b)"},{"location":"chapter_4_1/#c","text":"Estimate the standard deviation of system lifetimes. \\bar{s} = 0.9791683 \\bar{s} = 0.9791683 > sd ( lifetimes ) [ 1 ] 0.9791683","title":"c)"},{"location":"chapter_4_1/#d","text":"Estimate the probability that the system fails within 1 month. P(X<1)= 0.6395 P(X<1)= 0.6395 > mean(lifetimes<1) [1] 0.6395","title":"d)"},{"location":"chapter_4_1/#e","text":"Estimate the median system lifetime > median(lifetimes) [1] 0.6714813","title":"e)"},{"location":"chapter_4_1/#f","text":"Estimate the 10 th percentile of system lifetimes > quantile ( lifetimes , 0.1 ) 10 % 0.09988259","title":"f)"},{"location":"chapter_4_1/#g","text":"What seems to be the distribution of system lifetimes? (histogram etc) It seems to be the exponential distribution hist ( lifetimes , col = \"blue\" , nclass = 30 )","title":"g)"},{"location":"chapter_4_1/#42-basic-bootstrap-ci","text":"The following measurements were given for the cylindrical compressive strength (in MPa) for 11 prestressed concrete beams: 38.43, 38.43, 38.39, 38.83, 38.45, 38.35, 38.43, 38.31, 38.32, 38.48, 38.50 38.43, 38.43, 38.39, 38.83, 38.45, 38.35, 38.43, 38.31, 38.32, 38.48, 38.50 1000 bootstrap samples (each sample hence consisting of 11 measurements) were generated from these data, and the 1000 bootstrap means were arranged on order. Refer to the smallest as \\bar{x}^*_{(1)} \\bar{x}^*_{(1)} , the second smallest as \\bar{x}^*_{(2)} \\bar{x}^*_{(2)} and so on, with the largest being \\bar{x}^*_{(1000)} \\bar{x}^*_{(1000)} . Assume that \\bar{x}^*_{(25)} = 38.3818\\\\ \\bar{x}^*_{(26)} = 38.3818\\\\ \\bar{x}^*_{(50)} = 38.3909\\\\ \\bar{x}^*_{(51)} = 38.3918\\\\ \\bar{x}^*_{(950)} = 38.5218\\\\ \\bar{x}^*_{(951)} = 38.5236\\\\ \\bar{x}^*_{(975)} = 38.5382\\\\ \\bar{x}^*_{(976)} = 38.5391\\\\ \\bar{x}^*_{(25)} = 38.3818\\\\ \\bar{x}^*_{(26)} = 38.3818\\\\ \\bar{x}^*_{(50)} = 38.3909\\\\ \\bar{x}^*_{(51)} = 38.3918\\\\ \\bar{x}^*_{(950)} = 38.5218\\\\ \\bar{x}^*_{(951)} = 38.5236\\\\ \\bar{x}^*_{(975)} = 38.5382\\\\ \\bar{x}^*_{(976)} = 38.5391\\\\","title":"4.2 Basic bootstrap CI"},{"location":"chapter_4_1/#a_1","text":"Compute a 95% bootstrap confidence interval for the mean compressive strength. We need to find: [q_{0.025}, q_{0.975}] [q_{0.025}, q_{0.975}] By definition 1.7 q_p = (x_{(np)}+x_{(np+1}))/2 q_p = (x_{(np)}+x_{(np+1}))/2 So q_{0.025} = (x_{1000*0.025}+x_{1000*0.025+1})/2 = \\\\ (x_{25}+ x_{26})/2 = (38.3818 + 38.3818)/2 = 38.3818 q_{0.025} = (x_{1000*0.025}+x_{1000*0.025+1})/2 = \\\\ (x_{25}+ x_{26})/2 = (38.3818 + 38.3818)/2 = 38.3818 And q_{0.975}= (x_{1000*0.975}+x_{1000*0.975+1})/2= \\\\ (x_{975}+x_{976})/2= (38.5382 + 38.5391)/2 = 38.53865 q_{0.975}= (x_{1000*0.975}+x_{1000*0.975+1})/2= \\\\ (x_{975}+x_{976})/2= (38.5382 + 38.5391)/2 = 38.53865 The answer is that we accept that \\bar{x} \\in [38.3818, 38.53865] \\bar{x} \\in [38.3818, 38.53865]","title":"a)"},{"location":"chapter_4_1/#b_1","text":"Compute a 90% bootstrap confidence interval for the mean compressive strength. We know \\alpha = 1 - \\frac{90\\%}{100\\%} = 0.1 \\\\ \\alpha = 1 - \\frac{90\\%}{100\\%} = 0.1 \\\\ We need to find [q_{\\alpha/2}, q_{1-\\alpha/2}] = [q_{0.05}, q_{0.95}] [q_{\\alpha/2}, q_{1-\\alpha/2}] = [q_{0.05}, q_{0.95}] So q_{0.05} = (x_{50}+x_{51})/2 = (38.3909+38.3918)/2 = 38.39135 \\\\ q_{0.95} = (x_{950}+x_{951})/2 = (38.5218+38.5236)/2 = 38.5227 q_{0.05} = (x_{50}+x_{51})/2 = (38.3909+38.3918)/2 = 38.39135 \\\\ q_{0.95} = (x_{950}+x_{951})/2 = (38.5218+38.5236)/2 = 38.5227 The answer is that we accept that \\bar{x} \\in [38.39135, 38.5227] \\bar{x} \\in [38.39135, 38.5227]","title":"b)"},{"location":"chapter_4_1/#43-various-bootstrap-cis","text":"Consider the data from the exercise above. These data are entered into R as: x <- c ( 38.43 , 38.43 , 38.39 , 38.83 , 38.45 , 38.35 , 38.43 , 38.31 , 38.32 , 38.48 , 38.50 ) Now generate k = 1000 k = 1000 bootstrap samples and compute the 1000 means (go higher if your computer is fine with it)","title":"4.3 Various bootstrap CIs"},{"location":"chapter_4_1/#a_2","text":"What are the 2.5%, and 97.5% quantiles (so what is the 95% confidence interval for \\mu \\mu without assuming any distribution)? > k <- 10000 > x <- c ( 38.43 , 38.43 , 38.39 , 38.83 , 38.45 , 38.35 , + 38.43 , 38.31 , 38.32 , 38.48 , 38.50 ) > simSamples <- replicate ( k , sample ( x , replace = TRUE )) > simMeans <- apply ( simSamples , 2 , mean ) > hist ( simMeans ) > quantile ( simMeans , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.38091 38.53727","title":"a)"},{"location":"chapter_4_1/#b_2","text":"Find the 95% confidence interval for \\mu \\mu by the parametric bootstrap assuming the normal distribution for the observations. Compare with the classical analytic approach based on the t-distribution from Chapter 2. Parametric distribution: > simSamples <- replicate ( k , rnorm ( length ( x ), xBar , sBar )) > simMean <- apply ( simSamples , 2 , mean ) > quantile ( simMean , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.36430 38.53135 Based on the t-distribution: > c ( xBar - qt ( 0.975 , df = length ( x ) -1 ) * sBar / sqrt ( length ( x )), + xBar + qt ( 0.975 , df = length ( x ) -1 ) * sBar / sqrt ( length ( x ))) [ 1 ] 38.35250 38.54205 > t.test ( x ) One Sample t - test data : x t = 903.89 , df = 10 , p - value < 2.2e-16 alternative hypothesis : true mean is not equal to 0 95 percent confidence interval : 38.35250 38.54205 sample estimates : mean of x 38.44727","title":"b)"},{"location":"chapter_4_1/#c_1","text":"Find the 95% confidence interval for \\mu \\mu by the parametric bootstrap assuming the log-normal distribution for the observations. > logx <- log ( x ) > logxMean <- mean ( logx ) > logxSd <- sd ( logx ) > sim_logx <- replicate ( k , rlnorm ( length ( logx ), logxMean , logxSd )) > sim_mean <- apply ( sim_logx , 2 , mean ) > quantile ( sim_mean , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.36428 38.53088","title":"c)"},{"location":"chapter_4_1/#d_1","text":"Find the 95% confidence interval for the lower quartile Q_1 Q_1 by the parametric bootstrap assuming the normal distribution for the observations. > Q1 <- function ( x ) { quantile ( x , 0.25 )} > xBar <- mean ( x ) > sBar <- sd ( x ) > simSamples <- replicate ( k , rnorm ( length ( x ), xBar , sBar )) > simQ1 <- apply ( simSamples , 2 , Q1 ) > quantile ( simQ1 , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.25936 38.46556","title":"d)"},{"location":"chapter_4_1/#e_1","text":"Find the 95% confidence interval for the lower quartile Q_1 Q_1 by the non-parametric bootstrap (so without any distributional assumptions) > simSamples <- replicate ( k , sample ( x , replace = TRUE )) > simQ1_nonparametric <- apply ( simSamples , 2 , Q1 ) > quantile ( simQ1_nonparametric , c ( 0.025 , 0.975 )) 2.5 % 97.5% 38.315 38.430","title":"e)"},{"location":"chapter_4_1/#44-two-sample-tv-data","text":"A TV producer had 20 consumers evaluate the quality of two different TV flat screens - 10 consumers for each screen. A scale from 1 (worst) up to 5 (best) were used and the following results were obtained: TV screen 1 TV screen 2 1 3 2 4 1 2 3 4 2 2 1 3 2 2 3 4 1 3 1 2","title":"4.4 Two-sample TV data"},{"location":"chapter_4_1/#a_3","text":"Compare the two means without assuming any distribution for the two samples (non-parametric bootstrap confidence interval and relevant hypothesis test interpretation). tv1 <- c ( 1 , 2 , 1 , 3 , 2 , 1 , 2 , 3 , 1 , 1 ) tv2 <- c ( 3 , 4 , 2 , 4 , 2 , 3 , 2 , 4 , 3 , 2 ) k <- 100000 sim_tv1 <- replicate ( k , sample ( tv1 , replace = TRUE )) sim_tv2 <- replicate ( k , sample ( tv2 , replace = TRUE )) means_sim_tv1 <- apply ( sim_tv1 , 2 , mean ) means_sim_tv2 <- apply ( sim_tv2 , 2 , mean ) sim_dif <- means_sim_tv1 - means_sim_tv2 quantile ( sim_dif , c ( 0.025 , 0.975 )) 2.5 % 97.5% -1.9 -0.5 If: H_0 :\\ \\mu_1= \\mu_2 H_0 :\\ \\mu_1= \\mu_2 so we reject the null hypothesis, since 0 is not included in the CI of the differences.","title":"a)"},{"location":"chapter_4_1/#b_3","text":"Compare the two means assuming normal distributions for the two samples without using simulations (or rather: assuming/hoping that the sample sizes are large enough to make the results approximately valid). t.test ( tv1 , tv2 ) Welch Two Sample t - test data : tv1 and tv2 t = -3.1574 , df = 17.932 , p - value = 0.005468 alternative hypothesis : true difference in means is not equal to 0 95 percent confidence interval : -1.99869 -0.40131 sample estimates : mean of x mean of y 1.7 2.9","title":"b)"},{"location":"chapter_4_1/#c_2","text":"Compare the two means assuming normal distributions for the two samples simulation based (parametric bootstrap confidence interval and relevant hypothesis test interpretation \u2013 in spite of the obviously wrong assumption). tv1 <- c ( 1 , 2 , 1 , 3 , 2 , 1 , 2 , 3 , 1 , 1 ) tv2 <- c ( 3 , 4 , 2 , 4 , 2 , 3 , 2 , 4 , 3 , 2 ) k <- 100000 n <- length ( tv1 ) sim_norm_tv1 <- replicate ( k , rnorm ( n , mean = mean ( tv1 ), sd = sd ( tv1 ) )) sim_norm_tv2 <- replicate ( k , rnorm ( n , mean = mean ( tv2 ), sd = sd ( tv2 ) )) means_sim_tv1 <- apply ( sim_norm_tv1 , 2 , mean ) means_sim_tv2 <- apply ( sim_norm_tv2 , 2 , mean ) sim_norm_dif <- means_sim_tv1 - means_sim_tv2 quantile ( sim_norm_dif , c ( 0.025 , 0.975 )) 2.5 % 97.5% -1.9371878 -0.4560157 We reject the null hypothesis of \\mu_1=\\mu_2 \\mu_1=\\mu_2","title":"c)"},{"location":"chapter_4_1/#45-non-linear-error-propagation","text":"The pressure P P , and the volume V V of one mole of an ideal gas are related by the equation PV = 8.31T PV = 8.31T , when P P is measured in kilopascals, T T is measured in kelvins, and V V is measured in liters.","title":"4.5 Non-linear error propagation"},{"location":"chapter_4_1/#a_4","text":"Assume that P P is measured to be 240.48 kPa 240.48 kPa and V V to be 9.987 L 9.987 L with known measurement errors (given as standard deviations): 0.03 kPa 0.03 kPa and$ 0.002 L$. Estimate T T and find the uncertainty in the estimate. We know: $$ PV = 8.31T\\ T = \\frac{PV}{8.31} $$ Estimate T T : $$ \\hat{T} = 240.48*9.987 / 8.31 = 289.0101 $$ Differentiate the function with respect to both p and v: f(p,v) = \\frac{pv}{8.31} \\\\ \\frac{\\partial f}{\\partial p} = \\frac{1*p^0v}{8.31}=\\frac{v}{8.31} \\\\ \\frac{\\partial f}{\\partial v} = \\frac{p*1*v^0}{8.31} = \\frac{p}{8.31} \\\\ f(p,v) = \\frac{pv}{8.31} \\\\ \\frac{\\partial f}{\\partial p} = \\frac{1*p^0v}{8.31}=\\frac{v}{8.31} \\\\ \\frac{\\partial f}{\\partial v} = \\frac{p*1*v^0}{8.31} = \\frac{p}{8.31} \\\\ Calculate the uncertainty: \\sigma^2_{\\hat{T}} = \\left(\\frac{\\partial f}{\\partial p}\\right)^2*\\sigma^2_p+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{v^2}{8.31^2} * \\sigma^2_p + \\frac{p^2}{8.31^2}*\\sigma^2_v =\\\\ 9.987^2/8.31^2*0.03^2+240.48^2/8.31^2*0.002^2 = 0.3210887 \\\\ \\sigma^2_{\\hat{T}} = \\left(\\frac{\\partial f}{\\partial p}\\right)^2*\\sigma^2_p+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{v^2}{8.31^2} * \\sigma^2_p + \\frac{p^2}{8.31^2}*\\sigma^2_v =\\\\ 9.987^2/8.31^2*0.03^2+240.48^2/8.31^2*0.002^2 = 0.3210887 \\\\ So the uncertainty is: \\sigma_{\\hat{T}} = \\sqrt{0.3210887} = 0.06818855 \\sigma_{\\hat{T}} = \\sqrt{0.3210887} = 0.06818855","title":"a)"},{"location":"chapter_4_1/#b_4","text":"Assume that P P is measured to be 240.48kPa 240.48kPa and T T to be 289.12K 289.12K with known measurement errors (given as standard deviations): 0.03kPa 0.03kPa and 0.02K 0.02K . Estimate V V and find the uncertainty in the estimate. We know: $$ V = \\frac{8.31T}{P}\\ $$ Estimate $$ \\hat{V} = 8.31*289.12/240.48= 9.990798 $$ Differentiate the function with respect to both p and v: $$ f(p,v) = \\frac{8.31t}{p} \\ \\frac{\\partial f}{\\partial t} = \\frac{1*t^0*8.31}{p}=\\frac{8.31}{p} \\ \\frac{\\partial f}{\\partial p} = 8.31t*-1*p^{-1-1} =- \\frac{8.31t}{p^2} \\ $$ Calculate the uncertainty: $$ \\sigma^2_{\\hat{V}} = \\left(\\frac{\\partial f}{\\partial t}\\right) 2*\\sigma 2_t+\\left(\\frac{\\partial f}{\\partial p}\\right) 2*\\sigma 2_p = \\ \\frac{8.31 2}{p 2} * \\sigma^2_t + \\left( -\\frac{8.31*t}{p^2}\\sigma_p \\right)^2 =\\ 8.31 2/240.48 2*0.02^2 + (- 8.31*289.12/240.48 2*0.03) 2= 0.001425149 ^2\\ $$ So the uncertainty is: $$ \\sigma_{\\hat{T}} = \\sqrt{0.001425149 ^2} = 0.001425149 $$","title":"b)"},{"location":"chapter_4_1/#c_3","text":"Assume that V V is measured to be 9.987 L 9.987 L and T T to be 289.12 K 289.12 K with known measurement errors (given as standard deviations): 0.002 L 0.002 L and 0.02 K 0.02 K . Estimate P and find the uncertainty in the estimate. We know: P = \\frac{8.31T}{V}\\\\ P = \\frac{8.31T}{V}\\\\ Estimate P P : \\hat{P} = 8.31*289.12/9.987 = 240.5715 \\hat{P} = 8.31*289.12/9.987 = 240.5715 Differentiate the function with respect to both t and v: f(t,v) = \\frac{8.31t}{v} \\\\ \\frac{\\partial f}{\\partial t} = \\frac{1*t^0*8.31}{v}=\\frac{8.31}{v} \\\\ \\frac{\\partial f}{\\partial v} = 8.31t*-1*v^{-1-1} =- \\frac{8.31t}{v^2} \\\\ f(t,v) = \\frac{8.31t}{v} \\\\ \\frac{\\partial f}{\\partial t} = \\frac{1*t^0*8.31}{v}=\\frac{8.31}{v} \\\\ \\frac{\\partial f}{\\partial v} = 8.31t*-1*v^{-1-1} =- \\frac{8.31t}{v^2} \\\\ Calculate the uncertainty: \\sigma^2_{\\hat{P}} = \\left(\\frac{\\partial f}{\\partial t}\\right)^2*\\sigma^2_t+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{8.31^2}{v^2} * \\sigma^2_t + \\left( -\\frac{8.31*t}{v^2}\\sigma_v \\right)^2 =\\\\ 8.31^2/9.987^2*0.02^2 + (- 8.31*289.12/9.987^2*0.002)^2= 0.00259796\\\\ \\sigma^2_{\\hat{P}} = \\left(\\frac{\\partial f}{\\partial t}\\right)^2*\\sigma^2_t+\\left(\\frac{\\partial f}{\\partial v}\\right)^2*\\sigma^2_v = \\\\ \\frac{8.31^2}{v^2} * \\sigma^2_t + \\left( -\\frac{8.31*t}{v^2}\\sigma_v \\right)^2 =\\\\ 8.31^2/9.987^2*0.02^2 + (- 8.31*289.12/9.987^2*0.002)^2= 0.00259796\\\\ So the uncertainty is: \\sigma_{\\hat{T}} = \\sqrt{0.00259796} = 0.05097019 \\sigma_{\\hat{T}} = \\sqrt{0.00259796} = 0.05097019","title":"c)"},{"location":"chapter_4_1/#d_2","text":"Try to answer one or more of these questions by simulation (assume that the errors are normally distributed). Let's do simulations in order to estimate P P and find the the uncertainty in the estimate, where: $$ P = \\frac{8.31T}{V}\\ $$ > n <- 10000 > Ts <- rnorm ( n , mean = 289.12 , sd = 0.02 ) > Vs <- rnorm ( n , mean = 9.987 , sd = 0.002 ) > p <- 8.31 * Ts / Vs > mean ( p ) [ 1 ] 240.5706 > sd ( p ) [ 1 ] 0.05104125","title":"d)"},{"location":"chapter_5/","text":"5 Simple Linear Regression 5.1 Plastic film folding machine On a machine that folds plastic film the temperature may be varied in the range of 130-185 \u00b0C. For obtaining, if possible, a model for the influence of temperature on the folding thickness, n = 12 related set of values of temperature and the fold thickness were measured that is illustrated in the following figure: a) Determine by looking at the figure, which of the following sets of estimates for the parameters in the usual regression model is correct: \\hat{\\beta_0}=0 \\hat{\\beta_0}=0 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=36 \\hat{\\sigma}=36 \\hat{\\beta_0}=0 \\hat{\\beta_0}=0 , \\hat{\\beta_1}=0.9 \\hat{\\beta_1}=0.9 , \\hat{\\sigma}=3.6 \\hat{\\sigma}=3.6 \\hat{\\beta_0}=252 \\hat{\\beta_0}=252 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=3.6 \\hat{\\sigma}=3.6 \\hat{\\beta_0}=-252 \\hat{\\beta_0}=-252 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=36 \\hat{\\sigma}=36 \\hat{\\beta_0}=252 \\hat{\\beta_0}=252 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=36 \\hat{\\sigma}=36 The only possible intercept \\beta_0 \\beta_0 among the ones given in the answers is 252, because the line continues to ascend to the left, and it must cross y-axis somewhere above 130. The slope estimate of -0.9 in these two options looks reasonable, because the line goes downward. The estimated standard deviation of the error s_e =\\hat{\\sigma} s_e =\\hat{\\sigma} is 3.6, because from the figure it is clear that the points are NOT having an average vertical distance to the line in the size of 36. So the answer is 3. b) What is the only possible correct answer: The proportion of explained variation is 50% and the correlation is 0.98 The proportion of explained variation is 0% and the correlation is -0.98 The proportion of explained variation is 96% and the correlation is -1 The proportion of explained variation is 96% and the correlation is 0.98 The proportion of explained variation is 96% and the correlation is -0.98 The proportion of variation explained must be pretty high, because the observations are pretty close to the line. That means that 96% of total variation is explained by the line. Answer 1 and 4 are ruled out since the correlation clearly is negative. This also narrows the possibilities down to answer 3 and 5. And since the correlation is NOT exactly -1 (in which case the observations would be exactly on the line), the correct answer is: 5 5.2 Linear regression life time model A company manufactures an electronic device to be used in a very wide temperature range. The company knows that increased temperature shortens the life time of the device, and a study is therefore performed in which the life time is determined as a function of temperature. The following data is found: Temperature in Celsius (t) Life time in hours(y) 10 420 20 365 30 285 40 220 50 176 60 117 70 69 80 34 90 5 a) Calculate the 95% confidence interval for the slope in the usual linear regression model, which expresses the life time as a linear function of the temperature. By using the linear regression model Y_i = \\beta_0 + \\beta_1 t_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 Y_i = \\beta_0 + \\beta_1 t_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 t <- c ( 10 , 20 , 30 , 40 , 50 , 60 , 70 , 80 , 90 ) y <- c ( 420 , 365 , 285 , 220 , 176 , 117 , 69 , 34 , 5 ) tbar <- mean ( t ) ybar <- mean ( y ) # Find parameter estimates Sxx <- sum (( t - tbar ) ^ 2 ) beta1hat <- sum (( t - tbar ) * ( y - ybar )) / Sxx beta0hat <- ybar - beta1hat * tbar # Find the error variance estimate e <- y - ( beta0hat + beta1hat * t ) sigmahat <- sqrt ( sum ( e ^ 2 ) / ( length ( t ) -2 )) # Find the standart error for the slope sigmabeta1 <- sqrt ( sigmahat ^ 2 / Sxx ) sigmabeta1 # Find CI for the slope (Method 5.15) c ( beta1hat - qt (( 1-0.05 / 2 ), df = length ( t ) -2 ) * sigmabeta1 , beta1hat + qt (( 1-0.05 / 2 ), df = length ( t ) -2 ) * sigmabeta1 ) -5.918161 -4.708505 So the answer is that we accept \\beta_1 \\in [-5.918161 -4.708505] \\beta_1 \\in [-5.918161 -4.708505] b) Can a relation between temperature and life time be documented on level 5%? By the method 5.14 1.: H_{01}\\ :\\ \\beta_1= 0 \\\\ H_{11}\\ :\\ \\beta_1\\ne 0 H_{01}\\ :\\ \\beta_1= 0 \\\\ H_{11}\\ :\\ \\beta_1\\ne 0 2.: t_{obs, \\beta_{1}} = -20.77291 \\\\ t_{obs, \\beta_{1}} = -20.77291 \\\\ 3.: \\text{p-value}_{1} = 1.505039*10^{-7} \\text{p-value}_{1} = 1.505039*10^{-7} 4.: \\text{p-value}_1 \\text{p-value}_1 is less than \\alpha = 0.05 \\alpha = 0.05 , so we reject H_{01} H_{01} tobsbeta1 <- beta1hat / sigmabeta1 pvalue1 <- 2 * ( 1 - pt ( abs ( tobsbeta1 ), df = length ( t ) -2 )) 5.3 Yield of chemical process The yield y of a chemical process is a random variable whose value is considered to be a linear function of the temperature x. The following data of corresponding values of x and y is found: Temperature in \u00b0C (x) Yield in grams(y) 0 14 25 38 50 54 75 76 100 95 The average and standard deviation of temperature and yield are $$ \\bar{x} = 50 , s_x = 39.52847, \\bar{y}=55.4, s_y=31.66702 s_y=31.66702 $$ In the exercise the usual linear regression model is used Y_i = \\beta_0 + \\beta_1 X_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 Y_i = \\beta_0 + \\beta_1 X_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 a) Can a significant relationship between yield and temperature be documented on the usual significance level \\alpha = 0.05 \\alpha = 0.05 ? In R output P-value of the slope is only 6.27*10^{-5} 6.27*10^{-5} that is less than 0.05 0.05 . So we can conclude that there is a significant relationship between yield and temperature b) Give the 95% confidence interval of the expected yield at a temperature of x_{new}= 80 \u00b0C x_{new}= 80 \u00b0C . By method 5.18 \\hat\\beta_0+\\hat\\beta_1x_{new}\\pm t_{1-\\alpha/2} \\hat\\sigma \\sqrt{\\frac{1}{n}+\\frac{(x_{new}-\\bar{x})^2}{S_{xx}}} \\hat\\beta_0+\\hat\\beta_1x_{new}\\pm t_{1-\\alpha/2} \\hat\\sigma \\sqrt{\\frac{1}{n}+\\frac{(x_{new}-\\bar{x})^2}{S_{xx}}} x <- c ( 0 , 25 , 50 , 75 , 100 ) y <- c ( 14 , 38 , 54 , 76 , 95 ) fit <- lm ( y ~ x ) alpha <- 0.05 xnew <- 80 # By method 5.18 res <- coef ( fit )[ 1 ] + coef ( fit )[ 2 ] * xnew range <- qt (( 1 - alpha / 2 ), df = length ( x ) -2 ) * sigma ( fit ) * sqrt ( 1 / length ( x ) + ( xnew - mean ( x )) ^ 2 / sum (( x - mean ( x )) ^ 2 )) c ( res - range , res + range ) 75.79348 83.00652 # By using predict function predict ( fit , newdata = data.frame ( x = xnew ), interval = \"confidence\" , level = 1 - alpha ) fit lwr upr 79.4 75.79 83.01 Thus the answer is [75.79,83.01] [75.79,83.01] c) What is the upper quartile of the residuals? Upper quantile = Q_3 Q_3 = q_{0.75} q_{0.75} $$ pn= 0.75*5 = 3.75 $$ pn pn is not an integer, so we take \"next one\" in the list, that is 4. > sort ( fit $ residuals )[ 4 ] 4 0.6 Thus the answer is: 0.6 5.4 Plastic material In the manufacturing of a plastic material, it is believed that the cooling time has an influence on the impact strength. Therefore a study is carried out in which plastic material impact strength is determined for 4 different cooling times. The results of this experiment are shown in the following table: Cooling times in seconds(x) Impact strength in kJ/m^2 kJ/m^2 (y) 15 42.1 25 36.0 35 31.8 40 28.7 The following statistics may by used: $$ \\bar{x} = 28.75, \\bar{y}=34.65, S_{xx}=368.75 $$ a) What is the 95% confidence interval for the slope of the regression model, expressing the impact strength as a linear function of the cooling time? x <- c ( 15 , 25 , 35 , 40 ) y <- c ( 42.1 , 36.0 , 31.8 , 28.7 ) xbar <- 28.75 ybar <- 34.65 Sxx <- 368.75 fit <- lm ( y ~ x ) out <- summary ( fit ) beta1hat <- coef ( fit )[ 2 ] sigmabeta1 <- out $ coefficients [ 2 , 2 ] c ( beta1hat - qt (( 1-0.05 / 2 ), df = length ( x ) -2 ) * sigmabeta1 , beta1hat + qt (( 1-0.05 / 2 ), df = length ( x ) -2 ) * sigmabeta1 ) -0.6460407 -0.3966711 So the answer is that we accept \\beta_1 \\in [-0.6460407, -0.3966711] \\beta_1 \\in [-0.6460407, -0.3966711] b) Can you conclude that there is a relation between the impact strength and the cooling time at significance level \\alpha \\alpha = 5%? pvalue1 <- out $ coefficients [ 2 , 4 ] 0.003075239 \\text{p-value}_1 \\text{p-value}_1 is less than \\alpha = 0.05 \\alpha = 0.05 , so we can conclude that there is a relation between the impact strength and the cooling time. In other words, the relation is statically significant. c) For a similar plastic material the tabulated value for the linear relation between temperature and impact strength (i.e the slope) is -0.30. If the following hypothesis is tested (at level \\alpha \\alpha = 0.05) H_0: \\beta_1 = -0.30 \\\\ H_1: \\beta_1 \\ne -0.30 H_0: \\beta_1 = -0.30 \\\\ H_1: \\beta_1 \\ne -0.30 with the usual t-test statistic for such a test, what is the range (for t) within which the hypothesis is accepted? alpha <- 0.05 c ( qt ( alpha / 2 , df = 2 ), qt ( 1 - alpha / 2 , df = 2 )) -4.302653 4.302653 The critical values for the t-statistic with \u03bd = 2 degrees of freedom is [-4.302653, 4.302653] [-4.302653, 4.302653] 5.5 Water pollution In a study of pollution in a water stream, the concentration of pollution is measured at 5 different locations. The locations are at different distances to the pollution source. In the table below, these distances and the average pollution are given: Distance to the pollution source(km) Average concentration 2 11.5 4 10.2 6 10.3 8 9.68 10 9.32 a) What are the parameter estimates for the three unknown parameters in the usual linear regression model: 1) The intercept ( \\beta_0 \\beta_0 ), 2) the slope ( \\beta_1 \\beta_1 ) and 3) error standard deviation ( \\sigma \\sigma )? distances <- c ( 2 , 4 , 6 , 8 , 10 ) concentrations <- c ( 11.5 , 10.2 , 10.3 , 9.68 , 9.32 ) fit <- lm ( concentrations ~ distances ) out <- summary ( fit ) beta0hat <- coef ( fit )[ 1 ] 11.664 beta1hat <- coef ( fit )[ 2 ] -0.244 sigmahat <- sigma ( fit ) 0.348023 \\hat\\beta_0 = 11.664 \\\\ \\hat\\beta_1 = -0.244 \\\\ \\hat\\sigma = 0.348023 \\hat\\beta_0 = 11.664 \\\\ \\hat\\beta_1 = -0.244 \\\\ \\hat\\sigma = 0.348023 b) How large a part of the variation in concentration can be explained by the distance? out $ r.squared 0.8676188 R^2 = 0.8676188 R^2 = 0.8676188 Note that this is only an estimate. c) What is a 95%-confidence interval for the expected pollution concentration 7 km from the pollution source? predict ( fit , newdata = data.frame ( distances = dnew ), interval = \"confidence\" , level = 1 - alpha ) fit lwr upr 1 9.956 9.430636 10.48136 The answer: [9.430636, 10.48136] [9.430636, 10.48136] 5.6 Membrane pressure drop When purifying drinking water you can use a so-called membrane filtration. In an experiment one wishes to examine the relationship between the pressure drop across a membrane and the flux (flow per area) through the membrane. We observe the following 10 related values of pressure (x) and flux (y): Pressure(x) Flux(y) 1 1.02 1.15 2 2.08 0.85 3 2.89 1.56 4 4.01 1.72 5 5.32 4.32 6 5.83 5.07 7 7.26 5.00 8 7.96 5.31 9 9.11 6.17 10 9.99 7.04 a) What is the empirical correlation between pressure and flux estimated to? Give also an interpretation of the correlation. cor ( D $ pressure , D $ flux ) [ 1 ] 0.9638184 \\hat\\rho = r = 0.964 \\hat\\rho = r = 0.964 This means that flux increase with increasing pressure. b) What is a 90% confidence interval for the slope \\beta_1 \\beta_1 in the usual regression model? alpha <- 0.1 beta1hat <- coef ( fit )[ 2 ] sigmabeta1 <- out $ coefficients [ 2 , 2 ] c ( beta1hat - qt (( 1 - alpha / 2 ), df = out $ df [ 2 ]) * sigmabeta1 , beta1hat + qt (( 1 - alpha / 2 ), df = out $ df [ 2 ]) * sigmabeta1 ) 0.5911094 0.8538426 So the answer is that we accept \\beta_1 \\in [0.5911094, 0.8538426] \\beta_1 \\in [0.5911094, 0.8538426] c) How large a part of the flux-variation \\sum\\limits_{i=1}^{10}(y_i-\\bar{y})^2 \\sum\\limits_{i=1}^{10}(y_i-\\bar{y})^2 is not explained by pressure differences? 1 - cor ( D $ pressure , D $ flux ) ^ 2 0.07105402 d) Can you at significance level \\alpha \\alpha = 0.05 reject the hypothesis that the line passes through (0, 0)? The intercept should be equals to 0, if the line passes through (0,0). This means that if we can reject that the intercept equals to 0, so we can reject that the line passes through (0, 0). Therefore we formulate the null hypothesis and the alternative hypothesis as follows: $$ H_{00}: \\beta_0=0 \\ H_{01} : \\beta_0 \\ne 0 $$ pvalue0 <- out $ coefficients [ 1 , 4 ] 0.6806967 \\text{p-value}_0=0.68 \\text{p-value}_0=0.68 is higher than \\alpha=0.05 \\alpha=0.05 , so we need to accept that the line passes through (0, 0). e) A confidence interval for the line at three different pressure levels: x_{new}^A= 3.5 x_{new}^A= 3.5 , x^B_{new}=5.0 x^B_{new}=5.0 and , x^C_{new}=9.5 x^C_{new}=9.5 will look as follows: \\hat\\beta_0+\\beta_1*x^U_{new}\\pm C_U \\hat\\beta_0+\\beta_1*x^U_{new}\\pm C_U where U U then is either A A , B B or C C . Write the constants C_U C_U in increasing order. alpha <- 0.05 xnews <- c ( 3.5 , 5.0 , 9.5 ) CIs <- predict ( fit , newdata = data.frame ( pressure = xnews ), interval = \"confidence\" , level = 1 - alpha ) constants <- numeric ( 3 ) for ( i in 1 : 3 ){ constants [ i ] <- CIs [ i , 3 ] - CIs [ i , 1 ] } constants 0.4647513 0.3858058 0.6429206 C_A = 0.4647513 \\\\ C_B = 0.3858058 \\\\ C_C = 0.6429206 C_A = 0.4647513 \\\\ C_B = 0.3858058 \\\\ C_C = 0.6429206 This gives that: C_B < C_A < C_C C_B < C_A < C_C It can also be calculated without R as follows: By Method 5.18 constants differs only by this term: (x_{new}-\\bar{x})^2 (x_{new}-\\bar{x})^2 So since \\bar{x}=5.547 \\bar{x}=5.547 : (5.0-5.547)^2<(3.5-5.547)^2<(9.5-5.547)^2 \\\\ (x^B_{new}-5.547)^2<(x^A_{new}-5.547)^2<(x^C_{new}-5.547)^2 \\\\ C_B<C_A<C_C (5.0-5.547)^2<(3.5-5.547)^2<(9.5-5.547)^2 \\\\ (x^B_{new}-5.547)^2<(x^A_{new}-5.547)^2<(x^C_{new}-5.547)^2 \\\\ C_B<C_A<C_C","title":"5 Simple Linear Regression"},{"location":"chapter_5/#5-simple-linear-regression","text":"","title":"5 Simple Linear Regression"},{"location":"chapter_5/#51-plastic-film-folding-machine","text":"On a machine that folds plastic film the temperature may be varied in the range of 130-185 \u00b0C. For obtaining, if possible, a model for the influence of temperature on the folding thickness, n = 12 related set of values of temperature and the fold thickness were measured that is illustrated in the following figure:","title":"5.1 Plastic film folding machine"},{"location":"chapter_5/#a","text":"Determine by looking at the figure, which of the following sets of estimates for the parameters in the usual regression model is correct: \\hat{\\beta_0}=0 \\hat{\\beta_0}=0 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=36 \\hat{\\sigma}=36 \\hat{\\beta_0}=0 \\hat{\\beta_0}=0 , \\hat{\\beta_1}=0.9 \\hat{\\beta_1}=0.9 , \\hat{\\sigma}=3.6 \\hat{\\sigma}=3.6 \\hat{\\beta_0}=252 \\hat{\\beta_0}=252 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=3.6 \\hat{\\sigma}=3.6 \\hat{\\beta_0}=-252 \\hat{\\beta_0}=-252 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=36 \\hat{\\sigma}=36 \\hat{\\beta_0}=252 \\hat{\\beta_0}=252 , \\hat{\\beta_1}=-0.9 \\hat{\\beta_1}=-0.9 , \\hat{\\sigma}=36 \\hat{\\sigma}=36 The only possible intercept \\beta_0 \\beta_0 among the ones given in the answers is 252, because the line continues to ascend to the left, and it must cross y-axis somewhere above 130. The slope estimate of -0.9 in these two options looks reasonable, because the line goes downward. The estimated standard deviation of the error s_e =\\hat{\\sigma} s_e =\\hat{\\sigma} is 3.6, because from the figure it is clear that the points are NOT having an average vertical distance to the line in the size of 36. So the answer is 3.","title":"a)"},{"location":"chapter_5/#b","text":"What is the only possible correct answer: The proportion of explained variation is 50% and the correlation is 0.98 The proportion of explained variation is 0% and the correlation is -0.98 The proportion of explained variation is 96% and the correlation is -1 The proportion of explained variation is 96% and the correlation is 0.98 The proportion of explained variation is 96% and the correlation is -0.98 The proportion of variation explained must be pretty high, because the observations are pretty close to the line. That means that 96% of total variation is explained by the line. Answer 1 and 4 are ruled out since the correlation clearly is negative. This also narrows the possibilities down to answer 3 and 5. And since the correlation is NOT exactly -1 (in which case the observations would be exactly on the line), the correct answer is: 5","title":"b)"},{"location":"chapter_5/#52-linear-regression-life-time-model","text":"A company manufactures an electronic device to be used in a very wide temperature range. The company knows that increased temperature shortens the life time of the device, and a study is therefore performed in which the life time is determined as a function of temperature. The following data is found: Temperature in Celsius (t) Life time in hours(y) 10 420 20 365 30 285 40 220 50 176 60 117 70 69 80 34 90 5","title":"5.2 Linear regression life time model"},{"location":"chapter_5/#a_1","text":"Calculate the 95% confidence interval for the slope in the usual linear regression model, which expresses the life time as a linear function of the temperature. By using the linear regression model Y_i = \\beta_0 + \\beta_1 t_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 Y_i = \\beta_0 + \\beta_1 t_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 t <- c ( 10 , 20 , 30 , 40 , 50 , 60 , 70 , 80 , 90 ) y <- c ( 420 , 365 , 285 , 220 , 176 , 117 , 69 , 34 , 5 ) tbar <- mean ( t ) ybar <- mean ( y ) # Find parameter estimates Sxx <- sum (( t - tbar ) ^ 2 ) beta1hat <- sum (( t - tbar ) * ( y - ybar )) / Sxx beta0hat <- ybar - beta1hat * tbar # Find the error variance estimate e <- y - ( beta0hat + beta1hat * t ) sigmahat <- sqrt ( sum ( e ^ 2 ) / ( length ( t ) -2 )) # Find the standart error for the slope sigmabeta1 <- sqrt ( sigmahat ^ 2 / Sxx ) sigmabeta1 # Find CI for the slope (Method 5.15) c ( beta1hat - qt (( 1-0.05 / 2 ), df = length ( t ) -2 ) * sigmabeta1 , beta1hat + qt (( 1-0.05 / 2 ), df = length ( t ) -2 ) * sigmabeta1 ) -5.918161 -4.708505 So the answer is that we accept \\beta_1 \\in [-5.918161 -4.708505] \\beta_1 \\in [-5.918161 -4.708505]","title":"a)"},{"location":"chapter_5/#b_1","text":"Can a relation between temperature and life time be documented on level 5%? By the method 5.14 1.: H_{01}\\ :\\ \\beta_1= 0 \\\\ H_{11}\\ :\\ \\beta_1\\ne 0 H_{01}\\ :\\ \\beta_1= 0 \\\\ H_{11}\\ :\\ \\beta_1\\ne 0 2.: t_{obs, \\beta_{1}} = -20.77291 \\\\ t_{obs, \\beta_{1}} = -20.77291 \\\\ 3.: \\text{p-value}_{1} = 1.505039*10^{-7} \\text{p-value}_{1} = 1.505039*10^{-7} 4.: \\text{p-value}_1 \\text{p-value}_1 is less than \\alpha = 0.05 \\alpha = 0.05 , so we reject H_{01} H_{01} tobsbeta1 <- beta1hat / sigmabeta1 pvalue1 <- 2 * ( 1 - pt ( abs ( tobsbeta1 ), df = length ( t ) -2 ))","title":"b)"},{"location":"chapter_5/#53-yield-of-chemical-process","text":"The yield y of a chemical process is a random variable whose value is considered to be a linear function of the temperature x. The following data of corresponding values of x and y is found: Temperature in \u00b0C (x) Yield in grams(y) 0 14 25 38 50 54 75 76 100 95 The average and standard deviation of temperature and yield are $$ \\bar{x} = 50 , s_x = 39.52847, \\bar{y}=55.4, s_y=31.66702 s_y=31.66702 $$ In the exercise the usual linear regression model is used Y_i = \\beta_0 + \\beta_1 X_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5 Y_i = \\beta_0 + \\beta_1 X_i+ \\epsilon_i\\text{ , } \\epsilon_i \\sim N(0,\\sigma^2_{\\epsilon})\\text{, } i = 1,...,5","title":"5.3 Yield of chemical process"},{"location":"chapter_5/#a_2","text":"Can a significant relationship between yield and temperature be documented on the usual significance level \\alpha = 0.05 \\alpha = 0.05 ? In R output P-value of the slope is only 6.27*10^{-5} 6.27*10^{-5} that is less than 0.05 0.05 . So we can conclude that there is a significant relationship between yield and temperature","title":"a)"},{"location":"chapter_5/#b_2","text":"Give the 95% confidence interval of the expected yield at a temperature of x_{new}= 80 \u00b0C x_{new}= 80 \u00b0C . By method 5.18 \\hat\\beta_0+\\hat\\beta_1x_{new}\\pm t_{1-\\alpha/2} \\hat\\sigma \\sqrt{\\frac{1}{n}+\\frac{(x_{new}-\\bar{x})^2}{S_{xx}}} \\hat\\beta_0+\\hat\\beta_1x_{new}\\pm t_{1-\\alpha/2} \\hat\\sigma \\sqrt{\\frac{1}{n}+\\frac{(x_{new}-\\bar{x})^2}{S_{xx}}} x <- c ( 0 , 25 , 50 , 75 , 100 ) y <- c ( 14 , 38 , 54 , 76 , 95 ) fit <- lm ( y ~ x ) alpha <- 0.05 xnew <- 80 # By method 5.18 res <- coef ( fit )[ 1 ] + coef ( fit )[ 2 ] * xnew range <- qt (( 1 - alpha / 2 ), df = length ( x ) -2 ) * sigma ( fit ) * sqrt ( 1 / length ( x ) + ( xnew - mean ( x )) ^ 2 / sum (( x - mean ( x )) ^ 2 )) c ( res - range , res + range ) 75.79348 83.00652 # By using predict function predict ( fit , newdata = data.frame ( x = xnew ), interval = \"confidence\" , level = 1 - alpha ) fit lwr upr 79.4 75.79 83.01 Thus the answer is [75.79,83.01] [75.79,83.01]","title":"b)"},{"location":"chapter_5/#c","text":"What is the upper quartile of the residuals? Upper quantile = Q_3 Q_3 = q_{0.75} q_{0.75} $$ pn= 0.75*5 = 3.75 $$ pn pn is not an integer, so we take \"next one\" in the list, that is 4. > sort ( fit $ residuals )[ 4 ] 4 0.6 Thus the answer is: 0.6","title":"c)"},{"location":"chapter_5/#54-plastic-material","text":"In the manufacturing of a plastic material, it is believed that the cooling time has an influence on the impact strength. Therefore a study is carried out in which plastic material impact strength is determined for 4 different cooling times. The results of this experiment are shown in the following table: Cooling times in seconds(x) Impact strength in kJ/m^2 kJ/m^2 (y) 15 42.1 25 36.0 35 31.8 40 28.7 The following statistics may by used: $$ \\bar{x} = 28.75, \\bar{y}=34.65, S_{xx}=368.75 $$","title":"5.4 Plastic material"},{"location":"chapter_5/#a_3","text":"What is the 95% confidence interval for the slope of the regression model, expressing the impact strength as a linear function of the cooling time? x <- c ( 15 , 25 , 35 , 40 ) y <- c ( 42.1 , 36.0 , 31.8 , 28.7 ) xbar <- 28.75 ybar <- 34.65 Sxx <- 368.75 fit <- lm ( y ~ x ) out <- summary ( fit ) beta1hat <- coef ( fit )[ 2 ] sigmabeta1 <- out $ coefficients [ 2 , 2 ] c ( beta1hat - qt (( 1-0.05 / 2 ), df = length ( x ) -2 ) * sigmabeta1 , beta1hat + qt (( 1-0.05 / 2 ), df = length ( x ) -2 ) * sigmabeta1 ) -0.6460407 -0.3966711 So the answer is that we accept \\beta_1 \\in [-0.6460407, -0.3966711] \\beta_1 \\in [-0.6460407, -0.3966711]","title":"a)"},{"location":"chapter_5/#b_3","text":"Can you conclude that there is a relation between the impact strength and the cooling time at significance level \\alpha \\alpha = 5%? pvalue1 <- out $ coefficients [ 2 , 4 ] 0.003075239 \\text{p-value}_1 \\text{p-value}_1 is less than \\alpha = 0.05 \\alpha = 0.05 , so we can conclude that there is a relation between the impact strength and the cooling time. In other words, the relation is statically significant.","title":"b)"},{"location":"chapter_5/#c_1","text":"For a similar plastic material the tabulated value for the linear relation between temperature and impact strength (i.e the slope) is -0.30. If the following hypothesis is tested (at level \\alpha \\alpha = 0.05) H_0: \\beta_1 = -0.30 \\\\ H_1: \\beta_1 \\ne -0.30 H_0: \\beta_1 = -0.30 \\\\ H_1: \\beta_1 \\ne -0.30 with the usual t-test statistic for such a test, what is the range (for t) within which the hypothesis is accepted? alpha <- 0.05 c ( qt ( alpha / 2 , df = 2 ), qt ( 1 - alpha / 2 , df = 2 )) -4.302653 4.302653 The critical values for the t-statistic with \u03bd = 2 degrees of freedom is [-4.302653, 4.302653] [-4.302653, 4.302653]","title":"c)"},{"location":"chapter_5/#55-water-pollution","text":"In a study of pollution in a water stream, the concentration of pollution is measured at 5 different locations. The locations are at different distances to the pollution source. In the table below, these distances and the average pollution are given: Distance to the pollution source(km) Average concentration 2 11.5 4 10.2 6 10.3 8 9.68 10 9.32","title":"5.5 Water pollution"},{"location":"chapter_5/#a_4","text":"What are the parameter estimates for the three unknown parameters in the usual linear regression model: 1) The intercept ( \\beta_0 \\beta_0 ), 2) the slope ( \\beta_1 \\beta_1 ) and 3) error standard deviation ( \\sigma \\sigma )? distances <- c ( 2 , 4 , 6 , 8 , 10 ) concentrations <- c ( 11.5 , 10.2 , 10.3 , 9.68 , 9.32 ) fit <- lm ( concentrations ~ distances ) out <- summary ( fit ) beta0hat <- coef ( fit )[ 1 ] 11.664 beta1hat <- coef ( fit )[ 2 ] -0.244 sigmahat <- sigma ( fit ) 0.348023 \\hat\\beta_0 = 11.664 \\\\ \\hat\\beta_1 = -0.244 \\\\ \\hat\\sigma = 0.348023 \\hat\\beta_0 = 11.664 \\\\ \\hat\\beta_1 = -0.244 \\\\ \\hat\\sigma = 0.348023","title":"a)"},{"location":"chapter_5/#b_4","text":"How large a part of the variation in concentration can be explained by the distance? out $ r.squared 0.8676188 R^2 = 0.8676188 R^2 = 0.8676188 Note that this is only an estimate.","title":"b)"},{"location":"chapter_5/#c_2","text":"What is a 95%-confidence interval for the expected pollution concentration 7 km from the pollution source? predict ( fit , newdata = data.frame ( distances = dnew ), interval = \"confidence\" , level = 1 - alpha ) fit lwr upr 1 9.956 9.430636 10.48136 The answer: [9.430636, 10.48136] [9.430636, 10.48136]","title":"c)"},{"location":"chapter_5/#56-membrane-pressure-drop","text":"When purifying drinking water you can use a so-called membrane filtration. In an experiment one wishes to examine the relationship between the pressure drop across a membrane and the flux (flow per area) through the membrane. We observe the following 10 related values of pressure (x) and flux (y): Pressure(x) Flux(y) 1 1.02 1.15 2 2.08 0.85 3 2.89 1.56 4 4.01 1.72 5 5.32 4.32 6 5.83 5.07 7 7.26 5.00 8 7.96 5.31 9 9.11 6.17 10 9.99 7.04","title":"5.6 Membrane pressure drop"},{"location":"chapter_5/#a_5","text":"What is the empirical correlation between pressure and flux estimated to? Give also an interpretation of the correlation. cor ( D $ pressure , D $ flux ) [ 1 ] 0.9638184 \\hat\\rho = r = 0.964 \\hat\\rho = r = 0.964 This means that flux increase with increasing pressure.","title":"a)"},{"location":"chapter_5/#b_5","text":"What is a 90% confidence interval for the slope \\beta_1 \\beta_1 in the usual regression model? alpha <- 0.1 beta1hat <- coef ( fit )[ 2 ] sigmabeta1 <- out $ coefficients [ 2 , 2 ] c ( beta1hat - qt (( 1 - alpha / 2 ), df = out $ df [ 2 ]) * sigmabeta1 , beta1hat + qt (( 1 - alpha / 2 ), df = out $ df [ 2 ]) * sigmabeta1 ) 0.5911094 0.8538426 So the answer is that we accept \\beta_1 \\in [0.5911094, 0.8538426] \\beta_1 \\in [0.5911094, 0.8538426]","title":"b)"},{"location":"chapter_5/#c_3","text":"How large a part of the flux-variation \\sum\\limits_{i=1}^{10}(y_i-\\bar{y})^2 \\sum\\limits_{i=1}^{10}(y_i-\\bar{y})^2 is not explained by pressure differences? 1 - cor ( D $ pressure , D $ flux ) ^ 2 0.07105402","title":"c)"},{"location":"chapter_5/#d","text":"Can you at significance level \\alpha \\alpha = 0.05 reject the hypothesis that the line passes through (0, 0)? The intercept should be equals to 0, if the line passes through (0,0). This means that if we can reject that the intercept equals to 0, so we can reject that the line passes through (0, 0). Therefore we formulate the null hypothesis and the alternative hypothesis as follows: $$ H_{00}: \\beta_0=0 \\ H_{01} : \\beta_0 \\ne 0 $$ pvalue0 <- out $ coefficients [ 1 , 4 ] 0.6806967 \\text{p-value}_0=0.68 \\text{p-value}_0=0.68 is higher than \\alpha=0.05 \\alpha=0.05 , so we need to accept that the line passes through (0, 0).","title":"d)"},{"location":"chapter_5/#e","text":"A confidence interval for the line at three different pressure levels: x_{new}^A= 3.5 x_{new}^A= 3.5 , x^B_{new}=5.0 x^B_{new}=5.0 and , x^C_{new}=9.5 x^C_{new}=9.5 will look as follows: \\hat\\beta_0+\\beta_1*x^U_{new}\\pm C_U \\hat\\beta_0+\\beta_1*x^U_{new}\\pm C_U where U U then is either A A , B B or C C . Write the constants C_U C_U in increasing order. alpha <- 0.05 xnews <- c ( 3.5 , 5.0 , 9.5 ) CIs <- predict ( fit , newdata = data.frame ( pressure = xnews ), interval = \"confidence\" , level = 1 - alpha ) constants <- numeric ( 3 ) for ( i in 1 : 3 ){ constants [ i ] <- CIs [ i , 3 ] - CIs [ i , 1 ] } constants 0.4647513 0.3858058 0.6429206 C_A = 0.4647513 \\\\ C_B = 0.3858058 \\\\ C_C = 0.6429206 C_A = 0.4647513 \\\\ C_B = 0.3858058 \\\\ C_C = 0.6429206 This gives that: C_B < C_A < C_C C_B < C_A < C_C It can also be calculated without R as follows: By Method 5.18 constants differs only by this term: (x_{new}-\\bar{x})^2 (x_{new}-\\bar{x})^2 So since \\bar{x}=5.547 \\bar{x}=5.547 : (5.0-5.547)^2<(3.5-5.547)^2<(9.5-5.547)^2 \\\\ (x^B_{new}-5.547)^2<(x^A_{new}-5.547)^2<(x^C_{new}-5.547)^2 \\\\ C_B<C_A<C_C (5.0-5.547)^2<(3.5-5.547)^2<(9.5-5.547)^2 \\\\ (x^B_{new}-5.547)^2<(x^A_{new}-5.547)^2<(x^C_{new}-5.547)^2 \\\\ C_B<C_A<C_C","title":"e)"},{"location":"chapter_6/","text":"6 Multiple Linear Regression 6.1 Nitrate concentration In order to analyze the effect of reducing nitrate loading in a Danish fjord, it was decided to formulate a linear model that describes the nitrate concentration in the fjord as a function of nitrate loading, it was further decided to correct for fresh water runoff. The resulting model was $$ Y_i = \\beta_0+\\beta_1x_{1,i}+\\beta_2x_{2,i}+ \\varepsilon_i , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) $$ where Y_i Y_i is the natural logarithm of nitrate concentration, x_{1,i} x_{1,i} is the natural logarithm of nitrate loading, and x_{2,i} x_{2,i} is the natural logarithm of fresh water run off. a) Which of the following statements are assumed fulfilled in the usual multiple linear regression model? \\varepsilon_i = 0 \\varepsilon_i = 0 for all i = 1, ..., n, i = 1, ..., n, and \\beta_j \\beta_j follows a normal distribution E[x_1] = E[x_2] = 0 E[x_1] = E[x_2] = 0 and V[\\varepsilon_i] = \\beta^2_1 V[\\varepsilon_i] = \\beta^2_1 E[\\varepsilon_i] = 0 E[\\varepsilon_i] = 0 and V[\\varepsilon_i] = \\beta^2_1 V[\\varepsilon_i] = \\beta^2_1 . \\varepsilon_i \\varepsilon_i is normally distributed with constant variance, and \\varepsilon_i \\varepsilon_i and \\varepsilon_j \\varepsilon_j are independent for i \\ne j i \\ne j . Yes \\varepsilon_i = 0 \\varepsilon_i = 0 for all i = 1, ..., n, i = 1, ..., n, and x_j x_j follows a normal distribution for j = \\{1, 2\\} j = \\{1, 2\\} Answer : only 4. is correct, because this is the usual assumption about the errors b) The parameters in the model were estimated in R and the following results are available (slightly modified output from summary): > summary ( lm ( y ~ x1 + x2 )) Call : lm ( formula = y ~ x1 + x2 ) Coefficients : Estimate Std. Error t value Pr ( >| t | ) ( Intercept ) -2.36500 0.22184 -10.661 < 2e-16 x1 0.47621 0.06169 7.720 3.25e-13 x2 0.08269 0.06977 1.185 0.237 --- Residual standard error : 0.3064 on 237 degrees of freedom Multiple R - squared : 0.3438 , Adjusted R - squared : 0.3382 F - statistic : 62.07 on 2 and 237 DF , p - value : < 2.2e-16 What are the parameter estimates for the model parameters ( \\hat\\beta_i \\hat\\beta_i and \\hat\\sigma^2 \\hat\\sigma^2 ) and how many observations are included in the estimation? \\hat\\beta_0 = -2.365 \\\\ \\hat\\beta_1 = 0.47621 \\\\ \\hat\\beta_2 = 0.08269 \\\\ \\hat\\sigma^2 = 0.3064^2 \\hat\\beta_0 = -2.365 \\\\ \\hat\\beta_1 = 0.47621 \\\\ \\hat\\beta_2 = 0.08269 \\\\ \\hat\\sigma^2 = 0.3064^2 And there are 240 observations included in the estimation, because the number of degrees of freedom (237) is equal n-(p+1) n-(p+1) , where p=2 p=2 (because of \\hat\\beta_2 \\hat\\beta_2 ) c) Calculate the usual 95% confidence intervals for the parameters ( \\beta_0 \\beta_0 , \\beta_1 \\beta_1 , and \\beta_2 \\beta_2 ) By method 6.5 confidence intervals for the parameters are given by: \\hat\\beta_i\\pm t_{1-\\alpha/2}\\hat\\sigma_{\\beta_i} \\hat\\beta_i\\pm t_{1-\\alpha/2}\\hat\\sigma_{\\beta_i} So: \\hat\\beta_0\\in [-2.80203, -1.92797] \\\\ \\hat\\beta_1 \\in [0.3546792, 0.5977408] \\\\ \\hat \\beta_2 \\in [-0.05475858, 0.22013858] \\hat\\beta_0\\in [-2.80203, -1.92797] \\\\ \\hat\\beta_1 \\in [0.3546792, 0.5977408] \\\\ \\hat \\beta_2 \\in [-0.05475858, 0.22013858] # The example of Beta0 calculation in R alpha <- 0.05 beta <- -2.36500 sigmabeta <- 0.22184 c ( beta - qt (( 1 - alpha / 2 ), df = 237 ) * sigmabeta , beta + qt (( 1 - alpha / 2 ), df = 237 ) * sigmabeta ) -2.80203 -1.92797 d) On level \\alpha= 0.05 \\alpha= 0.05 which of the parameters are significantly different from 0, also find the p-values for the tests used for each of the parameters? By using the summary in the R output we can conclude that only \\beta_0 \\beta_0 and \\beta_1 \\beta_1 are significantly different from 0, because these parameters have very low \\text{p-value} \\text{p-value} (very strong evidence against the null hypothesis in both cases) 6.2 Multiple linear regression model The following measurements have been obtained in a study: D <- data.frame ( x1 = c ( 0.58 , 0.86 , 0.29 , 0.20 , 0.56 , 0.28 , 0.08 , 0.41 , 0.22 , 0.35 , 0.59 , 0.22 , 0.26 , 0.12 , 0.65 , 0.70 , 0.30 , 0.70 , 0.39 , 0.72 , 0.45 , 0.81 , 0.04 , 0.20 , 0.95 ), x2 = c ( 0.71 , 0.13 , 0.79 , 0.20 , 0.56 , 0.92 , 0.01 , 0.60 , 0.70 , 0.73 , 0.13 , 0.96 , 0.27 , 0.21 , 0.88 , 0.30 , 0.15 , 0.09 , 0.17 , 0.25 , 0.30 , 0.32 , 0.82 , 0.98 , 0.00 ), y = c ( 1.45 , 1.93 , 0.81 , 0.61 , 1.55 , 0.95 , 0.45 , 1.14 , 0.74 , 0.98 , 1.41 , 0.81 , 0.89 , 0.68 , 1.39 , 1.53 , 0.91 , 1.49 , 1.38 , 1.73 , 1.11 , 1.68 , 0.66 , 0.69 , 1.98 ) ) It is expected that the response variable y y can be described by the independent variables x_1 x_1 and x_2 x_2 . This imply that the parameters of the following model should be estimated and tested Y_i = \\beta_0+\\beta_1x_{1}+\\beta_2x_{2}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) Y_i = \\beta_0+\\beta_1x_{1}+\\beta_2x_{2}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) a) Calculate the parameter estimates ( \\beta_0 \\beta_0 , \\beta_1 \\beta_1 , \\beta_2 \\beta_2 , and \\sigma^2 \\sigma^2 ), in addition find the usual 95% confidence intervals for \\beta_0 \\beta_0 , \\beta_1 \\beta_1 and \\beta_2 \\beta_2 . > fit <- lm ( y ~ x1 + x2 , data = D ) > summary ( fit ) Call : lm ( formula = y ~ x1 + x2 , data = D ) Residuals : Min 1 Q Median 3 Q Max -0.15493 -0.07801 -0.02004 0.04999 0.30112 Coefficients : Estimate Std. Error t value Pr ( >| t | ) ( Intercept ) 0.433547 0.065983 6.571 1.31e-06 *** x1 1.652993 0.095245 17.355 2.53e-14 *** x2 0.003945 0.074854 0.053 0.958 --- Signif. codes : 0 \u2018 *** \u2019 0.001 \u2018 ** \u2019 0.01 \u2018 * \u2019 0.05 \u2018 . \u2019 0.1 \u2018 \u2019 1 Residual standard error : 0.1127 on 22 degrees of freedom Multiple R - squared : 0.9399 , Adjusted R - squared : 0.9344 F - statistic : 172 on 2 and 22 DF , p - value : 3.699e-14 \\hat\\beta_0 = 0.433547 \\\\ \\hat\\beta_1 = 1.652993 \\\\ \\hat\\beta_2 = 0.003945 \\\\ \\hat\\sigma^2 = 0.1127^2 \\\\ \\hat\\beta_0 = 0.433547 \\\\ \\hat\\beta_1 = 1.652993 \\\\ \\hat\\beta_2 = 0.003945 \\\\ \\hat\\sigma^2 = 0.1127^2 \\\\ > confint ( fit , level = 0.95 ) 2.5 % 97.5 % ( Intercept ) 0.2967067 0.5703875 x1 1.4554666 1.8505203 x2 -0.1512924 0.1591822 \\hat\\beta_0 \\in [0.2967067, 0.570387] \\\\ \\hat\\beta_1 \\in [1.4554666, 1.8505203] \\\\ \\hat\\beta_2 \\in [-0.1512924, 0.1591822] \\\\ \\hat\\beta_0 \\in [0.2967067, 0.570387] \\\\ \\hat\\beta_1 \\in [1.4554666, 1.8505203] \\\\ \\hat\\beta_2 \\in [-0.1512924, 0.1591822] \\\\ b) Still using confidence level \\alpha= 0.05 \\alpha= 0.05 reduce the model if appropriate Since the confidence interval for \\beta_2 \\beta_2 cover zero and the \\text{p-value} \\text{p-value} is much larger than 0.05 0.05 , the parameter should be removed from the model to get the simpler model: Y_i = \\beta_0+\\beta_1x_{1}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) Y_i = \\beta_0+\\beta_1x_{1}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) The parameter estimates in the simpler model are: > fit <- lm ( y ~ x1 , data = D ) > summary ( fit ) Call : lm ( formula = y ~ x1 , data = D ) Residuals : Min 1 Q Median 3 Q Max -0.15633 -0.07633 -0.02145 0.05157 0.29994 Coefficients : Estimate Std. Error t value Pr ( >| t | ) ( Intercept ) 0.43609 0.04399 9.913 9.02e-10 *** x1 1.65121 0.08707 18.963 1.54e-15 *** --- Signif. codes : 0 \u2018 *** \u2019 0.001 \u2018 ** \u2019 0.01 \u2018 * \u2019 0.05 \u2018 . \u2019 0.1 \u2018 \u2019 1 Residual standard error : 0.1102 on 23 degrees of freedom Multiple R - squared : 0.9399 , Adjusted R - squared : 0.9373 F - statistic : 359.6 on 1 and 23 DF , p - value : 1.538e-15 And both parameters are now significant. c) Carry out a residual analysis to check that the model assumptions are fulfilled. It seems that there are no strong evidence against the assumptions, the qq-plot is are a straight line and the are no obvious dependence between the residuals and the fitted values, and we conclude that the assumptions are fulfilled. par ( mfrow = c ( 1 , 2 )) qqnorm ( fit $ residuals ) qqline ( fit $ residuals ) plot ( fit $ fitted.values , fit $ residuals , main = \"Fitted vs residuals\" ) ## Walley library ( MESS ) qqwrap <- function ( x , y , ... ){ stdy <- ( y - mean ( y )) / sd ( y ) qqnorm ( stdy , main = \"\" , ... ) qqline ( stdy )} wallyplot ( fit $ residuals , FUN = qqwrap , ylim = c ( -3 , 3 )) d) Make a plot of the fitted line and 95% confidence and prediction intervals of the line for x_1 \\in [0, 1] x_1 \\in [0, 1] (it is assumed that the model was reduced above). par ( mfrow = c ( 1 , 1 )) x1new <- seq ( 0 , 1 , by = 0.01 ) pred <- predict ( fit , newdata = data.frame ( x1 = x1new ), interval = \"prediction\" ) conf <- predict ( fit , newdata = data.frame ( x1 = x1new ), interval = \"confidence\" ) plot ( x1new , pred [ , \"fit\" ], type = \"l\" , ylim = c ( 0.1 , 2.4 ), xlab = \"x1\" , ylab = \"Prediction\" ) lines ( x1new , conf [ , \"lwr\" ], col = \"green\" , lty = 2 ) lines ( x1new , conf [ , \"upr\" ], col = \"green\" , lty = 2 ) lines ( x1new , pred [ , \"lwr\" ], col = \"red\" , lty = 2 ) lines ( x1new , pred [ , \"upr\" ], col = \"red\" , lty = 2 ) legend ( \"topleft\" , c ( \"Prediction\" , \"Confidence band\" , \"Prediction band\" ), lty = c ( 1 , 2 , 2 ), col = c ( 1 , 3 , 2 ), cex = 0.7 )","title":"6 Multiple Linear Regression"},{"location":"chapter_6/#6-multiple-linear-regression","text":"","title":"6 Multiple Linear Regression"},{"location":"chapter_6/#61-nitrate-concentration","text":"In order to analyze the effect of reducing nitrate loading in a Danish fjord, it was decided to formulate a linear model that describes the nitrate concentration in the fjord as a function of nitrate loading, it was further decided to correct for fresh water runoff. The resulting model was $$ Y_i = \\beta_0+\\beta_1x_{1,i}+\\beta_2x_{2,i}+ \\varepsilon_i , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) $$ where Y_i Y_i is the natural logarithm of nitrate concentration, x_{1,i} x_{1,i} is the natural logarithm of nitrate loading, and x_{2,i} x_{2,i} is the natural logarithm of fresh water run off.","title":"6.1 Nitrate concentration"},{"location":"chapter_6/#a","text":"Which of the following statements are assumed fulfilled in the usual multiple linear regression model? \\varepsilon_i = 0 \\varepsilon_i = 0 for all i = 1, ..., n, i = 1, ..., n, and \\beta_j \\beta_j follows a normal distribution E[x_1] = E[x_2] = 0 E[x_1] = E[x_2] = 0 and V[\\varepsilon_i] = \\beta^2_1 V[\\varepsilon_i] = \\beta^2_1 E[\\varepsilon_i] = 0 E[\\varepsilon_i] = 0 and V[\\varepsilon_i] = \\beta^2_1 V[\\varepsilon_i] = \\beta^2_1 . \\varepsilon_i \\varepsilon_i is normally distributed with constant variance, and \\varepsilon_i \\varepsilon_i and \\varepsilon_j \\varepsilon_j are independent for i \\ne j i \\ne j . Yes \\varepsilon_i = 0 \\varepsilon_i = 0 for all i = 1, ..., n, i = 1, ..., n, and x_j x_j follows a normal distribution for j = \\{1, 2\\} j = \\{1, 2\\} Answer : only 4. is correct, because this is the usual assumption about the errors","title":"a)"},{"location":"chapter_6/#b","text":"The parameters in the model were estimated in R and the following results are available (slightly modified output from summary): > summary ( lm ( y ~ x1 + x2 )) Call : lm ( formula = y ~ x1 + x2 ) Coefficients : Estimate Std. Error t value Pr ( >| t | ) ( Intercept ) -2.36500 0.22184 -10.661 < 2e-16 x1 0.47621 0.06169 7.720 3.25e-13 x2 0.08269 0.06977 1.185 0.237 --- Residual standard error : 0.3064 on 237 degrees of freedom Multiple R - squared : 0.3438 , Adjusted R - squared : 0.3382 F - statistic : 62.07 on 2 and 237 DF , p - value : < 2.2e-16 What are the parameter estimates for the model parameters ( \\hat\\beta_i \\hat\\beta_i and \\hat\\sigma^2 \\hat\\sigma^2 ) and how many observations are included in the estimation? \\hat\\beta_0 = -2.365 \\\\ \\hat\\beta_1 = 0.47621 \\\\ \\hat\\beta_2 = 0.08269 \\\\ \\hat\\sigma^2 = 0.3064^2 \\hat\\beta_0 = -2.365 \\\\ \\hat\\beta_1 = 0.47621 \\\\ \\hat\\beta_2 = 0.08269 \\\\ \\hat\\sigma^2 = 0.3064^2 And there are 240 observations included in the estimation, because the number of degrees of freedom (237) is equal n-(p+1) n-(p+1) , where p=2 p=2 (because of \\hat\\beta_2 \\hat\\beta_2 )","title":"b)"},{"location":"chapter_6/#c","text":"Calculate the usual 95% confidence intervals for the parameters ( \\beta_0 \\beta_0 , \\beta_1 \\beta_1 , and \\beta_2 \\beta_2 ) By method 6.5 confidence intervals for the parameters are given by: \\hat\\beta_i\\pm t_{1-\\alpha/2}\\hat\\sigma_{\\beta_i} \\hat\\beta_i\\pm t_{1-\\alpha/2}\\hat\\sigma_{\\beta_i} So: \\hat\\beta_0\\in [-2.80203, -1.92797] \\\\ \\hat\\beta_1 \\in [0.3546792, 0.5977408] \\\\ \\hat \\beta_2 \\in [-0.05475858, 0.22013858] \\hat\\beta_0\\in [-2.80203, -1.92797] \\\\ \\hat\\beta_1 \\in [0.3546792, 0.5977408] \\\\ \\hat \\beta_2 \\in [-0.05475858, 0.22013858] # The example of Beta0 calculation in R alpha <- 0.05 beta <- -2.36500 sigmabeta <- 0.22184 c ( beta - qt (( 1 - alpha / 2 ), df = 237 ) * sigmabeta , beta + qt (( 1 - alpha / 2 ), df = 237 ) * sigmabeta ) -2.80203 -1.92797","title":"c)"},{"location":"chapter_6/#d","text":"On level \\alpha= 0.05 \\alpha= 0.05 which of the parameters are significantly different from 0, also find the p-values for the tests used for each of the parameters? By using the summary in the R output we can conclude that only \\beta_0 \\beta_0 and \\beta_1 \\beta_1 are significantly different from 0, because these parameters have very low \\text{p-value} \\text{p-value} (very strong evidence against the null hypothesis in both cases)","title":"d)"},{"location":"chapter_6/#62-multiple-linear-regression-model","text":"The following measurements have been obtained in a study: D <- data.frame ( x1 = c ( 0.58 , 0.86 , 0.29 , 0.20 , 0.56 , 0.28 , 0.08 , 0.41 , 0.22 , 0.35 , 0.59 , 0.22 , 0.26 , 0.12 , 0.65 , 0.70 , 0.30 , 0.70 , 0.39 , 0.72 , 0.45 , 0.81 , 0.04 , 0.20 , 0.95 ), x2 = c ( 0.71 , 0.13 , 0.79 , 0.20 , 0.56 , 0.92 , 0.01 , 0.60 , 0.70 , 0.73 , 0.13 , 0.96 , 0.27 , 0.21 , 0.88 , 0.30 , 0.15 , 0.09 , 0.17 , 0.25 , 0.30 , 0.32 , 0.82 , 0.98 , 0.00 ), y = c ( 1.45 , 1.93 , 0.81 , 0.61 , 1.55 , 0.95 , 0.45 , 1.14 , 0.74 , 0.98 , 1.41 , 0.81 , 0.89 , 0.68 , 1.39 , 1.53 , 0.91 , 1.49 , 1.38 , 1.73 , 1.11 , 1.68 , 0.66 , 0.69 , 1.98 ) ) It is expected that the response variable y y can be described by the independent variables x_1 x_1 and x_2 x_2 . This imply that the parameters of the following model should be estimated and tested Y_i = \\beta_0+\\beta_1x_{1}+\\beta_2x_{2}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) Y_i = \\beta_0+\\beta_1x_{1}+\\beta_2x_{2}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2)","title":"6.2  Multiple linear regression model"},{"location":"chapter_6/#a_1","text":"Calculate the parameter estimates ( \\beta_0 \\beta_0 , \\beta_1 \\beta_1 , \\beta_2 \\beta_2 , and \\sigma^2 \\sigma^2 ), in addition find the usual 95% confidence intervals for \\beta_0 \\beta_0 , \\beta_1 \\beta_1 and \\beta_2 \\beta_2 . > fit <- lm ( y ~ x1 + x2 , data = D ) > summary ( fit ) Call : lm ( formula = y ~ x1 + x2 , data = D ) Residuals : Min 1 Q Median 3 Q Max -0.15493 -0.07801 -0.02004 0.04999 0.30112 Coefficients : Estimate Std. Error t value Pr ( >| t | ) ( Intercept ) 0.433547 0.065983 6.571 1.31e-06 *** x1 1.652993 0.095245 17.355 2.53e-14 *** x2 0.003945 0.074854 0.053 0.958 --- Signif. codes : 0 \u2018 *** \u2019 0.001 \u2018 ** \u2019 0.01 \u2018 * \u2019 0.05 \u2018 . \u2019 0.1 \u2018 \u2019 1 Residual standard error : 0.1127 on 22 degrees of freedom Multiple R - squared : 0.9399 , Adjusted R - squared : 0.9344 F - statistic : 172 on 2 and 22 DF , p - value : 3.699e-14 \\hat\\beta_0 = 0.433547 \\\\ \\hat\\beta_1 = 1.652993 \\\\ \\hat\\beta_2 = 0.003945 \\\\ \\hat\\sigma^2 = 0.1127^2 \\\\ \\hat\\beta_0 = 0.433547 \\\\ \\hat\\beta_1 = 1.652993 \\\\ \\hat\\beta_2 = 0.003945 \\\\ \\hat\\sigma^2 = 0.1127^2 \\\\ > confint ( fit , level = 0.95 ) 2.5 % 97.5 % ( Intercept ) 0.2967067 0.5703875 x1 1.4554666 1.8505203 x2 -0.1512924 0.1591822 \\hat\\beta_0 \\in [0.2967067, 0.570387] \\\\ \\hat\\beta_1 \\in [1.4554666, 1.8505203] \\\\ \\hat\\beta_2 \\in [-0.1512924, 0.1591822] \\\\ \\hat\\beta_0 \\in [0.2967067, 0.570387] \\\\ \\hat\\beta_1 \\in [1.4554666, 1.8505203] \\\\ \\hat\\beta_2 \\in [-0.1512924, 0.1591822] \\\\","title":"a)"},{"location":"chapter_6/#b_1","text":"Still using confidence level \\alpha= 0.05 \\alpha= 0.05 reduce the model if appropriate Since the confidence interval for \\beta_2 \\beta_2 cover zero and the \\text{p-value} \\text{p-value} is much larger than 0.05 0.05 , the parameter should be removed from the model to get the simpler model: Y_i = \\beta_0+\\beta_1x_{1}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) Y_i = \\beta_0+\\beta_1x_{1}+ \\varepsilon_i \\ , \\qquad \\varepsilon_i\\sim N(0,\\sigma^2) The parameter estimates in the simpler model are: > fit <- lm ( y ~ x1 , data = D ) > summary ( fit ) Call : lm ( formula = y ~ x1 , data = D ) Residuals : Min 1 Q Median 3 Q Max -0.15633 -0.07633 -0.02145 0.05157 0.29994 Coefficients : Estimate Std. Error t value Pr ( >| t | ) ( Intercept ) 0.43609 0.04399 9.913 9.02e-10 *** x1 1.65121 0.08707 18.963 1.54e-15 *** --- Signif. codes : 0 \u2018 *** \u2019 0.001 \u2018 ** \u2019 0.01 \u2018 * \u2019 0.05 \u2018 . \u2019 0.1 \u2018 \u2019 1 Residual standard error : 0.1102 on 23 degrees of freedom Multiple R - squared : 0.9399 , Adjusted R - squared : 0.9373 F - statistic : 359.6 on 1 and 23 DF , p - value : 1.538e-15 And both parameters are now significant.","title":"b)"},{"location":"chapter_6/#c_1","text":"Carry out a residual analysis to check that the model assumptions are fulfilled. It seems that there are no strong evidence against the assumptions, the qq-plot is are a straight line and the are no obvious dependence between the residuals and the fitted values, and we conclude that the assumptions are fulfilled. par ( mfrow = c ( 1 , 2 )) qqnorm ( fit $ residuals ) qqline ( fit $ residuals ) plot ( fit $ fitted.values , fit $ residuals , main = \"Fitted vs residuals\" ) ## Walley library ( MESS ) qqwrap <- function ( x , y , ... ){ stdy <- ( y - mean ( y )) / sd ( y ) qqnorm ( stdy , main = \"\" , ... ) qqline ( stdy )} wallyplot ( fit $ residuals , FUN = qqwrap , ylim = c ( -3 , 3 ))","title":"c)"},{"location":"chapter_6/#d_1","text":"Make a plot of the fitted line and 95% confidence and prediction intervals of the line for x_1 \\in [0, 1] x_1 \\in [0, 1] (it is assumed that the model was reduced above). par ( mfrow = c ( 1 , 1 )) x1new <- seq ( 0 , 1 , by = 0.01 ) pred <- predict ( fit , newdata = data.frame ( x1 = x1new ), interval = \"prediction\" ) conf <- predict ( fit , newdata = data.frame ( x1 = x1new ), interval = \"confidence\" ) plot ( x1new , pred [ , \"fit\" ], type = \"l\" , ylim = c ( 0.1 , 2.4 ), xlab = \"x1\" , ylab = \"Prediction\" ) lines ( x1new , conf [ , \"lwr\" ], col = \"green\" , lty = 2 ) lines ( x1new , conf [ , \"upr\" ], col = \"green\" , lty = 2 ) lines ( x1new , pred [ , \"lwr\" ], col = \"red\" , lty = 2 ) lines ( x1new , pred [ , \"upr\" ], col = \"red\" , lty = 2 ) legend ( \"topleft\" , c ( \"Prediction\" , \"Confidence band\" , \"Prediction band\" ), lty = c ( 1 , 2 , 2 ), col = c ( 1 , 3 , 2 ), cex = 0.7 )","title":"d)"},{"location":"chapter_7/","text":"Categorical and Count Data 7.1 Passing proportions The passing proportions for the two courses, p_1 p_1 and p_2 p_2 should be compared. Course 1 Course 2 Row total Passed 82 104 186 Not passed 26 39 65 Column total 108 143 251 a) Compute a 95% confidence interval for the difference between the two passing proportions. By Method 7.15 $$ \\hat{p_1} = \\frac{82}{108} = 0.7592593 \\ \\hat{p_2} = \\frac{104}{143} = 0.7272727 $$ \\hat{\\sigma}_{\\hat{p_1} -\\hat{p_2}} = \\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1}+\\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}} = 0.05549318 \\hat{\\sigma}_{\\hat{p_1} -\\hat{p_2}} = \\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1}+\\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}} = 0.05549318 n1 <- 108 n2 <- 143 p1 <- 82 / n1 p2 <- 104 / n2 SEp1 <- sqrt ( p1 * ( 1 - p1 ) / n1 ) SEp2 <- sqrt ( p2 * ( 1 - p2 ) / n2 ) SEp1p2 <- sqrt ( SEp1 ^ 2 + SEp2 ^ 2 ) SEp1p2 0.05549318 So the 95% CI for the difference is: (\\hat{p}_1-\\hat{p}_2) \\pm z_{1-\\alpha/2}*\\hat\\sigma_{\\hat{p}_1-{\\hat{p}_2}} = [-0.0767781,0.1407512 ] (\\hat{p}_1-\\hat{p}_2) \\pm z_{1-\\alpha/2}*\\hat\\sigma_{\\hat{p}_1-{\\hat{p}_2}} = [-0.0767781,0.1407512 ] ( p1 - p2 ) - qnorm ( 1-0.05 / 2 ) * SEp1p2 -0.0767781 ( p1 - p2 ) + qnorm ( 1-0.05 / 2 ) * SEp1p2 0.1407512 By prop.test function > prop.test ( x = c ( 82 , 104 ), n = c ( n1 , n2 ), correct = FALSE ) 2 - sample test for equality of proportions without continuity correction data : c ( 82 , 104 ) out of c ( n1 , n2 ) X - squared = 0.32805 , df = 1 , p - value = 0.5668 alternative hypothesis : two.sided 95 percent confidence interval : -0.0767781 0.1407512 sample estimates : prop 1 prop 2 0.7592593 0.7272727 b) What is the critical values for the \\chi^2 \\chi^2 -test of the hypothesis H_0:p_1=p_2 H_0:p_1=p_2 with significance level \\alpha= 0.01 \\alpha= 0.01 ? By method 7.22 The degree of freedom is (r-1)(c-1) = (2-1)(2-1) = 1 (r-1)(c-1) = (2-1)(2-1) = 1 > qchisq ( 1-0.01 , df = 1 ) [ 1 ] 6.634897 Note z_{1-\\alpha/2} z_{1-\\alpha/2} , but \\chi^2_{1-\\alpha} \\chi^2_{1-\\alpha} . So you don't divide \\alpha \\alpha by two, when you use \\chi^2 \\chi^2 distribution. c) If the passing proportion for a course given repeatedly is assumed to be 0.80 on average, and there are 250 students who are taking the exam each time, what is the expected value, \\mu \\mu and standard deviation \\sigma \\sigma , for the number of students who do not pass the exam for a randomly selected course? By Theorem 2.21 \\mu = np = 250 * 0.20 = 50 \\\\ \\sigma = \\sqrt{np(1-p)} = \\sqrt{250*0.2(1-0.2)} = 6.324555 \\mu = np = 250 * 0.20 = 50 \\\\ \\sigma = \\sqrt{np(1-p)} = \\sqrt{250*0.2(1-0.2)} = 6.324555 7.2 Outdoor lighting A company that sells outdoor lighting, gets a lamp produced in 3 material variations: in copper, with painted surface and with stainless steel. The lamps are sold partly in Denmark and partly for export. For 250 lamps the distribution of sales between the three variants and Denmark/export are depicted. The data is shown in the following table: Denmark (Success?) Export (Failure?) Copper variant 7.2% 6.4% Painted variant 28.0% 34.8% Stainless steel variant 8.8% 14.8% a) Is there a significant difference between the proportion exported and the proportion sold in Denmark (with \\alpha = 0.05 \\alpha = 0.05 )? Here we need to find difference between Denmark and export, which means that we don't need to specify different variants. So the total number for Denmark and the total number for export is respectively 44% and 56% or 110 lamps and 140 lamps. By method 7.11 (One sample proportion hypothesis test) : H_0: {p} = 0.5 \\\\ H_1: {p} \\ne 0.5 H_0: {p} = 0.5 \\\\ H_1: {p} \\ne 0.5 z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} = -1.897367 z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} = -1.897367 \\text{p-value} = 0.05777957 \\text{p-value} = 0.05777957 > zobs <- ( 110 - 250 * 0.5 ) / ( sqrt ( 250 * 0.5 * ( 0.5 ))) [ 1 ] -1.897367 > pvalue <- 2 * ( 1 - pnorm ( abs ( zobs ))) [ 1 ] 0.05777957 \\text{p-value} > \\alpha \\text{p-value} > \\alpha , so we accept H_0 H_0 , meaning that there is no significant difference between the proportion exported and the proportion sold in Denmark. With prop.test > prop.test ( x = xDK , n = n , p = 0.5 , correct = FALSE ) 1 - sample proportions test without continuity correction data : xDK out of n , null probability 0.5 X - squared = 3.6 , df = 1 , p - value = 0.05778 alternative hypothesis : true p is not equal to 0.5 95 percent confidence interval : 0.379837 0.501979 sample estimates : p 0.44 b) The relevant critical value to use for testing whether there is a significant difference in how the sold variants are distributed in Denmark and for export is (with \\alpha = 0.05 \\alpha = 0.05 )? The degree of freedom: $ (R-1)(C-1) = (3-1)(2-1) = 2$ The correct answer is: \\chi^2_{1-\\alpha}= \\chi^2_{0.95} = 5.991465 \\chi^2_{1-\\alpha}= \\chi^2_{0.95} = 5.991465 qchisq ( 0.95 , df = 2 ) 7.3 Local election At the local elections in Denmark in November 2013 the Social Democrats (A) had p = 29.5\\% p = 29.5\\% of the votes at the country level. From an early so-called exit poll it was estimated that they would only get 22.7\\% 22.7\\% of the votes. Suppose the exit poll was based on 740 740 people out of which then 168 168 people reported having voted for A. a) At the time of the exit poll the p p was of course not known. If the following hypothesis was tested based on the exit poll: H_0: p = 0.295 \\\\ H_1 : p \\ne 0.295 H_0: p = 0.295 \\\\ H_1 : p \\ne 0.295 what test statistic and conclusion would then be obtained with \\alpha=0.001 \\alpha=0.001 ? Test statistic z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} \\\\ x = 168 \\\\ n = 740 \\\\ p_0 = 0.295 z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} \\\\ x = 168 \\\\ n = 740 \\\\ p_0 = 0.295 > n <- 740 > x <- 168 > p0 <- 0.295 > zobs <- ( x - n * p0 ) / ( sqrt ( n * p0 * ( 1 - p0 ))) [ 1 ] -4.054586 So we get that $$ z_{obs} = -4.054586 $$ The critical value z_{1-\\alpha/2} z_{1-\\alpha/2} > qnorm ( 1 - ( 0.001 / 2 )) 3.290527 Conclusion |z_{obs}| = 4.0545 |z_{obs}| = 4.0545 is more than the critical value 3.290527 3.290527 , so we reject H_0 H_0 . This means that it was significantly unlikely that Social Democrats would have p=29.5 p=29.5 at the local elections in Denmark in November 2013 based on the exit poll. b) Calculate a 95%-confidence interval for p p based on the exit poll. By method 7.3: \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} Where $$ n = 740 \\ \\hat{p} = 0.227 \\ z_{1-0.05/2} = 1.959964 $$ So the answer is: $$ 0.227 \\pm 0.03018109 = [0.1968189, 0.2571811 ] $$ or $$ [19.7\\%, 25.7\\%] $$ With prop.test > prop.test ( x = 168 , n = 740 , p = 0.295 , correct = FALSE ) 1 - sample proportions test without continuity correction data : 168 out of 740 , null probability 0.295 X - squared = 16.44 , df = 1 , p - value = 5.022e-05 alternative hypothesis : true p is not equal to 0.295 95 percent confidence interval : 0.1982994 0.2585741 sample estimates : p 0.227027 7.4 Sugar quality A wholesaler needs to find a supplier that delivers sugar in 1 kg bags. From two potential suppliers 50 bags of sugar are received from each. A bag is described as \u2019defective\u2019 if the weight of the filled bag is less than 990 grams. The received bags were all control weighed and 6 defective from supplier A and 12 defective from supplier B were found. a) If the following hypothesis H_0 : p_A = p_B, \\\\ H_1 : p_A \\ne p_B H_0 : p_A = p_B, \\\\ H_1 : p_A \\ne p_B is tested on a significance level of 5%, what is the p-value and conclusion? Given: x_{A} = 6 \\\\ x_{B} = 12 \\\\ n_A = n_B = 50 \\\\ \\hat{p}_A = 0.12 \\\\ \\hat{p}_B = 0.24 x_{A} = 6 \\\\ x_{B} = 12 \\\\ n_A = n_B = 50 \\\\ \\hat{p}_A = 0.12 \\\\ \\hat{p}_B = 0.24 By method 7.18 \\hat{p} = \\frac{x_A + x_B}{n_A+n_B} = 0.18 \\hat{p} = \\frac{x_A + x_B}{n_A+n_B} = 0.18 Test statics z_{obs} = \\frac{\\hat{p}_A -\\hat{p}_B }{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_A}+\\frac{1}{n_A})}} = -1.561738 z_{obs} = \\frac{\\hat{p}_A -\\hat{p}_B }{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_A}+\\frac{1}{n_A})}} = -1.561738 Critical value z_{1-\\alpha/2} = z_{0.975} = 1.959964 z_{1-\\alpha/2} = z_{0.975} = 1.959964 Conclusion |z_{obs}| = 1.561738 |z_{obs}| = 1.561738 is less than the critical value, so we accept H_0 H_0 , which means that there is no significant difference between two suppliers. With prop.test and chisq.test > prop.test ( x = c ( 6 , 12 ), n = c ( 50 , 50 ), correct = FALSE , conf.level = 0.95 ) 2 - sample test for equality of proportions without continuity correction data : c ( 6 , 12 ) out of c ( 50 , 50 ) X - squared = 2.439 , df = 1 , p - value = 0.1183 alternative hypothesis : two.sided 95 percent confidence interval : -0.26875081 0.02875081 sample estimates : prop 1 prop 2 0.12 0.24 > chisq.test ( matrix ( c ( 6 , 12 , 44 , 38 ), ncol = 2 ), correct = FALSE ) Pearsons Chi - squared test data : matrix ( c ( 6 , 12 , 44 , 38 ), ncol = 2 ) X - squared = 2.439 , df = 1 , p - value = 0.1183 b) A supplier has delivered 200 bags, of which 36 were defective. A 99% confidence interval for p p the proportion of defective bags for this supplier is: \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} Where $$ n = 200 \\ \\hat{p} = \\frac{36}{200} = 0.18 \\ z_{1-0.01/2} = 2.575829 $$ So the answer is: $$ 0.18 \\pm 0.03637847 = [ 0.11, 0.25 ] $$ or $$ [22,50 ] $$ > n <- 200 > p <- 36 / 200 > z <- qnorm ( 1-0.01 / 2 ) > p - z * sqrt ( p * ( 1 - p ) / n ) [ 1 ] 0.1100246 > p + z * sqrt ( p * ( 1 - p ) / n ) [ 1 ] 0.2499754 With prop.test > prop.test ( x = 36 , n = 200 , correct = FALSE , conf.level = 0.99 ) 1 - sample proportions test without continuity correction data : 36 out of 200 , null probability 0.5 X - squared = 81.92 , df = 1 , p - value < 2.2e-16 alternative hypothesis : true p is not equal to 0.5 99 percent confidence interval : 0.1206696 0.2598803 sample estimates : p 0.18 7.5 Physical training A company wants to investigate whether the employees\u2019 physical training condition will affect their success in the job. 200 employees were tested and the following count data were found: Physical training condition Below average Average Above average Total Bad job success 11 27 15 53 Average job success 14 40 30 84 Good job success 5 23 35 63 Total 30 90 80 200 The hypothesis of independence between job success and physical training condition is to be tested by the use of the for this setup usual \\chi^2 \\chi^2 \u2212test. a) What is the expected number of individuals with above average training condition and good job success under H_0 H_0 (i.e. if H_0 H_0 is assumed to be true)? The expected number under the null hypothesis for each cell is found as e_{ij} = \"j\\text{th column total}\" * \\frac{\"i\\text{th row total}\"}{\"\\text{grand total}\"} e_{ij} = \"j\\text{th column total}\" * \\frac{\"i\\text{th row total}\"}{\"\\text{grand total}\"} The answer for table cell(3,3) is e_{33} = 80 * 63 / 200 = 25.2 e_{33} = 80 * 63 / 200 = 25.2 b) For the calculation of the relevant \\chi^2 \\chi^2 -test statistic, identify the following two numbers: A: The number of contributions to the test statistic: R*C = 3*3 = 9 R*C = 3*3 = 9 , one for each cell B: \\frac{(o_{11}-e_{11})^2}{e_{11}} \\frac{(o_{11}-e_{11})^2}{e_{11}} Find o_{ii} o_{ii} and e_{ii} e_{ii} o_{11} = 11 \\\\ e_{11} = 30*53/200 = 7.95 o_{11} = 11 \\\\ e_{11} = 30*53/200 = 7.95 Hence \\frac{(11-7.95)^2}{7.95} = 1.170126 \\frac{(11-7.95)^2}{7.95} = 1.170126 So the contribution to the statistic from table cell (1,1) is 1.170126 1.170126 c) The total \\chi^2 \\chi^2 -test statistic is 10.985 10.985 , so the \\text{p-value} \\text{p-value} and the conclusion will be(both must be valid): The degree of freedom: (R-1)(C-1)= (3-1)(3-1) = 2 (R-1)(C-1)= (3-1)(3-1) = 2 > pvalue <- 1 - pchisq ( 10.985 , df = 4 ) [ 1 ] 0.02673311 So \\text{p-value} = 0.0267 \\text{p-value} = 0.0267 The conclusion is that the calculated \\text{p-value} \\text{p-value} is less than \\alpha=0.05 \\alpha=0.05 , which means that the hypothesis of independence between physical training condition and success in the job is rejected on a 5% level. In other words, there is significant dependence between job success and physical training condition. > training <- matrix ( c ( 11 , 27 , 15 , 14 , 40 , 30 , 5 , 23 , 35 ), ncol = 3 , byrow = TRUE ) > colnames ( training ) <- c ( \"Below averga\" , \"Average\" , \"Above average\" ) > rownames ( training ) <- c ( \"Bad job success\" , \"Average job success\" , \"Good job success\" ) > training Below averga Average Above average Bad job success 11 27 15 Average job success 14 40 30 Good job success 5 23 35 > chi <- chisq.test ( training , correct = FALSE ) > chi Pearsons Chi - squared test data : training X - squared = 10.985 , df = 4 , p - value = 0.02673","title":"7 Categorical and Count Data"},{"location":"chapter_7/#categorical-and-count-data","text":"","title":"Categorical and Count Data"},{"location":"chapter_7/#71-passing-proportions","text":"The passing proportions for the two courses, p_1 p_1 and p_2 p_2 should be compared. Course 1 Course 2 Row total Passed 82 104 186 Not passed 26 39 65 Column total 108 143 251","title":"7.1 Passing proportions"},{"location":"chapter_7/#a","text":"Compute a 95% confidence interval for the difference between the two passing proportions. By Method 7.15 $$ \\hat{p_1} = \\frac{82}{108} = 0.7592593 \\ \\hat{p_2} = \\frac{104}{143} = 0.7272727 $$ \\hat{\\sigma}_{\\hat{p_1} -\\hat{p_2}} = \\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1}+\\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}} = 0.05549318 \\hat{\\sigma}_{\\hat{p_1} -\\hat{p_2}} = \\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1}+\\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}} = 0.05549318 n1 <- 108 n2 <- 143 p1 <- 82 / n1 p2 <- 104 / n2 SEp1 <- sqrt ( p1 * ( 1 - p1 ) / n1 ) SEp2 <- sqrt ( p2 * ( 1 - p2 ) / n2 ) SEp1p2 <- sqrt ( SEp1 ^ 2 + SEp2 ^ 2 ) SEp1p2 0.05549318 So the 95% CI for the difference is: (\\hat{p}_1-\\hat{p}_2) \\pm z_{1-\\alpha/2}*\\hat\\sigma_{\\hat{p}_1-{\\hat{p}_2}} = [-0.0767781,0.1407512 ] (\\hat{p}_1-\\hat{p}_2) \\pm z_{1-\\alpha/2}*\\hat\\sigma_{\\hat{p}_1-{\\hat{p}_2}} = [-0.0767781,0.1407512 ] ( p1 - p2 ) - qnorm ( 1-0.05 / 2 ) * SEp1p2 -0.0767781 ( p1 - p2 ) + qnorm ( 1-0.05 / 2 ) * SEp1p2 0.1407512 By prop.test function > prop.test ( x = c ( 82 , 104 ), n = c ( n1 , n2 ), correct = FALSE ) 2 - sample test for equality of proportions without continuity correction data : c ( 82 , 104 ) out of c ( n1 , n2 ) X - squared = 0.32805 , df = 1 , p - value = 0.5668 alternative hypothesis : two.sided 95 percent confidence interval : -0.0767781 0.1407512 sample estimates : prop 1 prop 2 0.7592593 0.7272727","title":"a)"},{"location":"chapter_7/#b","text":"What is the critical values for the \\chi^2 \\chi^2 -test of the hypothesis H_0:p_1=p_2 H_0:p_1=p_2 with significance level \\alpha= 0.01 \\alpha= 0.01 ? By method 7.22 The degree of freedom is (r-1)(c-1) = (2-1)(2-1) = 1 (r-1)(c-1) = (2-1)(2-1) = 1 > qchisq ( 1-0.01 , df = 1 ) [ 1 ] 6.634897 Note z_{1-\\alpha/2} z_{1-\\alpha/2} , but \\chi^2_{1-\\alpha} \\chi^2_{1-\\alpha} . So you don't divide \\alpha \\alpha by two, when you use \\chi^2 \\chi^2 distribution.","title":"b)"},{"location":"chapter_7/#c","text":"If the passing proportion for a course given repeatedly is assumed to be 0.80 on average, and there are 250 students who are taking the exam each time, what is the expected value, \\mu \\mu and standard deviation \\sigma \\sigma , for the number of students who do not pass the exam for a randomly selected course? By Theorem 2.21 \\mu = np = 250 * 0.20 = 50 \\\\ \\sigma = \\sqrt{np(1-p)} = \\sqrt{250*0.2(1-0.2)} = 6.324555 \\mu = np = 250 * 0.20 = 50 \\\\ \\sigma = \\sqrt{np(1-p)} = \\sqrt{250*0.2(1-0.2)} = 6.324555","title":"c)"},{"location":"chapter_7/#72-outdoor-lighting","text":"A company that sells outdoor lighting, gets a lamp produced in 3 material variations: in copper, with painted surface and with stainless steel. The lamps are sold partly in Denmark and partly for export. For 250 lamps the distribution of sales between the three variants and Denmark/export are depicted. The data is shown in the following table: Denmark (Success?) Export (Failure?) Copper variant 7.2% 6.4% Painted variant 28.0% 34.8% Stainless steel variant 8.8% 14.8%","title":"7.2 Outdoor lighting"},{"location":"chapter_7/#a_1","text":"Is there a significant difference between the proportion exported and the proportion sold in Denmark (with \\alpha = 0.05 \\alpha = 0.05 )? Here we need to find difference between Denmark and export, which means that we don't need to specify different variants. So the total number for Denmark and the total number for export is respectively 44% and 56% or 110 lamps and 140 lamps. By method 7.11 (One sample proportion hypothesis test) : H_0: {p} = 0.5 \\\\ H_1: {p} \\ne 0.5 H_0: {p} = 0.5 \\\\ H_1: {p} \\ne 0.5 z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} = -1.897367 z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} = -1.897367 \\text{p-value} = 0.05777957 \\text{p-value} = 0.05777957 > zobs <- ( 110 - 250 * 0.5 ) / ( sqrt ( 250 * 0.5 * ( 0.5 ))) [ 1 ] -1.897367 > pvalue <- 2 * ( 1 - pnorm ( abs ( zobs ))) [ 1 ] 0.05777957 \\text{p-value} > \\alpha \\text{p-value} > \\alpha , so we accept H_0 H_0 , meaning that there is no significant difference between the proportion exported and the proportion sold in Denmark. With prop.test > prop.test ( x = xDK , n = n , p = 0.5 , correct = FALSE ) 1 - sample proportions test without continuity correction data : xDK out of n , null probability 0.5 X - squared = 3.6 , df = 1 , p - value = 0.05778 alternative hypothesis : true p is not equal to 0.5 95 percent confidence interval : 0.379837 0.501979 sample estimates : p 0.44","title":"a)"},{"location":"chapter_7/#b_1","text":"The relevant critical value to use for testing whether there is a significant difference in how the sold variants are distributed in Denmark and for export is (with \\alpha = 0.05 \\alpha = 0.05 )? The degree of freedom: $ (R-1)(C-1) = (3-1)(2-1) = 2$ The correct answer is: \\chi^2_{1-\\alpha}= \\chi^2_{0.95} = 5.991465 \\chi^2_{1-\\alpha}= \\chi^2_{0.95} = 5.991465 qchisq ( 0.95 , df = 2 )","title":"b)"},{"location":"chapter_7/#73-local-election","text":"At the local elections in Denmark in November 2013 the Social Democrats (A) had p = 29.5\\% p = 29.5\\% of the votes at the country level. From an early so-called exit poll it was estimated that they would only get 22.7\\% 22.7\\% of the votes. Suppose the exit poll was based on 740 740 people out of which then 168 168 people reported having voted for A.","title":"7.3 Local election"},{"location":"chapter_7/#a_2","text":"At the time of the exit poll the p p was of course not known. If the following hypothesis was tested based on the exit poll: H_0: p = 0.295 \\\\ H_1 : p \\ne 0.295 H_0: p = 0.295 \\\\ H_1 : p \\ne 0.295 what test statistic and conclusion would then be obtained with \\alpha=0.001 \\alpha=0.001 ? Test statistic z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} \\\\ x = 168 \\\\ n = 740 \\\\ p_0 = 0.295 z_{obs} = \\frac{x-np_0}{\\sqrt{np_0(1-p_0)}} \\\\ x = 168 \\\\ n = 740 \\\\ p_0 = 0.295 > n <- 740 > x <- 168 > p0 <- 0.295 > zobs <- ( x - n * p0 ) / ( sqrt ( n * p0 * ( 1 - p0 ))) [ 1 ] -4.054586 So we get that $$ z_{obs} = -4.054586 $$ The critical value z_{1-\\alpha/2} z_{1-\\alpha/2} > qnorm ( 1 - ( 0.001 / 2 )) 3.290527 Conclusion |z_{obs}| = 4.0545 |z_{obs}| = 4.0545 is more than the critical value 3.290527 3.290527 , so we reject H_0 H_0 . This means that it was significantly unlikely that Social Democrats would have p=29.5 p=29.5 at the local elections in Denmark in November 2013 based on the exit poll.","title":"a)"},{"location":"chapter_7/#b_2","text":"Calculate a 95%-confidence interval for p p based on the exit poll. By method 7.3: \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} Where $$ n = 740 \\ \\hat{p} = 0.227 \\ z_{1-0.05/2} = 1.959964 $$ So the answer is: $$ 0.227 \\pm 0.03018109 = [0.1968189, 0.2571811 ] $$ or $$ [19.7\\%, 25.7\\%] $$ With prop.test > prop.test ( x = 168 , n = 740 , p = 0.295 , correct = FALSE ) 1 - sample proportions test without continuity correction data : 168 out of 740 , null probability 0.295 X - squared = 16.44 , df = 1 , p - value = 5.022e-05 alternative hypothesis : true p is not equal to 0.295 95 percent confidence interval : 0.1982994 0.2585741 sample estimates : p 0.227027","title":"b)"},{"location":"chapter_7/#74-sugar-quality","text":"A wholesaler needs to find a supplier that delivers sugar in 1 kg bags. From two potential suppliers 50 bags of sugar are received from each. A bag is described as \u2019defective\u2019 if the weight of the filled bag is less than 990 grams. The received bags were all control weighed and 6 defective from supplier A and 12 defective from supplier B were found.","title":"7.4 Sugar quality"},{"location":"chapter_7/#a_3","text":"If the following hypothesis H_0 : p_A = p_B, \\\\ H_1 : p_A \\ne p_B H_0 : p_A = p_B, \\\\ H_1 : p_A \\ne p_B is tested on a significance level of 5%, what is the p-value and conclusion? Given: x_{A} = 6 \\\\ x_{B} = 12 \\\\ n_A = n_B = 50 \\\\ \\hat{p}_A = 0.12 \\\\ \\hat{p}_B = 0.24 x_{A} = 6 \\\\ x_{B} = 12 \\\\ n_A = n_B = 50 \\\\ \\hat{p}_A = 0.12 \\\\ \\hat{p}_B = 0.24 By method 7.18 \\hat{p} = \\frac{x_A + x_B}{n_A+n_B} = 0.18 \\hat{p} = \\frac{x_A + x_B}{n_A+n_B} = 0.18 Test statics z_{obs} = \\frac{\\hat{p}_A -\\hat{p}_B }{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_A}+\\frac{1}{n_A})}} = -1.561738 z_{obs} = \\frac{\\hat{p}_A -\\hat{p}_B }{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_A}+\\frac{1}{n_A})}} = -1.561738 Critical value z_{1-\\alpha/2} = z_{0.975} = 1.959964 z_{1-\\alpha/2} = z_{0.975} = 1.959964 Conclusion |z_{obs}| = 1.561738 |z_{obs}| = 1.561738 is less than the critical value, so we accept H_0 H_0 , which means that there is no significant difference between two suppliers. With prop.test and chisq.test > prop.test ( x = c ( 6 , 12 ), n = c ( 50 , 50 ), correct = FALSE , conf.level = 0.95 ) 2 - sample test for equality of proportions without continuity correction data : c ( 6 , 12 ) out of c ( 50 , 50 ) X - squared = 2.439 , df = 1 , p - value = 0.1183 alternative hypothesis : two.sided 95 percent confidence interval : -0.26875081 0.02875081 sample estimates : prop 1 prop 2 0.12 0.24 > chisq.test ( matrix ( c ( 6 , 12 , 44 , 38 ), ncol = 2 ), correct = FALSE ) Pearsons Chi - squared test data : matrix ( c ( 6 , 12 , 44 , 38 ), ncol = 2 ) X - squared = 2.439 , df = 1 , p - value = 0.1183","title":"a)"},{"location":"chapter_7/#b_3","text":"A supplier has delivered 200 bags, of which 36 were defective. A 99% confidence interval for p p the proportion of defective bags for this supplier is: \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\hat{p} \\pm z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} Where $$ n = 200 \\ \\hat{p} = \\frac{36}{200} = 0.18 \\ z_{1-0.01/2} = 2.575829 $$ So the answer is: $$ 0.18 \\pm 0.03637847 = [ 0.11, 0.25 ] $$ or $$ [22,50 ] $$ > n <- 200 > p <- 36 / 200 > z <- qnorm ( 1-0.01 / 2 ) > p - z * sqrt ( p * ( 1 - p ) / n ) [ 1 ] 0.1100246 > p + z * sqrt ( p * ( 1 - p ) / n ) [ 1 ] 0.2499754 With prop.test > prop.test ( x = 36 , n = 200 , correct = FALSE , conf.level = 0.99 ) 1 - sample proportions test without continuity correction data : 36 out of 200 , null probability 0.5 X - squared = 81.92 , df = 1 , p - value < 2.2e-16 alternative hypothesis : true p is not equal to 0.5 99 percent confidence interval : 0.1206696 0.2598803 sample estimates : p 0.18","title":"b)"},{"location":"chapter_7/#75-physical-training","text":"A company wants to investigate whether the employees\u2019 physical training condition will affect their success in the job. 200 employees were tested and the following count data were found: Physical training condition Below average Average Above average Total Bad job success 11 27 15 53 Average job success 14 40 30 84 Good job success 5 23 35 63 Total 30 90 80 200 The hypothesis of independence between job success and physical training condition is to be tested by the use of the for this setup usual \\chi^2 \\chi^2 \u2212test.","title":"7.5 Physical training"},{"location":"chapter_7/#a_4","text":"What is the expected number of individuals with above average training condition and good job success under H_0 H_0 (i.e. if H_0 H_0 is assumed to be true)? The expected number under the null hypothesis for each cell is found as e_{ij} = \"j\\text{th column total}\" * \\frac{\"i\\text{th row total}\"}{\"\\text{grand total}\"} e_{ij} = \"j\\text{th column total}\" * \\frac{\"i\\text{th row total}\"}{\"\\text{grand total}\"} The answer for table cell(3,3) is e_{33} = 80 * 63 / 200 = 25.2 e_{33} = 80 * 63 / 200 = 25.2","title":"a)"},{"location":"chapter_7/#b_4","text":"For the calculation of the relevant \\chi^2 \\chi^2 -test statistic, identify the following two numbers: A: The number of contributions to the test statistic: R*C = 3*3 = 9 R*C = 3*3 = 9 , one for each cell B: \\frac{(o_{11}-e_{11})^2}{e_{11}} \\frac{(o_{11}-e_{11})^2}{e_{11}} Find o_{ii} o_{ii} and e_{ii} e_{ii} o_{11} = 11 \\\\ e_{11} = 30*53/200 = 7.95 o_{11} = 11 \\\\ e_{11} = 30*53/200 = 7.95 Hence \\frac{(11-7.95)^2}{7.95} = 1.170126 \\frac{(11-7.95)^2}{7.95} = 1.170126 So the contribution to the statistic from table cell (1,1) is 1.170126 1.170126","title":"b)"},{"location":"chapter_7/#c_1","text":"The total \\chi^2 \\chi^2 -test statistic is 10.985 10.985 , so the \\text{p-value} \\text{p-value} and the conclusion will be(both must be valid): The degree of freedom: (R-1)(C-1)= (3-1)(3-1) = 2 (R-1)(C-1)= (3-1)(3-1) = 2 > pvalue <- 1 - pchisq ( 10.985 , df = 4 ) [ 1 ] 0.02673311 So \\text{p-value} = 0.0267 \\text{p-value} = 0.0267 The conclusion is that the calculated \\text{p-value} \\text{p-value} is less than \\alpha=0.05 \\alpha=0.05 , which means that the hypothesis of independence between physical training condition and success in the job is rejected on a 5% level. In other words, there is significant dependence between job success and physical training condition. > training <- matrix ( c ( 11 , 27 , 15 , 14 , 40 , 30 , 5 , 23 , 35 ), ncol = 3 , byrow = TRUE ) > colnames ( training ) <- c ( \"Below averga\" , \"Average\" , \"Above average\" ) > rownames ( training ) <- c ( \"Bad job success\" , \"Average job success\" , \"Good job success\" ) > training Below averga Average Above average Bad job success 11 27 15 Average job success 14 40 30 Good job success 5 23 35 > chi <- chisq.test ( training , correct = FALSE ) > chi Pearsons Chi - squared test data : training X - squared = 10.985 , df = 4 , p - value = 0.02673","title":"c)"}]}